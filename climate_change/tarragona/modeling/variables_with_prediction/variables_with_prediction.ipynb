{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables With Prediction Modelling\n",
    "\n",
    "Variables with future predictions are used to predict the Absorbance.\n",
    "\n",
    "The variables are:\n",
    "* Air temperature\n",
    "* Daily Cumulated Rainfall\n",
    "* Water Temperature\n",
    "* Flow River (River Discharge in the Projections folder)\n",
    "\n",
    "\n",
    "3 different models are used:\n",
    "* linear regression\n",
    "* random forest\n",
    "* neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.outliers_influence import (\n",
    "    variance_inflation_factor,\n",
    ")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Neural Network\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"..\", \"data\", \"tarragona\")\n",
    "\n",
    "raw_data_folder = os.path.join(data_folder, \"raw_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_excel(\n",
    "    os.path.join(raw_data_folder, \"raw_full_dataset.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.rename(\n",
    "    columns={\n",
    "        \"flowriver\": \"Flow River\",\n",
    "        \"cumulated_rainfall_24h\": \"Daily Cumulated Rainfall\",\n",
    "        \"environmental_temperature\": \"Air Temperature\",\n",
    "        \"nitrate\": \"Nitrate\",\n",
    "        \"dissolvedoxygen\": \"Dissolved Oxygen\",\n",
    "        \"turbidity\": \"Turbidity\",\n",
    "        \"watertemperature\": \"Water Temperature\",\n",
    "        \"redoxpotential\": \"Redox Potential\",\n",
    "        \"ABS254\": \"UVA254\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Variables with no future projections\n",
    "\n",
    "They are:\n",
    "- Nitrate\n",
    "- pH\n",
    "- Ammonium\n",
    "- Dissolved Oxygen\n",
    "- Conductivity\n",
    "- Redox Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(\n",
    "    columns=[\n",
    "        \"Nitrate (mg/L)\",\n",
    "        \"pH\",\n",
    "        \"Ammonium (mg/L)\",\n",
    "        \"Dissolved Oxygen (mg/L)\",\n",
    "        \"Conductivity (ÂµS/cm)\",\n",
    "        \"Redox Potential (mV)\",\n",
    "        \"Turbidity (NTU)\",\n",
    "        \"Daily Cumulated Rainfall\",\n",
    "        \"Flow River\",                       \n",
    "        \"Air Temperature\",\n",
    "        \"is_outlier\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the Monthly Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Year\"] = full_df[\"DateTime\"].dt.year\n",
    "full_df[\"Month\"] = full_df[\"DateTime\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the monthly average\n",
    "monthly_avg_df = full_df.groupby([\"Year\", \"Month\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = monthly_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Season\"] = full_df[\"Month\"].apply(\n",
    "    lambda x: \"Winter\"\n",
    "    if x in [12, 1, 2]\n",
    "    else \"Spring\"\n",
    "    if x in [3, 4, 5]\n",
    "    else \"Summer\"\n",
    "    if x in [6, 7, 8]\n",
    "    else \"Autumn\"\n",
    ")\n",
    "\n",
    "# convert Season to integer\n",
    "full_df[\"Season\"] = full_df[\"Season\"].apply(\n",
    "    lambda x: 1\n",
    "    if x == \"Winter\"\n",
    "    else 2\n",
    "    if x == \"Spring\"\n",
    "    else 3\n",
    "    if x == \"Summer\"\n",
    "    else 4\n",
    ")\n",
    "\n",
    "full_df[\"Timestamp\"] = full_df[\"DateTime\"].apply(\n",
    "    lambda x: x.timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[full_df.columns.difference([\"DateTime\"])]\n",
    "\n",
    "\n",
    "vif_test = pd.DataFrame()\n",
    "vif_test[\"variable\"] = X.columns\n",
    "vif_test[\"VIF\"] = [\n",
    "    variance_inflation_factor(X.values, i) for i in range(X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[full_df.columns.difference([\"DateTime\"])]\n",
    "\n",
    "\n",
    "vif_test = pd.DataFrame()\n",
    "vif_test[\"variable\"] = X.columns\n",
    "vif_test[\"VIF\"] = [\n",
    "    variance_inflation_factor(X.values, i) for i in range(X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, lags: int, rolling_window: int, poly_degree: int):\n",
    "    \n",
    "    initial_features = df.columns\n",
    "    # add polynomial features\n",
    "    poly = PolynomialFeatures(degree=poly_degree)\n",
    "    df_poly = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df_poly, columns=poly.get_feature_names_out(df.columns))\n",
    "    \n",
    "    # add lagged, rolling and expanding features for each variable in df\n",
    "    for col in initial_features.difference([\"Year\", \"Month\"]):\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
    "            \n",
    "        df[f\"{col}_rolling{rolling_window}\"] = df[col].rolling(rolling_window).mean()\n",
    "        \n",
    "    # fill NaN values with bfill\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    df.drop(columns=['1'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the year and month columns\n",
    "full_df[\"Year\"] = full_df[\"DateTime\"].dt.year\n",
    "full_df[\"Month\"] = full_df[\"DateTime\"].dt.month\n",
    "\n",
    "# Save the datetime column for later (drop diff returns error\n",
    "# if I remove it before)\n",
    "datetime_column = full_df.dropna()[\"DateTime\"]\n",
    "\n",
    "X = full_df.drop(columns=[\"DateTime\", \"UVA254\"])\n",
    "y = full_df[['DateTime', 'UVA254']]\n",
    "\n",
    "X = extend_features(X, lags=1, rolling_window=3, poly_degree=2)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "cols = X.columns\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=cols)\n",
    "\n",
    "# Add the datetime column back\n",
    "X[\"DateTime\"] = datetime_column.values\n",
    "\n",
    "\n",
    "X = X.set_index(\"DateTime\")\n",
    "y = y.set_index(\"DateTime\")\n",
    "\n",
    "# sort the columns\n",
    "X = X[sorted(X.columns)]\n",
    "\n",
    "X_train = X.loc[:\"2022-01-01\"]\n",
    "y_train = y.loc[:\"2022-01-01\"]\n",
    "\n",
    "X_test = X.loc[\"2022-01-01\":]\n",
    "y_test = y.loc[\"2022-01-01\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train.values, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "predictions = model.get_prediction(\n",
    "    sm.add_constant(X_test)\n",
    ").summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = model.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, predictions[\"mean\"]))\n",
    "r2 = r2_score(y_test, predictions[\"mean\"])\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, predictions[\"mean\"], c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(model.fittedvalues, train_res, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Train Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=model.fittedvalues.values,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = (\n",
    "    y_test[\"UVA254\"].values - predictions[\"mean\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(predictions[\"mean\"], residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "# sns.lineplot(x=y_train['DateTime'], y=model.fittedvalues.values, label='Fitted Values')\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=predictions[\"mean\"].values,\n",
    "    label=\"Predicted Values\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    predictions[\"obs_ci_lower\"],\n",
    "    predictions[\"obs_ci_upper\"],\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"AIC = {model.aic:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[0],\n",
    "    75,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 Predictions\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = predictions[\"mean\"]\n",
    "lr_lower_bound = predictions[\"obs_ci_lower\"]\n",
    "lr_upper_bound = predictions[\"obs_ci_upper\"]\n",
    "lr_rmse = rmse\n",
    "lr_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform K-Fold Cross-Validation\n",
    "\n",
    "K = 10 since the training set is composed of 10 years (almost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestQuantileRegressor(\n",
    "    n_estimators=20, max_features=\"log2\", max_depth=7, random_state=42\n",
    ")\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "rf_ensemble = cross_validate(\n",
    "    rf_model,\n",
    "    X_train,\n",
    "    y_train.values.flatten(),\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_estimator=True,\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = X_train.columns\n",
    "feature_importance[\"importance_mean\"] = np.mean(\n",
    "    [\n",
    "        estimator.feature_importances_\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "feature_importance[\"importance_std\"] = np.std(\n",
    "    [\n",
    "        estimator.feature_importances_\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance_mean\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature with the std\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.errorbar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    y=feature_importance[\"importance_mean\"],\n",
    "    yerr=feature_importance[\"importance_std\"],\n",
    "    fmt=\"o\",\n",
    ")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "mean_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test, quantiles=0.5)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "lower_bound_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test, quantiles=0.05)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "upper_bound_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test, quantiles=0.95)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predictions = np.mean(mean_predictions, axis=0)\n",
    "lower_bound_predictions = np.mean(lower_bound_predictions, axis=0)\n",
    "upper_bound_predictions = np.mean(upper_bound_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, mean_predictions))\n",
    "r2 = r2_score(y_test, mean_predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R\\u00b2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test.values, mean_predictions, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test[\"UVA254\"] - mean_predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(mean_predictions, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_train, quantiles=0.5)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "train_predictions = np.mean(train_predictions, axis=0)\n",
    "\n",
    "train_residuals = y_train[\"UVA254\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of the residuals and of the train set\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    "    ax=ax[0],\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    "    ax=ax[0],\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=train_residuals,\n",
    "    label=\"Training Residuals\",\n",
    "    ax=ax[1],\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index, y=mean_predictions, label=\"Predicted Values\"\n",
    ")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    lower_bound_predictions,\n",
    "    y2=upper_bound_predictions,\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[6],\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 Predictions\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = mean_predictions\n",
    "rf_lower_bound = lower_bound_predictions\n",
    "rf_upper_bound = upper_bound_predictions\n",
    "rf_rmse = rmse\n",
    "rf_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_xgb_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tra, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tra, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = xgb.XGBRegressor(random_state=42, **params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tra, y_tra)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_tr, y_tr) -> float:\n",
    "    eta = trial.suggest_float(\"eta\", 1e-5, 1, log=True)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1, log=True)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1, log=True)\n",
    "    learning_rate = trial.suggest_float(\n",
    "        \"learning_rate\", 1e-5, 1, log=True\n",
    "    )\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    updater = trial.suggest_categorical(\n",
    "        \"updater\", [\"shotgun\", \"coord_descent\"]\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"booster\": \"gblinear\",\n",
    "        \"eta\": eta,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"updater\": updater,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_tr, y_tr)\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_xgb_model(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            params,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"XGBoost-Extended.sqlite3\"):       \n",
    "    study = optuna.load_study(\n",
    "    study_name=\"Hyperparameter Tuning - XGBoost\",\n",
    "    storage=f\"sqlite:///XGBoost-Extended.sqlite3\",\n",
    "    )\n",
    "            \n",
    "else:    \n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=f\"sqlite:///XGBoost-Extended.sqlite3\",\n",
    "        study_name=\"Hyperparameter Tuning - XGBoost\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "params[\"objective\"] = \"reg:squarederror\"\n",
    "params[\"booster\"] = \"gblinear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params['n_estimators'] = 150\n",
    "# params['learning_rate'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {}\n",
    "# param[\"objective\"] = \"reg:squarederror\"\n",
    "# param[\"booster\"] = \"gblinear\"\n",
    "# param[\"n_estimators\"] = 10\n",
    "# param[\"learning_rate\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",\n",
    "#     \"booster\": \"gblinear\",\n",
    "#     \"eta\": 0.021222820197838683,\n",
    "#     \"reg_lambda\": 1.2716135487076726e-07,\n",
    "#     \"reg_alpha\": 0.25584966658518155,\n",
    "#     \"learning_rate\": 0.6602531811820622,\n",
    "#     \"n_estimators\": 369,\n",
    "#     \"updater\": \"shotgun\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    **params,\n",
    ")\n",
    "\n",
    "booster.fit(X_train, y_train[\"UVA254\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = booster.feature_names_in_\n",
    "feature_importance[\"importance\"] = booster.feature_importances_\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.bar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    height=feature_importance[\"importance\"],\n",
    ")\n",
    "\n",
    "# rotate the x axis words by 45Â°\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 100\n",
    "\n",
    "n_size = len(X_train)\n",
    "predictions = np.zeros((len(X_test), n_iterations))\n",
    "metrics = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "# Bootstrap sample (random state changes each iteration)\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, n_samples=n_size, random_state=i)\n",
    "    \n",
    "    # Train the model with the best hyperparameters\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[:, i] = y_pred\n",
    "    \n",
    "    # Calculate and store the metric (e.g., RMSE)\n",
    "    metric = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "\n",
    "\n",
    "# Convert to a numpy array for easier calculation\n",
    "metrics = np.array(metrics)\n",
    "\n",
    "# Calculate the mean RMSE\n",
    "mean_rmse = np.mean(metrics)\n",
    "\n",
    "# Calculate 95% confidence interval of the predictions\n",
    "lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "\n",
    "# Calculate the mean predictions\n",
    "mean_predictions = np.mean(predictions, axis=1)\n",
    "\n",
    "xgb_results = {\n",
    "    \"y_pred\": mean_predictions,\n",
    "    \"y_pred_lower\": lower_bound,\n",
    "    \"y_pred_upper\": upper_bound,\n",
    "    \"model\": model,\n",
    "    \"rmse\": mean_rmse,\n",
    "    \"r2\": r2_score(y_test, mean_predictions),\n",
    "    \"mae\": np.mean(np.abs(y_test.values - mean_predictions)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test[\"UVA254\"], xgb_results['y_pred'], c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test[\"UVA254\"] - xgb_results['y_pred']\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(xgb_results['y_pred'], residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = booster.predict(X_train)\n",
    "train_residuals = y_train[\"UVA254\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train.index, y=train_predictions, label=\"Fitted Values\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_med = xgb_results[\"y_pred\"]\n",
    "y_lower = xgb_results[\"y_pred_lower\"]\n",
    "y_upper = xgb_results[\"y_pred_upper\"]\n",
    "\n",
    "rmse = xgb_results[\"rmse\"]\n",
    "r2 = xgb_results[\"r2\"]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(x=y_test.index, y=y_med, label=\"Predicted Values\")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    y_lower,\n",
    "    y2=y_upper,\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[6],\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"UVA254 Predictions\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pred = y_med\n",
    "boost_lower_bound = y_lower\n",
    "boost_upper_bound = y_upper\n",
    "boost_rmse = rmse\n",
    "boost_r2 = r2\n",
    "boost_mae = xgb_results[\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM (Random Forest with Linear Regressors on leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_lgbm_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        random_state=42,\n",
    "        linear_tree=True,\n",
    "    )\n",
    "\n",
    "    if params is not None:\n",
    "        model.set_params(**params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    config = {\n",
    "        \"n_estimators\": trial.suggest_int(\n",
    "            \"n_estimators\", 1, 20, step=1\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_float(\n",
    "            \"learning_rate\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16, step=1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20, step=1),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\n",
    "            \"min_data_in_leaf\", 2, 50, step=1\n",
    "        ),\n",
    "        \"lambda_l1\": trial.suggest_float(\n",
    "            \"lambda_l1\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"lambda_l2\": trial.suggest_float(\n",
    "            \"lambda_l2\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"min_split_gain\": trial.suggest_float(\n",
    "            \"min_split_gain\", 0, 15, step=0.5\n",
    "        ),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"min_child_samples\": trial.suggest_int(\n",
    "            \"min_child_samples\", 20, 1000, log=True\n",
    "        ),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 500, step=10),\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_cv, y_cv)\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_lgbm_model(\n",
    "            X_cv,\n",
    "            y_cv,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"LGBM-Extended.sqlite3\"):\n",
    "        \n",
    "    study = optuna.load_study(\n",
    "    study_name=\"Hyperparameter Tuning - LGBM\",\n",
    "    storage=f\"sqlite:///LGBM-Extended.sqlite3\",\n",
    "    )\n",
    "        \n",
    "else:\n",
    "        \n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=f\"sqlite:///LGBM-Extended.sqlite3\",\n",
    "        study_name=\"Hyperparameter Tuning - LGBM\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "\n",
    "# params['n_estimators'] = 10\n",
    "# params[\"max_bin\"] = 30\n",
    "# params[\"learning_rate\"] = 0.6\n",
    "# params['lambda_l2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# params = {\n",
    "#     \"n_estimators\": 16,\n",
    "#     \"learning_rate\": 0.6192800859019298,\n",
    "#     \"max_depth\": 16,\n",
    "#     \"num_leaves\": 20,\n",
    "#     \"min_data_in_leaf\": 34,\n",
    "#     \"lambda_l1\": 1.8585248563175933,\n",
    "#     \"lambda_l2\": 0.020368547806226774,\n",
    "#     \"min_split_gain\": 2.5,\n",
    "#     \"subsample\": 0.5639096844841955,\n",
    "#     \"bagging_fraction\": 0.026474369917739878,\n",
    "#     \"feature_fraction\": 0.0012608584366219668,\n",
    "#     \"min_child_samples\": 33,\n",
    "#     \"max_bin\": 20,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "n_size = len(X_train)\n",
    "predictions = np.zeros((len(X_test), n_iterations))\n",
    "metrics = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "# Bootstrap sample (random state changes each iteration)\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, n_samples=n_size, random_state=i)\n",
    "    \n",
    "    # Train the model with the best hyperparameters\n",
    "    model = LGBMRegressor(\n",
    "    objective=\"regression\",\n",
    "    random_state=42,\n",
    "    linear_tree=True,\n",
    "    )\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[:, i] = y_pred\n",
    "    \n",
    "    # Calculate and store the metric (e.g., RMSE)\n",
    "    metric = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "\n",
    "\n",
    "# Convert to a numpy array for easier calculation\n",
    "metrics = np.array(metrics)\n",
    "\n",
    "# Calculate the mean RMSE\n",
    "mean_rmse = np.mean(metrics)\n",
    "\n",
    "# Calculate 95% confidence interval of the predictions\n",
    "lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "\n",
    "# Calculate the mean predictions\n",
    "mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "lgbm_results = {\n",
    "    \"y_pred\": mean_predictions,\n",
    "    \"y_pred_lower\": lower_bound,\n",
    "    \"y_pred_upper\": upper_bound,\n",
    "    \"model\": model,\n",
    "    \"rmse\": mean_rmse,\n",
    "    \"r2\": r2_score(y_test, mean_predictions),\n",
    "    \"mae\": np.mean(np.abs(y_test.values - mean_predictions)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = model.feature_name_\n",
    "feature_importance[\"importance\"] = model.feature_importances_\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.bar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    height=feature_importance[\"importance\"],\n",
    ")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_med = lgbm_results[\"y_pred\"]\n",
    "y_lower = lgbm_results[\"y_pred_lower\"]\n",
    "y_upper = lgbm_results[\"y_pred_upper\"]\n",
    "\n",
    "rmse = lgbm_results[\"rmse\"]\n",
    "r2 = lgbm_results[\"r2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test[\"UVA254\"], y_med, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test[\"UVA254\"] - y_med\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_med, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = model.predict(X_train)\n",
    "train_residuals = y_train[\"UVA254\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(x=y_test.index, y=y_med, label=\"Predicted Values\")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    y_lower.flatten(),\n",
    "    y2=y_upper.flatten(),\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[6],\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"UVA254 Predictions\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = y_med\n",
    "lgbm_lower_bound = y_lower\n",
    "lgbm_upper_bound = y_upper\n",
    "lgbm_rmse = rmse\n",
    "lgbm_r2 = r2\n",
    "lgbm_mae = lgbm_results[\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_nn_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = MLPRegressor(\n",
    "        random_state=42,\n",
    "        hidden_layer_sizes=tuple(params[\"layers\"]),\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    param = params.copy()\n",
    "    param.pop(\"layers\")\n",
    "    model.set_params(**param)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    config = {\n",
    "        \"layers\": [\n",
    "            trial.suggest_int(f\"n_units_{i}\", 50, 100, step=5)\n",
    "            for i in range(trial.suggest_int(\"n_layers\", 2, 2))\n",
    "        ],\n",
    "        \"activation\": trial.suggest_categorical(\n",
    "            \"activation\", [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "        ),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"sgd\", \"adam\"]),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-5, 1),\n",
    "        \"learning_rate\": trial.suggest_categorical(\n",
    "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "        ),\n",
    "        \"power_t\": trial.suggest_float(\"power_t\", 0.1, 1),\n",
    "        \"beta_1\": trial.suggest_float(\"beta_1\", 0.1, 1),\n",
    "        \"beta_2\": trial.suggest_float(\"beta_2\", 0.1, 1),\n",
    "        \"epsilon\": trial.suggest_float(\"epsilon\", 1e-8, 1),\n",
    "        \"early_stopping\": True,\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_cv, y_cv)\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_nn_model(\n",
    "            X_cv,\n",
    "            y_cv,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"MLP-Extended.sqlite3\"):\n",
    "    \n",
    "    study = optuna.load_study(\n",
    "    study_name=\"Hyperparameter Tuning - MLP\",\n",
    "    storage=f\"sqlite:///MLP-Extended.sqlite3\",\n",
    "    )\n",
    "        \n",
    "else:\n",
    "        \n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=f\"sqlite:///MLP-Extended.sqlite3\",\n",
    "        study_name=\"Hyperparameter Tuning - MLP\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_layers\": 2,\n",
    "#     \"n_units_0\": 85,\n",
    "#     \"n_units_1\": 75,\n",
    "#     \"activation\": \"relu\",\n",
    "#     \"solver\": \"adam\",\n",
    "#     \"alpha\": 0.7765540584565614,\n",
    "#     \"learning_rate\": \"constant\",\n",
    "#     \"power_t\": 0.3382710741601535,\n",
    "#     \"beta_1\": 0.19887581875693028,\n",
    "#     \"beta_2\": 0.984060053664114,\n",
    "#     \"epsilon\": 0.32827083622604075,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_size = len(X_train)\n",
    "predictions = np.zeros((len(X_test), n_iterations))\n",
    "metrics = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    # Copy since we will be modifying the params\n",
    "    params_copy = params.copy()\n",
    "    \n",
    "    # Bootstrap sample (random state changes each iteration)\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, n_samples=n_size, random_state=i)\n",
    "    \n",
    "    \n",
    "    hidden_layer_sizes = [\n",
    "        params_copy[f\"n_units_{k}\"] for k in range(params_copy[\"n_layers\"])\n",
    "    ]\n",
    "\n",
    "    for j in range(params_copy[\"n_layers\"]):\n",
    "        params_copy.pop(f\"n_units_{j}\")\n",
    "\n",
    "    params_copy.pop(\"n_layers\")\n",
    "        \n",
    "    model = MLPRegressor(\n",
    "        random_state=42,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    model.set_params(**params_copy)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    model.fit(X_resampled, y_resampled.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[:, i] = y_pred\n",
    "    \n",
    "    # Calculate and store the metric (e.g., RMSE)\n",
    "    metric = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "\n",
    "\n",
    "# Convert to a numpy array for easier calculation\n",
    "metrics = np.array(metrics)\n",
    "\n",
    "# Calculate the mean RMSE\n",
    "mean_rmse = np.mean(metrics)\n",
    "\n",
    "# Calculate 95% confidence interval of the predictions\n",
    "lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "\n",
    "# Calculate the mean predictions\n",
    "mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "mlp_results = {\n",
    "    \"y_pred\": mean_predictions,\n",
    "    \"y_pred_lower\": lower_bound,\n",
    "    \"y_pred_upper\": upper_bound,\n",
    "    \"model\": model,\n",
    "    \"rmse\": mean_rmse,\n",
    "    \"r2\": r2_score(y_test, mean_predictions),\n",
    "    \"mae\": np.mean(np.abs(y_test.values - mean_predictions)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate prediction and coverage level on testing set\n",
    "y_med = mlp_results[\"y_pred\"]\n",
    "y_lower = mlp_results[\"y_pred_lower\"]\n",
    "y_upper = mlp_results[\"y_pred_upper\"]\n",
    "\n",
    "rmse = mlp_results[\"rmse\"]\n",
    "r2 = mlp_results[\"r2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test[\"UVA254\"], y_med, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test[\"UVA254\"] - y_med\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_med, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = model.predict(X_train)\n",
    "train_residuals = y_train[\"UVA254\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    train_predictions.flatten(), train_residuals, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index, y=y_med, label=\"Predicted Values\"\n",
    ")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    y_lower.flatten(),\n",
    "    y2=y_upper.flatten(),\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[6],\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"UVA254 Predictions\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = y_med\n",
    "nn_lower_bound = y_lower\n",
    "nn_upper_bound = y_upper\n",
    "nn_rmse = rmse\n",
    "nn_r2 = r2\n",
    "nn_mae = mlp_results[\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "from cProfile import label\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train.index,\n",
    "    y=y_train[\"UVA254\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Linear Regression\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=boost_pred,\n",
    "    label=\"XGBoost\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    boost_lower_bound,\n",
    "    boost_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=lgbm_pred,\n",
    "    label=\"Light GBM\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    lgbm_lower_bound,\n",
    "    lgbm_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Neural Network\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=nn_pred,\n",
    "    label=\"Neural Network\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    nn_lower_bound,\n",
    "    nn_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"XGBoost RMSE = {boost_rmse:.2f}, R\\u00b2 = {boost_r2:.2f}, MAE = {boost_mae:.2f}\",\n",
    "        f\"Light GBM RMSE = {lgbm_rmse:.2f}, R\\u00b2 = {lgbm_r2:.2f}, MAE = {lgbm_mae:.2f}\",\n",
    "        f\"Neural Network RMSE = {nn_rmse:.2f}, R\\u00b2 = {nn_r2:.2f} MAE = {nn_mae:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train.index[6],\n",
    "    -2,\n",
    "    s=text_string,\n",
    "    fontsize=16,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "plt.figure(figsize=(20, 10))\n",
    "# sns.lineplot(x=y_train['DateTime'], y=y_train['UVA254'], label='Historical Data')\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=y_test[\"UVA254\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=boost_pred,\n",
    "    label=\"XGBoost\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    boost_lower_bound,\n",
    "    boost_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Light GBM\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=lgbm_pred,\n",
    "    label=\"Light GBM\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    lgbm_lower_bound,\n",
    "    lgbm_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Neural Network\n",
    "sns.lineplot(\n",
    "    x=y_test.index,\n",
    "    y=nn_pred,\n",
    "    label=\"MLP Neural Network\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test.index,\n",
    "    nn_lower_bound,\n",
    "    nn_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "plt.ylim(-5, 41)\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"XGBoost RMSE = {boost_rmse:.2f}, R\\u00b2 = {boost_r2:.2f}, MAE = {boost_mae:.2f}\",\n",
    "        f\"Light GBM RMSE = {lgbm_rmse:.2f}, R\\u00b2 = {lgbm_r2:.2f}, MAE = {lgbm_mae:.2f}\",\n",
    "        f\"Neural Network RMSE = {nn_rmse:.2f}, R\\u00b2 = {nn_r2:.2f} MAE = {nn_mae:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_test.index[6],\n",
    "    36,\n",
    "    s=text_string,\n",
    "    fontsize=16,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
