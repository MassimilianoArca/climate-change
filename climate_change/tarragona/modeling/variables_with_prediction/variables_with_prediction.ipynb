{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables With Prediction Modelling\n",
    "\n",
    "Variables with future predictions are used to predict the Absorbance.\n",
    "\n",
    "The variables are:\n",
    "* Air temperature\n",
    "* Daily Cumulated Rainfall\n",
    "* Water Temperature\n",
    "* Flow River (River Discharge in the Projections folder)\n",
    "\n",
    "\n",
    "3 different models are used:\n",
    "* linear regression\n",
    "* random forest\n",
    "* neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.outliers_influence import (\n",
    "    variance_inflation_factor,\n",
    ")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Neural Network\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# MAPiE\n",
    "from mapie.regression import MapieQuantileRegressor, MapieRegressor\n",
    "from mapie.metrics import regression_coverage_score\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"..\", \"data\", \"tarragona\")\n",
    "\n",
    "raw_data_folder = os.path.join(data_folder, \"raw_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_excel(\n",
    "    os.path.join(raw_data_folder, \"raw_full_dataset.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.rename(\n",
    "    columns={\n",
    "        \"flowriver\": \"Flow River\",\n",
    "        \"cumulated_rainfall_24h\": \"Daily Cumulated Rainfall\",\n",
    "        \"environmental_temperature\": \"Air Temperature\",\n",
    "        \"nitrate\": \"Nitrate\",\n",
    "        \"dissolvedoxygen\": \"Dissolved Oxygen\",\n",
    "        \"turbidity\": \"Turbidity\",\n",
    "        \"watertemperature\": \"Water Temperature\",\n",
    "        \"redoxpotential\": \"Redox Potential\",\n",
    "        \"ABS254\": \"Absorbance 254nm\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Variables with no future projections\n",
    "\n",
    "They are:\n",
    "- Nitrate\n",
    "- pH\n",
    "- Ammonium\n",
    "- Dissolved Oxygen\n",
    "- Conductivity\n",
    "- Redox Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(\n",
    "    columns=[\n",
    "        \"Nitrate\",\n",
    "        \"pH\",\n",
    "        \"Ammonium\",\n",
    "        \"Dissolved Oxygen\",\n",
    "        \"Conductivity\",\n",
    "        \"Redox Potential\",\n",
    "        \"Turbidity\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the Monthly Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Year\"] = full_df[\"DateTime\"].dt.year\n",
    "full_df[\"Month\"] = full_df[\"DateTime\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the monthly average\n",
    "monthly_avg_df = full_df.groupby([\"Year\", \"Month\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = monthly_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Season\"] = full_df[\"Month\"].apply(\n",
    "    lambda x: \"Winter\"\n",
    "    if x in [12, 1, 2]\n",
    "    else \"Spring\"\n",
    "    if x in [3, 4, 5]\n",
    "    else \"Summer\"\n",
    "    if x in [6, 7, 8]\n",
    "    else \"Autumn\"\n",
    ")\n",
    "\n",
    "# convert Season to integer\n",
    "full_df[\"Season\"] = full_df[\"Season\"].apply(\n",
    "    lambda x: 1\n",
    "    if x == \"Winter\"\n",
    "    else 2\n",
    "    if x == \"Spring\"\n",
    "    else 3\n",
    "    if x == \"Summer\"\n",
    "    else 4\n",
    ")\n",
    "\n",
    "full_df[\"Timestamp\"] = full_df[\"DateTime\"].apply(\n",
    "    lambda x: x.timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[full_df.columns.difference([\"DateTime\"])]\n",
    "\n",
    "\n",
    "vif_test = pd.DataFrame()\n",
    "vif_test[\"variable\"] = X.columns\n",
    "vif_test[\"VIF\"] = [\n",
    "    variance_inflation_factor(X.values, i) for i in range(X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[full_df.columns.difference([\"DateTime\"])]\n",
    "\n",
    "\n",
    "vif_test = pd.DataFrame()\n",
    "vif_test[\"variable\"] = X.columns\n",
    "vif_test[\"VIF\"] = [\n",
    "    variance_inflation_factor(X.values, i) for i in range(X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features + Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"All Features + Year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Month\", \"Season\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2022-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2022-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2022-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2022-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train[y_train.columns.difference([\"DateTime\"])]\n",
    "y_test_fit = y_test[y_test.columns.difference([\"DateTime\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_fit = scaler.fit_transform(X_train_fit)\n",
    "X_test_fit = scaler.transform(X_test_fit)\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit, columns=X_train.columns.difference([\"DateTime\"])\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit, columns=X_test.columns.difference([\"DateTime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With available future projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train_fit.values, sm.add_constant(X_train_fit)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "predictions = model.get_prediction(\n",
    "    sm.add_constant(X_test_fit)\n",
    ").summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = model.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_fit, predictions[\"mean\"]))\n",
    "r2 = r2_score(y_test_fit, predictions[\"mean\"])\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test_fit, predictions[\"mean\"], c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(model.fittedvalues, train_res, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Train Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=model.fittedvalues.values,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = (\n",
    "    y_test_fit[\"Absorbance 254nm\"].values - predictions[\"mean\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(predictions[\"mean\"], residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "# sns.lineplot(x=y_train['DateTime'], y=model.fittedvalues.values, label='Fitted Values')\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=predictions[\"mean\"].values,\n",
    "    label=\"Predicted Values\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    predictions[\"obs_ci_lower\"],\n",
    "    predictions[\"obs_ci_upper\"],\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"AIC = {model.aic:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    75,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm - Setting: {setting}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = predictions[\"mean\"]\n",
    "lr_lower_bound = predictions[\"obs_ci_lower\"]\n",
    "lr_upper_bound = predictions[\"obs_ci_upper\"]\n",
    "lr_rmse = rmse\n",
    "lr_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features + Year w/ log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"Ammonium + Flow River + Redox Potential + Turbidity + Year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Month\", \"Season\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]\n",
    "\n",
    "# scale y to ln(y)\n",
    "y[\"Absorbance 254nm\"] = np.log(y[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2022-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2022-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2022-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2022-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train[y_train.columns.difference([\"DateTime\"])]\n",
    "y_test_fit = y_test[y_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_fit = scaler.fit_transform(X_train_fit)\n",
    "X_test_fit = scaler.transform(X_test_fit)\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit, columns=X_train.columns.difference([\"DateTime\"])\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit, columns=X_test.columns.difference([\"DateTime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train_fit.values, sm.add_constant(X_train_fit)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "predictions = model.get_prediction(\n",
    "    sm.add_constant(X_test_fit)\n",
    ").summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data\n",
    "y_train[\"Absorbance 254nm\"] = np.exp(y_train[\"Absorbance 254nm\"])\n",
    "y_test[\"Absorbance 254nm\"] = np.exp(y_test[\"Absorbance 254nm\"])\n",
    "y_test_fit = np.exp(y_test_fit)\n",
    "\n",
    "predictions[\"mean\"] = np.exp(predictions[\"mean\"])\n",
    "predictions[\"obs_ci_lower\"] = np.exp(predictions[\"obs_ci_lower\"])\n",
    "predictions[\"obs_ci_upper\"] = np.exp(predictions[\"obs_ci_upper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_fit, predictions[\"mean\"]))\n",
    "r2 = r2_score(y_test_fit, predictions[\"mean\"])\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test_fit, predictions[\"mean\"], c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = (\n",
    "    y_test_fit[\"Absorbance 254nm\"].values - predictions[\"mean\"].values\n",
    ")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(predictions[\"mean\"], residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=predictions[\"mean\"].values,\n",
    "    label=\"Predicted Values\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    predictions[\"obs_ci_lower\"],\n",
    "    predictions[\"obs_ci_upper\"],\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"AIC = {model.aic:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    75,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm - Setting: {setting}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = predictions[\"mean\"]\n",
    "log_lower_bound = predictions[\"obs_ci_lower\"]\n",
    "log_upper_bound = predictions[\"obs_ci_upper\"]\n",
    "log_rmse = rmse\n",
    "log_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features + Year + Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Month\", \"Season\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_poly = poly.fit_transform(\n",
    "    X[X.columns.difference([\"DateTime\"] + further_features)]\n",
    ")\n",
    "\n",
    "X_poly = pd.DataFrame(\n",
    "    X_poly,\n",
    "    columns=poly.get_feature_names_out(\n",
    "        X.columns.difference([\"DateTime\"] + further_features)\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_poly[\"DateTime\"] = X[\"DateTime\"].values\n",
    "\n",
    "X_poly[further_features] = X[further_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X_poly[X_poly[\"DateTime\"] < \"2022-01-01\"]\n",
    "X_test = X_poly[X_poly[\"DateTime\"] >= \"2022-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2022-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2022-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train[y_train.columns.difference([\"DateTime\"])]\n",
    "y_test_fit = y_test[y_test.columns.difference([\"DateTime\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_fit = scaler.fit_transform(\n",
    "    X_train_fit[X_train_fit.columns.difference(further_features)]\n",
    ")\n",
    "X_test_fit = scaler.transform(\n",
    "    X_test_fit[X_test_fit.columns.difference(further_features)]\n",
    ")\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit,\n",
    "    columns=X_train.columns.difference([\"DateTime\"] + further_features),\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit,\n",
    "    columns=X_test.columns.difference([\"DateTime\"] + further_features),\n",
    ")\n",
    "\n",
    "X_train_fit[further_features] = X_train[further_features].values\n",
    "X_test_fit[further_features] = X_test[further_features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train_fit.values, sm.add_constant(X_train_fit)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "predictions = model.get_prediction(\n",
    "    sm.add_constant(X_test_fit)\n",
    ").summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = model.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_fit, predictions[\"mean\"]))\n",
    "r2 = r2_score(y_test_fit, predictions[\"mean\"])\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test_fit, predictions[\"mean\"], c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(model.fittedvalues, train_res, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Train Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=model.fittedvalues.values,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = (\n",
    "    y_test_fit[\"Absorbance 254nm\"].values - predictions[\"mean\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(predictions[\"mean\"], residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "# sns.lineplot(x=y_train['DateTime'], y=model.fittedvalues.values, label='Fitted Values')\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=predictions[\"mean\"].values,\n",
    "    label=\"Predicted Values\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    predictions[\"obs_ci_lower\"],\n",
    "    predictions[\"obs_ci_upper\"],\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"AIC = {model.aic:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    75,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm - Setting: {setting}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pred = predictions[\"mean\"]\n",
    "poly_lower_bound = predictions[\"obs_ci_lower\"]\n",
    "poly_upper_bound = predictions[\"obs_ci_upper\"]\n",
    "poly_rmse = rmse\n",
    "poly_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Linear Regression\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=lr_pred.values,\n",
    "    label=\"Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    lr_lower_bound,\n",
    "    lr_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    ")\n",
    "\n",
    "# Linear Regression Log\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=log_pred.values,\n",
    "    label=\"Log Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    log_lower_bound,\n",
    "    log_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    ")\n",
    "\n",
    "# Linear Regression Poly\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=poly_pred.values,\n",
    "    label=\"Poly Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    poly_lower_bound,\n",
    "    poly_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Linear Regression RMSE = {lr_rmse:.2f}, R\\u00b2 = {lr_r2:.2f}\",\n",
    "        f\"Log Linear Regression RMSE = {log_rmse:.2f}, R\\u00b2 = {log_r2:.2f}\",\n",
    "        f\"Poly Linear Regression RMSE = {poly_rmse:.2f}, R\\u00b2 = {poly_r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_test[\"DateTime\"].iloc[0] - pd.Timedelta(days=20),\n",
    "    33,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "plt.figure(figsize=(20, 10))\n",
    "# sns.lineplot(x=y_train['DateTime'], y=y_train['Absorbance 254nm'], label='Historical Data')\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Linear Regression\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=lr_pred.values,\n",
    "    label=\"Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    lr_lower_bound,\n",
    "    lr_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    ")\n",
    "\n",
    "# Linear Regression Log\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=log_pred.values,\n",
    "    label=\"Log Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    log_lower_bound,\n",
    "    log_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    ")\n",
    "\n",
    "# Linear Regression Poly\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=poly_pred.values,\n",
    "    label=\"Poly Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    poly_lower_bound,\n",
    "    poly_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    ")\n",
    "\n",
    "# change the y range to see the differences\n",
    "plt.ylim(-5, 41)\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm (un.Abs/m)\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Linear Regression RMSE = {lr_rmse:.2f}\",\n",
    "        f\"Log Linear Regression RMSE = {log_rmse:.2f}\",\n",
    "        f\"Poly Linear Regression RMSE = {poly_rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_test[\"DateTime\"].iloc[0] - pd.Timedelta(days=20),\n",
    "    36,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm (un.Abs/m) - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"All Features + Year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[\n",
    "    full_df.columns.difference(\n",
    "        [\"Absorbance 254nm\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2022-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2022-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2022-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2022-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train[y_train.columns.difference([\"DateTime\"])]\n",
    "y_test_fit = y_test[y_test.columns.difference([\"DateTime\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform K-Fold Cross-Validation\n",
    "\n",
    "K = 10 since the training set is composed of 10 years (almost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestQuantileRegressor(\n",
    "    n_estimators=20, max_features=\"log2\", max_depth=7, random_state=42\n",
    ")\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "rf_ensemble = cross_validate(\n",
    "    rf_model,\n",
    "    X_train_fit,\n",
    "    y_train_fit.values.flatten(),\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_estimator=True,\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = X_train_fit.columns\n",
    "feature_importance[\"importance_mean\"] = np.mean(\n",
    "    [\n",
    "        estimator.feature_importances_\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "feature_importance[\"importance_std\"] = np.std(\n",
    "    [\n",
    "        estimator.feature_importances_\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance_mean\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature with the std\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.errorbar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    y=feature_importance[\"importance_mean\"],\n",
    "    yerr=feature_importance[\"importance_std\"],\n",
    "    fmt=\"o\",\n",
    ")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "mean_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test_fit, quantiles=0.5)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "lower_bound_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test_fit, quantiles=0.05)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "upper_bound_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_test_fit, quantiles=0.95)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predictions = np.mean(mean_predictions, axis=0)\n",
    "lower_bound_predictions = np.mean(lower_bound_predictions, axis=0)\n",
    "upper_bound_predictions = np.mean(upper_bound_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_fit, mean_predictions))\n",
    "r2 = r2_score(y_test_fit, mean_predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R\\u00b2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test_fit.values, mean_predictions, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test_fit[\"Absorbance 254nm\"] - mean_predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(mean_predictions, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = np.array(\n",
    "    [\n",
    "        estimator.predict(X_train_fit, quantiles=0.5)\n",
    "        for estimator in rf_ensemble[\"estimator\"]\n",
    "    ]\n",
    ")\n",
    "train_predictions = np.mean(train_predictions, axis=0)\n",
    "\n",
    "train_residuals = y_train_fit[\"Absorbance 254nm\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of the residuals and of the train set\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    "    ax=ax[0],\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    "    ax=ax[0],\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=train_residuals,\n",
    "    label=\"Training Residuals\",\n",
    "    ax=ax[1],\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"], y=mean_predictions, label=\"Predicted Values\"\n",
    ")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    lower_bound_predictions,\n",
    "    y2=upper_bound_predictions,\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    75,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"Absorbance 254nm - Setting: {setting}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = mean_predictions\n",
    "rf_lower_bound = lower_bound_predictions\n",
    "rf_upper_bound = upper_bound_predictions\n",
    "rf_rmse = rmse\n",
    "rf_r2 = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Season\", \"Month\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_poly = poly.fit_transform(X[X.columns.difference([\"DateTime\"])])\n",
    "\n",
    "X_poly = pd.DataFrame(\n",
    "    X_poly,\n",
    "    columns=poly.get_feature_names_out(\n",
    "        X.columns.difference([\"DateTime\"])\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_poly[\"DateTime\"] = X[\"DateTime\"].values\n",
    "\n",
    "# X_poly[further_features] = X[further_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X_poly[X_poly[\"DateTime\"] < \"2021-01-01\"]\n",
    "X_test = X_poly[X_poly[\"DateTime\"] >= \"2021-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2021-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train[y_train.columns.difference([\"DateTime\"])]\n",
    "y_test_fit = y_test[y_test.columns.difference([\"DateTime\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2021-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2021-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2021-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train.copy()\n",
    "y_test_fit = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scale the data and keep the column names\n",
    "X_train_fit = scaler.fit_transform(X_train_fit)\n",
    "X_test_fit = scaler.transform(X_test_fit)\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit, columns=X_train.columns.difference([\"DateTime\"])\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit, columns=X_test.columns.difference([\"DateTime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curves(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    cv=None,\n",
    "    train_sizes=np.linspace(0.3, 1.0, 5),\n",
    "):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        train_sizes=train_sizes,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "    train_scores_std = np.sqrt(np.std(train_scores, axis=1))\n",
    "    validation_scores_mean = np.sqrt(\n",
    "        -np.mean(validation_scores, axis=1)\n",
    "    )\n",
    "    validation_scores_std = np.sqrt(np.std(validation_scores, axis=1))\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    plt.figure(figsize=(20, 7.5))\n",
    "    plt.plot(\n",
    "        train_sizes,\n",
    "        train_scores_mean,\n",
    "        \"o-\",\n",
    "        color=\"r\",\n",
    "        label=\"Training error\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        train_sizes,\n",
    "        validation_scores_mean,\n",
    "        \"o-\",\n",
    "        color=\"g\",\n",
    "        label=\"Validation error\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        validation_scores_mean - validation_scores_std,\n",
    "        validation_scores_mean + validation_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)\n",
    "    plt.xlabel(\"Training set size\", fontsize=14)\n",
    "    title = title\n",
    "    plt.title(title, fontsize=18, y=1.03)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_curves(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    cv=None,\n",
    "    param_name=None,\n",
    "    param_range=None,\n",
    "    fit_params=None,\n",
    "):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        param_name=param_name,\n",
    "        param_range=param_range,\n",
    "        fit_params=fit_params,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",  #'roc_auc'\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "    train_scores_std = np.sqrt(np.std(train_scores, axis=1))\n",
    "    test_scores_mean = np.sqrt(-np.mean(test_scores, axis=1))\n",
    "    test_scores_std = np.sqrt(np.std(test_scores, axis=1))\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    plt.figure(figsize=(20, 7.5))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(param_name, fontsize=14)\n",
    "    plt.ylabel(\"Score\", fontsize=14)\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        param_range,\n",
    "        train_scores_mean,\n",
    "        label=\"Training score\",\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.plot(\n",
    "        param_range,\n",
    "        test_scores_mean,\n",
    "        label=\"Cross-validation score\",\n",
    "        color=\"navy\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"navy\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.legend(loc=\"best\")\n",
    "    # plt.ylim(4, 8)\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()\n",
    "\n",
    "    # print param value with lowest test score\n",
    "    print(\n",
    "        f\"{param_name} with lowest score:\",\n",
    "        param_range[np.argmin(test_scores_mean)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    booster=\"gblinear\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (XGB)\"\n",
    "learning_curves(\n",
    "    model, title, X_train_fit, y_train_fit[\"Absorbance 254nm\"], cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"n_estimators\"\n",
    "param_range = np.arange(1, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Validation Curves (LGBM)\"\n",
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"learning_rate\"\n",
    "param_range = np.logspace(-3, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-3, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"eta\"\n",
    "param_range = np.logspace(-5, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"reg_alpha\"\n",
    "param_range = np.logspace(-8, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"reg_lambda\"\n",
    "param_range = np.logspace(-5, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"scale_pos_weight\"\n",
    "param_range = np.logspace(-5, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"base_score\"\n",
    "param_range = np.linspace(0.1, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"importance_type\"\n",
    "param_range = [\"gain\", \"weight\", \"cover\", \"total_gain\", \"total_cover\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_xgb_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = xgb.XGBRegressor(random_state=42, **params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    eta = trial.suggest_float(\"eta\", 1e-5, 1, log=True)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1, log=True)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1, log=True)\n",
    "    learning_rate = trial.suggest_float(\n",
    "        \"learning_rate\", 1e-5, 1, log=True\n",
    "    )\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    updater = trial.suggest_categorical(\n",
    "        \"updater\", [\"shotgun\", \"coord_descent\"]\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"booster\": \"gblinear\",\n",
    "        \"eta\": eta,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"updater\": updater,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_train_fit, y_train_fit[\"Absorbance 254nm\"])\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_xgb_model(\n",
    "            X_train_fit,\n",
    "            y_train_fit[\"Absorbance 254nm\"],\n",
    "            train_index,\n",
    "            test_index,\n",
    "            params,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///XGBoost.sqlite3\",\n",
    "    study_name=\"Hyperparameter Tuning - All Features\"\n",
    "    + \" + \"\n",
    "    + str(further_features),\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=200,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "params[\"objective\"] = \"reg:squarederror\"\n",
    "params[\"booster\"] = \"gblinear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params['n_estimators'] = 150\n",
    "# params['learning_rate'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "param[\"objective\"] = \"reg:squarederror\"\n",
    "param[\"booster\"] = \"gblinear\"\n",
    "param[\"n_estimators\"] = 10\n",
    "param[\"learning_rate\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"eta\": 0.021222820197838683,\n",
    "    \"reg_lambda\": 1.2716135487076726e-07,\n",
    "    \"reg_alpha\": 0.25584966658518155,\n",
    "    \"learning_rate\": 0.6602531811820622,\n",
    "    \"n_estimators\": 369,\n",
    "    \"updater\": \"shotgun\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    **params,\n",
    ")\n",
    "\n",
    "booster.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = booster.feature_names_in_\n",
    "feature_importance[\"importance\"] = booster.feature_importances_\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.bar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    height=feature_importance[\"importance\"],\n",
    ")\n",
    "\n",
    "# rotate the x axis words by 45\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie_cqr = MapieRegressor(booster, method=\"naive\", random_state=42)\n",
    "mapie_cqr.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# Evaluate prediction and coverage level on testing set\n",
    "y_med, y_pis_cqr = mapie_cqr.predict(X_test_fit, alpha=alpha)\n",
    "y_lower = y_pis_cqr[:, 0, 0]\n",
    "y_upper = y_pis_cqr[:, 1, 0]\n",
    "\n",
    "coverage_cqr = regression_coverage_score(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_lower, y_upper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coverage: {coverage_cqr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse(predictions, targets):\n",
    "    return 1 - (\n",
    "        np.sum((targets - predictions) ** 2)\n",
    "        / np.sum((targets - np.mean(targets)) ** 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "rmse = np.sqrt(\n",
    "    mean_squared_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    ")\n",
    "r2 = r2_score(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "mae = mean_absolute_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "nseff = nse(y_med, y_test_fit[\"Absorbance 254nm\"])\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R\\u00b2: {r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"NSE: {nseff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_med, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test_fit[\"Absorbance 254nm\"] - y_med\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_med, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions = booster.predict(X_train_fit)\n",
    "train_residuals = y_train_fit[\"Absorbance 254nm\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"], y=train_predictions, label=\"Fitted Values\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(x=y_test[\"DateTime\"], y=y_med, label=\"Predicted Values\")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    y_lower,\n",
    "    y2=y_upper,\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"Coverage = {coverage_cqr:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"Absorbance 254nm - Setting: All Features + {further_features}\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pred = y_med\n",
    "boost_lower_bound = y_lower\n",
    "boost_upper_bound = y_upper\n",
    "boost_rmse = rmse\n",
    "boost_r2 = r2\n",
    "boost_mae = mae\n",
    "boost_nse = nseff\n",
    "boost_coverage = coverage_cqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM (Random Forest with Linear Regressors on leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Season\", \"Month\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_poly = poly.fit_transform(X[X.columns.difference([\"DateTime\"])])\n",
    "\n",
    "X_poly = pd.DataFrame(\n",
    "    X_poly,\n",
    "    columns=poly.get_feature_names_out(\n",
    "        X.columns.difference([\"DateTime\"])\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_poly[\"DateTime\"] = X[\"DateTime\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X_poly[X_poly[\"DateTime\"] < \"2021-01-01\"]\n",
    "X_test = X_poly[X_poly[\"DateTime\"] >= \"2021-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2021-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train.copy()\n",
    "y_test_fit = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2021-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2021-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2021-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train.copy()\n",
    "y_test_fit = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scale the data and keep the column names\n",
    "X_train_fit = scaler.fit_transform(X_train_fit)\n",
    "X_test_fit = scaler.transform(X_test_fit)\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit, columns=X_train.columns.difference([\"DateTime\"])\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit, columns=X_test.columns.difference([\"DateTime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curves(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    cv=None,\n",
    "    train_sizes=np.linspace(0.3, 1.0, 5),\n",
    "):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        train_sizes=train_sizes,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "    train_scores_std = np.sqrt(np.std(train_scores, axis=1))\n",
    "    validation_scores_mean = np.sqrt(\n",
    "        -np.mean(validation_scores, axis=1)\n",
    "    )\n",
    "    validation_scores_std = np.sqrt(np.std(validation_scores, axis=1))\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    plt.figure(figsize=(20, 7.5))\n",
    "    plt.plot(\n",
    "        train_sizes,\n",
    "        train_scores_mean,\n",
    "        \"o-\",\n",
    "        color=\"r\",\n",
    "        label=\"Training error\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        train_sizes,\n",
    "        validation_scores_mean,\n",
    "        \"o-\",\n",
    "        color=\"g\",\n",
    "        label=\"Validation error\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        validation_scores_mean - validation_scores_std,\n",
    "        validation_scores_mean + validation_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)\n",
    "    plt.xlabel(\"Training set size\", fontsize=14)\n",
    "    title = title\n",
    "    plt.title(title, fontsize=18, y=1.03)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_curves(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    cv=None,\n",
    "    param_name=None,\n",
    "    param_range=None,\n",
    "    fit_params=None,\n",
    "):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        param_name=param_name,\n",
    "        param_range=param_range,\n",
    "        fit_params=fit_params,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",  #'roc_auc'\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "    train_scores_std = np.sqrt(np.std(train_scores, axis=1))\n",
    "    test_scores_mean = np.sqrt(-np.mean(test_scores, axis=1))\n",
    "    test_scores_std = np.sqrt(np.std(test_scores, axis=1))\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    plt.figure(figsize=(20, 7.5))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(param_name, fontsize=14)\n",
    "    plt.ylabel(\"Score\", fontsize=14)\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        param_range,\n",
    "        train_scores_mean,\n",
    "        label=\"Training score\",\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.plot(\n",
    "        param_range,\n",
    "        test_scores_mean,\n",
    "        label=\"Cross-validation score\",\n",
    "        color=\"navy\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"navy\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.legend(loc=\"best\")\n",
    "    # plt.ylim(4, 8)\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()\n",
    "\n",
    "    # print param value with lowest test score\n",
    "    print(\n",
    "        f\"{param_name} with lowest score:\",\n",
    "        param_range[np.argmin(test_scores_mean)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"linear_tree\": True,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**params_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (LGBM)\"\n",
    "learning_curves(\n",
    "    model, title, X_train_fit, y_train_fit[\"Absorbance 254nm\"], cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"n_estimators\"\n",
    "param_range = np.arange(1, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Validation Curves (LGBM)\"\n",
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"learning_rate\"\n",
    "param_range = np.logspace(-3, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-3, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"num_leaves\"\n",
    "param_range = np.arange(2, 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"lambda_l1\"\n",
    "param_range = np.logspace(-5, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"lambda_l2\"\n",
    "param_range = np.logspace(-5, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"max_depth\"\n",
    "param_range = np.arange(2, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"max_bin\"\n",
    "param_range = np.arange(2, 255, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curves(\n",
    "    model,\n",
    "    title,\n",
    "    X_train_fit,\n",
    "    y_train_fit[\"Absorbance 254nm\"],\n",
    "    cv=5,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_lgbm_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        random_state=42,\n",
    "        linear_tree=True,\n",
    "    )\n",
    "\n",
    "    if params is not None:\n",
    "        model.set_params(**params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    config = {\n",
    "        \"n_estimators\": trial.suggest_int(\n",
    "            \"n_estimators\", 1, 20, step=1\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_float(\n",
    "            \"learning_rate\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16, step=1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20, step=1),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\n",
    "            \"min_data_in_leaf\", 2, 50, step=1\n",
    "        ),\n",
    "        \"lambda_l1\": trial.suggest_float(\n",
    "            \"lambda_l1\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"lambda_l2\": trial.suggest_float(\n",
    "            \"lambda_l2\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"min_split_gain\": trial.suggest_float(\n",
    "            \"min_split_gain\", 0, 15, step=0.5\n",
    "        ),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"min_child_samples\": trial.suggest_int(\n",
    "            \"min_child_samples\", 20, 1000, log=True\n",
    "        ),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 500, step=10),\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_train_fit, y_train_fit[\"Absorbance 254nm\"])\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_lgbm_model(\n",
    "            X_train_fit,\n",
    "            y_train_fit[\"Absorbance 254nm\"],\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///LGBM.sqlite3\",\n",
    "    study_name=\"Hyperparameter Tuning - All Features\"\n",
    "    + \" + \"\n",
    "    + str(further_features),\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=400, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "\n",
    "# params['n_estimators'] = 10\n",
    "# params[\"max_bin\"] = 30\n",
    "params[\"learning_rate\"] = 0.6\n",
    "# params['lambda_l2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "params = {\n",
    "    \"n_estimators\": 16,\n",
    "    \"learning_rate\": 0.6192800859019298,\n",
    "    \"max_depth\": 16,\n",
    "    \"num_leaves\": 20,\n",
    "    \"min_data_in_leaf\": 34,\n",
    "    \"lambda_l1\": 1.8585248563175933,\n",
    "    \"lambda_l2\": 0.020368547806226774,\n",
    "    \"min_split_gain\": 2.5,\n",
    "    \"subsample\": 0.5639096844841955,\n",
    "    \"bagging_fraction\": 0.026474369917739878,\n",
    "    \"feature_fraction\": 0.0012608584366219668,\n",
    "    \"min_child_samples\": 33,\n",
    "    \"max_bin\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with mapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "estimator = LGBMRegressor(\n",
    "    objective=\"regression\", random_state=42, linear_tree=True, **params\n",
    ")\n",
    "\n",
    "estimator.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate uncertainties on calibration set\n",
    "mapie_cqr = MapieRegressor(estimator, cv=\"prefit\", random_state=42)\n",
    "mapie_cqr.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the importance of each feature in the model\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = estimator.feature_name_\n",
    "feature_importance[\"importance\"] = estimator.feature_importances_\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=\"importance\", ascending=False\n",
    ")\n",
    "\n",
    "# plot the importance of each feature\n",
    "plt.figure(figsize=(25, 7.5))\n",
    "plt.bar(\n",
    "    x=feature_importance[\"feature\"],\n",
    "    height=feature_importance[\"importance\"],\n",
    ")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate prediction and coverage level on testing set\n",
    "y_med, y_pis_cqr = mapie_cqr.predict(X_test_fit, alpha=alpha)\n",
    "y_lower = y_pis_cqr[:, 0, 0]\n",
    "y_upper = y_pis_cqr[:, 1, 0]\n",
    "\n",
    "coverage_cqr = regression_coverage_score(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_lower, y_upper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coverage:\", coverage_cqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    ")\n",
    "r2 = r2_score(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "mae = mean_absolute_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "nseff = nse(y_med, y_test_fit[\"Absorbance 254nm\"])\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R\\u00b2: {r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"NSE: {nseff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_med, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test_fit[\"Absorbance 254nm\"] - y_med\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_med, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions, _ = mapie_cqr.predict(X_train_fit, alpha=alpha)\n",
    "train_residuals = y_train_fit[\"Absorbance 254nm\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(train_predictions, train_residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train_fit[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train_fit[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test_fit[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(x=y_test[\"DateTime\"], y=y_med, label=\"Predicted Values\")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    y_lower.flatten(),\n",
    "    y2=y_upper.flatten(),\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"Coverage = {coverage_cqr:.3f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"Absorbance 254nm - Setting: All Features + {further_features}\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: prevede un trend crescente, probabilmente dato da qualche feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = y_med\n",
    "lgbm_lower_bound = y_lower\n",
    "lgbm_upper_bound = y_upper\n",
    "lgbm_rmse = rmse\n",
    "lgbm_r2 = r2\n",
    "lgbm_mae = mae\n",
    "lgbm_nse = nseff\n",
    "lgbm_coverage = coverage_cqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_features = [\"Year\", \"Season\", \"Month\", \"Timestamp\"]\n",
    "\n",
    "to_drop = [\"Timestamp\", \"Season\", \"Month\"]\n",
    "\n",
    "further_features = [\n",
    "    feature for feature in further_features if feature not in to_drop\n",
    "]\n",
    "\n",
    "X_columns_to_drop = to_drop + [\"Absorbance 254nm\"]\n",
    "\n",
    "X = full_df[full_df.columns.difference(X_columns_to_drop)]\n",
    "\n",
    "y = full_df[[\"DateTime\", \"Absorbance 254nm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data such that 2022 and 2023 are test data\n",
    "X_train = X[X[\"DateTime\"] < \"2021-01-01\"]\n",
    "X_test = X[X[\"DateTime\"] >= \"2021-01-01\"]\n",
    "\n",
    "y_train = y[y[\"DateTime\"] < \"2021-01-01\"]\n",
    "y_test = y[y[\"DateTime\"] >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit = X_train[X_train.columns.difference([\"DateTime\"])]\n",
    "X_test_fit = X_test[X_test.columns.difference([\"DateTime\"])]\n",
    "\n",
    "y_train_fit = y_train.copy()\n",
    "y_test_fit = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scale the data and keep the column names\n",
    "X_train_fit = scaler.fit_transform(X_train_fit)\n",
    "X_test_fit = scaler.transform(X_test_fit)\n",
    "\n",
    "X_train_fit = pd.DataFrame(\n",
    "    X_train_fit, columns=X_train.columns.difference([\"DateTime\"])\n",
    ")\n",
    "X_test_fit = pd.DataFrame(\n",
    "    X_test_fit, columns=X_test.columns.difference([\"DateTime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_nn_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = MLPRegressor(\n",
    "        random_state=42,\n",
    "        hidden_layer_sizes=tuple(params[\"layers\"]),\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    param = params.copy()\n",
    "    param.pop(\"layers\")\n",
    "    model.set_params(**param)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    config = {\n",
    "        \"layers\": [\n",
    "            trial.suggest_int(f\"n_units_{i}\", 50, 100, step=5)\n",
    "            for i in range(trial.suggest_int(\"n_layers\", 2, 2))\n",
    "        ],\n",
    "        \"activation\": trial.suggest_categorical(\n",
    "            \"activation\", [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "        ),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"sgd\", \"adam\"]),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-5, 1),\n",
    "        \"learning_rate\": trial.suggest_categorical(\n",
    "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "        ),\n",
    "        \"power_t\": trial.suggest_float(\"power_t\", 0.1, 1),\n",
    "        \"beta_1\": trial.suggest_float(\"beta_1\", 0.1, 1),\n",
    "        \"beta_2\": trial.suggest_float(\"beta_2\", 0.1, 1),\n",
    "        \"epsilon\": trial.suggest_float(\"epsilon\", 1e-8, 1),\n",
    "        \"early_stopping\": True,\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    cv_mae = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_train_fit, y_train_fit[\"Absorbance 254nm\"])\n",
    "    ):\n",
    "        cv_mae[i] = fit_and_validate_nn_model(\n",
    "            X_train_fit,\n",
    "            y_train_fit[\"Absorbance 254nm\"],\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_mae\", cv_mae)\n",
    "\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///NeuralNetwork.sqlite3\",\n",
    "    study_name=\"Hyperparameter Tuning - All Features\"\n",
    "    + \" + \"\n",
    "    + str(further_features),\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_layers\": 2,\n",
    "    \"n_units_0\": 85,\n",
    "    \"n_units_1\": 75,\n",
    "    \"activation\": \"relu\",\n",
    "    \"solver\": \"adam\",\n",
    "    \"alpha\": 0.7765540584565614,\n",
    "    \"learning_rate\": \"constant\",\n",
    "    \"power_t\": 0.3382710741601535,\n",
    "    \"beta_1\": 0.19887581875693028,\n",
    "    \"beta_2\": 0.984060053664114,\n",
    "    \"epsilon\": 0.32827083622604075,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[\"n_units_1\"] = 80\n",
    "# params['learning_rate'] = 'invscaling'\n",
    "params[\"activation\"] = \"identity\"\n",
    "\n",
    "hidden_layer_sizes = [\n",
    "    params[f\"n_units_{i}\"] for i in range(params[\"n_layers\"])\n",
    "]\n",
    "\n",
    "for i in range(params[\"n_layers\"]):\n",
    "    params.pop(f\"n_units_{i}\")\n",
    "\n",
    "params.pop(\"n_layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with mapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "estimator = MLPRegressor(\n",
    "    random_state=42,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    **params\n",
    ")\n",
    "\n",
    "estimator.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate uncertainties on calibration set\n",
    "mapie_cqr = MapieRegressor(estimator, cv=\"prefit\", random_state=42)\n",
    "mapie_cqr.fit(X_train_fit, y_train_fit[\"Absorbance 254nm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate prediction and coverage level on testing set\n",
    "y_med, y_pis_cqr = mapie_cqr.predict(X_test_fit, alpha=alpha)\n",
    "y_lower = y_pis_cqr[:, 0, 0]\n",
    "y_upper = y_pis_cqr[:, 1, 0]\n",
    "\n",
    "coverage_cqr = regression_coverage_score(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_lower, y_upper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coverage:\", coverage_cqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    ")\n",
    "r2 = r2_score(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "mae = mean_absolute_error(y_test_fit[\"Absorbance 254nm\"], y_med)\n",
    "\n",
    "nseff = nse(y_med, y_test_fit[\"Absorbance 254nm\"])\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R\\u00b2: {r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"NSE: {nseff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    y_test_fit[\"Absorbance 254nm\"], y_med, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axline([0, 0], [1, 1], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(f\"Predictions vs True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals\n",
    "residuals = y_test_fit[\"Absorbance 254nm\"] - y_med\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_med, residuals, c=\"b\", s=40, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Test Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Test Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training residuals\n",
    "train_predictions, _ = mapie_cqr.predict(X_train_fit, alpha=alpha)\n",
    "train_residuals = y_train_fit[\"Absorbance 254nm\"] - train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(\n",
    "    train_predictions.flatten(), train_residuals, c=\"b\", s=40, alpha=0.5\n",
    ")\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Training Set Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the training residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Training Set Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series fitted values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train_fit[\"DateTime\"],\n",
    "    y=y_train_fit[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_train_fit[\"DateTime\"],\n",
    "    y=train_predictions,\n",
    "    label=\"Fitted Values\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train_fit[\"DateTime\"],\n",
    "    y=y_train_fit[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test_fit[\"DateTime\"],\n",
    "    y=y_test_fit[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test_fit[\"DateTime\"], y=y_med, label=\"Predicted Values\"\n",
    ")\n",
    "# plot std of predictions\n",
    "plt.fill_between(\n",
    "    y_test_fit[\"DateTime\"],\n",
    "    y_lower.flatten(),\n",
    "    y2=y_upper.flatten(),\n",
    "    alpha=0.2,\n",
    "    label=\"95% Prediction Interval\",\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Absorbance 254nm\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"RMSE = {rmse:.2f}\",\n",
    "        f\"R\\u00b2 = {r2:.2f}\",\n",
    "        f\"Coverage = {coverage_cqr:.3f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train_fit[\"DateTime\"].iloc[0] - pd.Timedelta(days=120),\n",
    "    35,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    f\"Absorbance 254nm - Setting: All Features + {further_features}\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = y_med\n",
    "nn_lower_bound = y_lower\n",
    "nn_upper_bound = y_upper\n",
    "nn_rmse = rmse\n",
    "nn_r2 = r2\n",
    "nn_mae = mae\n",
    "nn_nse = nseff\n",
    "nn_coverage = coverage_cqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "from cProfile import label\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    x=y_train[\"DateTime\"],\n",
    "    y=y_train[\"Absorbance 254nm\"],\n",
    "    label=\"Historical Data\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Linear Regression\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=boost_pred,\n",
    "    label=\"XGBoost\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    boost_lower_bound,\n",
    "    boost_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=lgbm_pred,\n",
    "    label=\"Light GBM\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    lgbm_lower_bound,\n",
    "    lgbm_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Neural Network\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=nn_pred,\n",
    "    label=\"Neural Network\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    nn_lower_bound,\n",
    "    nn_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"XGBoost RMSE = {boost_rmse:.2f}, R\\u00b2 = {boost_r2:.2f}, MAE = {boost_mae:.2f}\",\n",
    "        f\"Light GBM RMSE = {lgbm_rmse:.2f}, R\\u00b2 = {lgbm_r2:.2f}, MAE = {lgbm_mae:.2f}\",\n",
    "        f\"Neural Network RMSE = {nn_rmse:.2f}, R\\u00b2 = {nn_r2:.2f} MAE = {nn_mae:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_train[\"DateTime\"].iloc[0],\n",
    "    -2,\n",
    "    s=text_string,\n",
    "    fontsize=16,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for the comparison of the models\n",
    "plt.figure(figsize=(20, 10))\n",
    "# sns.lineplot(x=y_train['DateTime'], y=y_train['Absorbance 254nm'], label='Historical Data')\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=y_test[\"Absorbance 254nm\"],\n",
    "    label=\"True Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Linear Regression\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=boost_pred,\n",
    "    label=\"Linear Regression\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    boost_lower_bound,\n",
    "    boost_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=lgbm_pred,\n",
    "    label=\"Random Forest\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    lgbm_lower_bound,\n",
    "    lgbm_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"orange\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "# Neural Network\n",
    "sns.lineplot(\n",
    "    x=y_test[\"DateTime\"],\n",
    "    y=nn_pred,\n",
    "    label=\"Neural Network\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    y_test[\"DateTime\"],\n",
    "    nn_lower_bound,\n",
    "    nn_upper_bound,\n",
    "    alpha=0.2,\n",
    "    color=\"green\",\n",
    "    label=\"95% Prediction Interval\",\n",
    ")\n",
    "\n",
    "plt.ylim(-5, 41)\n",
    "\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "\n",
    "# add rmse and r2 to the plot in a box\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"XGBoost RMSE = {boost_rmse:.2f}, R\\u00b2 = {boost_r2:.2f}, MAE = {boost_mae:.2f}\",\n",
    "        f\"Light GBM RMSE = {lgbm_rmse:.2f}, R\\u00b2 = {lgbm_r2:.2f}, MAE = {lgbm_mae:.2f}\",\n",
    "        f\"Neural Network RMSE = {nn_rmse:.2f}, R\\u00b2 = {nn_r2:.2f} MAE = {nn_mae:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    y_test[\"DateTime\"].iloc[0] - pd.Timedelta(days=20),\n",
    "    36,\n",
    "    s=text_string,\n",
    "    fontsize=16,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.title(f\"UVA254 - Model Comparison\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
