{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Analysis\n",
    "\n",
    "The data here is not imputed, the missing values are just dropped.\n",
    "\n",
    "A deep analysis of the peaks on the Absorbance is performed to understand if the frequency of peaks is increasing or not in time.\n",
    "\n",
    "Here the outliers for each variable of each site are analyzed in order to find some patterns between outliers of different variables. The main goal is to understand if a sample is a real outlier or an 'analytical' one due to an error in the measurement.\n",
    "\n",
    "A unique dataset is built, appending to the Xerta one the variables that are not measured in Xerta.\n",
    "\n",
    "The variables are:\n",
    "* Air Temperature (Guiamets)\n",
    "* Daily Cumulated Rainfall (Tortosa, since it is the closest city to Xerta)\n",
    "* Flow River (Tortosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "plt.rcParams.update({\"font.size\": 26})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict_from_folder(folder_path):\n",
    "    datasets_dict = {}\n",
    "    for folder in os.listdir(folder_path):\n",
    "        if os.path.isdir(os.path.join(folder_path, folder)):\n",
    "            datasets_dict[folder] = {}\n",
    "            for file in os.listdir(os.path.join(folder_path, folder)):\n",
    "                feature_name = file.split(\".\")[0]\n",
    "                datasets_dict[folder][feature_name] = pd.read_excel(\n",
    "                    os.path.join(folder_path, folder, file)\n",
    "                )\n",
    "    return datasets_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"data\", \"tarragona\")\n",
    "\n",
    "raw_data_folder = os.path.join(data_folder, \"raw_data\")\n",
    "\n",
    "intermediate_data_folder = os.path.join(\n",
    "    data_folder, \"intermediate_data\"\n",
    ")\n",
    "\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")\n",
    "\n",
    "probabilities_folder = os.path.join(data_folder, \"probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = build_dict_from_folder(intermediate_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs = datasets_dict[\"TORTOSA\"]\n",
    "guiamets_dfs = datasets_dict[\"GUIAMETS\"]\n",
    "mequinenza_dfs = datasets_dict[\"MEQUINENZA\"]\n",
    "xerta_dfs = datasets_dict[\"XERTA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Common Time Range for valid analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get common time range for all datasets\n",
    "min_tortosa = max(\n",
    "    min(tortosa_dfs[feature][\"DateTime\"])\n",
    "    for feature in tortosa_dfs.keys()\n",
    ")\n",
    "max_tortosa = min(\n",
    "    max(tortosa_dfs[feature][\"DateTime\"])\n",
    "    for feature in tortosa_dfs.keys()\n",
    ")\n",
    "\n",
    "min_guiamets = max(\n",
    "    min(guiamets_dfs[feature][\"DateTime\"])\n",
    "    for feature in guiamets_dfs.keys()\n",
    ")\n",
    "max_guiamets = min(\n",
    "    max(guiamets_dfs[feature][\"DateTime\"])\n",
    "    for feature in guiamets_dfs.keys()\n",
    ")\n",
    "\n",
    "min_mequinenza = max(\n",
    "    min(mequinenza_dfs[feature][\"DateTime\"])\n",
    "    for feature in mequinenza_dfs.keys()\n",
    ")\n",
    "max_mequinenza = min(\n",
    "    max(mequinenza_dfs[feature][\"DateTime\"])\n",
    "    for feature in mequinenza_dfs.keys()\n",
    ")\n",
    "\n",
    "min_xerta = max(\n",
    "    min(xerta_dfs[feature][\"DateTime\"]) for feature in xerta_dfs.keys()\n",
    ")\n",
    "max_xerta = min(\n",
    "    max(xerta_dfs[feature][\"DateTime\"]) for feature in xerta_dfs.keys()\n",
    ")\n",
    "\n",
    "min_date = max(min_tortosa, min_guiamets, min_mequinenza, min_xerta)\n",
    "max_date = min(max_tortosa, max_guiamets, max_mequinenza, max_xerta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in tortosa_dfs.keys():\n",
    "    tortosa_dfs[feature] = tortosa_dfs[feature].loc[\n",
    "        (tortosa_dfs[feature][\"DateTime\"] >= min_date)\n",
    "        & (tortosa_dfs[feature][\"DateTime\"] <= max_date)\n",
    "    ]\n",
    "\n",
    "for feature in guiamets_dfs.keys():\n",
    "    guiamets_dfs[feature] = guiamets_dfs[feature].loc[\n",
    "        (guiamets_dfs[feature][\"DateTime\"] >= min_date)\n",
    "        & (guiamets_dfs[feature][\"DateTime\"] <= max_date)\n",
    "    ]\n",
    "\n",
    "for feature in mequinenza_dfs.keys():\n",
    "    mequinenza_dfs[feature] = mequinenza_dfs[feature].loc[\n",
    "        (mequinenza_dfs[feature][\"DateTime\"] >= min_date)\n",
    "        & (mequinenza_dfs[feature][\"DateTime\"] <= max_date)\n",
    "    ]\n",
    "\n",
    "for feature in xerta_dfs.keys():\n",
    "    xerta_dfs[feature] = xerta_dfs[feature].loc[\n",
    "        (xerta_dfs[feature][\"DateTime\"] >= min_date)\n",
    "        & (xerta_dfs[feature][\"DateTime\"] <= max_date)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tortosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    tortosa_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, tortosa_df = list(tortosa_dfs.items())[0]\n",
    "\n",
    "tortosa_df = tortosa_df[[\"DateTime\", \"Average\"]]\n",
    "\n",
    "tortosa_df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "\n",
    "for feature, df in list(tortosa_dfs.items())[1:]:\n",
    "    df = df[[\"DateTime\", \"Average\"]]\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    tortosa_df = tortosa_df.merge(df, on=\"DateTime\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop turbidity since it has a lot of missing values\n",
    "tortosa_df = tortosa_df.drop(columns=[\"turbidity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in tortosa_df.columns[1:]:\n",
    "    plt.figure()\n",
    "    sns.lineplot(\n",
    "        x=\"DateTime\", y=feature, data=tortosa_df, label=feature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_tortosa_df = tortosa_df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_tortosa_df[scaled_tortosa_df.columns[1:]] = scaler.fit_transform(\n",
    "    tortosa_df[tortosa_df.columns[1:]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot every combination of features\n",
    "from scipy import signal\n",
    "import scipy\n",
    "\n",
    "\n",
    "for i, feature1 in enumerate(tortosa_df.columns[1:]):\n",
    "    for j, feature2 in enumerate(tortosa_df.columns[1:]):\n",
    "        if i < j:\n",
    "            \"\"\"# cross correlation\n",
    "            product_df = pd.DataFrame()\n",
    "            product_df[\"DateTime\"] = tortosa_df[\"DateTime\"]\n",
    "            product_df[\"product\"] = (\n",
    "                scaled_tortosa_df[feature1] * scaled_tortosa_df[feature2]\n",
    "            )\n",
    "            product_df[feature1] = tortosa_df[feature1] * product_df[\"product\"]\n",
    "            product_df[feature2] = tortosa_df[feature2] * product_df[\"product\"]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            product_df[product_df.columns[1:]] = scaler.fit_transform(\n",
    "                product_df[product_df.columns[1:]]\n",
    "            )\n",
    "\n",
    "            # fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "            ccf = signal.correlate(\n",
    "                tortosa_df[feature1], tortosa_df[feature2], mode=\"full\"\n",
    "            )\n",
    "\n",
    "            ccf /= np.max(ccf)\n",
    "            ccf = ccf[int((len(ccf) - 1) / 2) :]\n",
    "            lags = np.arange(0, len(ccf))\n",
    "\n",
    "            max_lag = lags[np.argmax(ccf)]\n",
    "\n",
    "            peaks = scipy.signal.find_peaks(tortosa_df[feature1])\"\"\"\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=feature1,\n",
    "                data=scaled_tortosa_df[\n",
    "                    scaled_tortosa_df[\"DateTime\"] > \"2013\"\n",
    "                ],\n",
    "                label=feature1,\n",
    "            )\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=feature2,\n",
    "                data=scaled_tortosa_df[\n",
    "                    scaled_tortosa_df[\"DateTime\"] > \"2013\"\n",
    "                ],\n",
    "                label=feature2,\n",
    "            )\n",
    "\n",
    "            plt.xlabel(\"lag\")\n",
    "            plt.ylabel(\"cross-correlation\")\n",
    "            plt.title(f\"{feature1} vs {feature2}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    guiamets_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, guiamets_df = list(guiamets_dfs.items())[0]\n",
    "\n",
    "guiamets_df = guiamets_df[[\"DateTime\", \"Average\"]]\n",
    "\n",
    "guiamets_df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "\n",
    "for feature, df in list(guiamets_dfs.items())[1:]:\n",
    "    df = df[[\"DateTime\", \"Average\"]]\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    guiamets_df = guiamets_df.merge(df, on=\"DateTime\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in guiamets_df.columns[1:]:\n",
    "    plt.figure()\n",
    "    sns.lineplot(\n",
    "        x=\"DateTime\", y=feature, data=guiamets_df, label=feature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_guiamets_df = guiamets_df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_guiamets_df[\n",
    "    scaled_guiamets_df.columns[1:]\n",
    "] = scaler.fit_transform(guiamets_df[guiamets_df.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot every combination of features\n",
    "from scipy import signal\n",
    "import scipy\n",
    "\n",
    "\n",
    "for i, feature1 in enumerate(guiamets_df.columns[1:]):\n",
    "    for j, feature2 in enumerate(guiamets_df.columns[1:]):\n",
    "        if i < j:\n",
    "            \"\"\"# cross correlation\n",
    "            product_df = pd.DataFrame()\n",
    "            product_df[\"DateTime\"] = guiamets_df[\"DateTime\"]\n",
    "            product_df[\"product\"] = (\n",
    "                scaled_guiamets_df[feature1] * scaled_guiamets_df[feature2]\n",
    "            )\n",
    "            product_df[feature1] = guiamets_df[feature1] * product_df[\"product\"]\n",
    "            product_df[feature2] = guiamets_df[feature2] * product_df[\"product\"]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            product_df[product_df.columns[1:]] = scaler.fit_transform(\n",
    "                product_df[product_df.columns[1:]]\n",
    "            )\n",
    "\n",
    "            # fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "            ccf = signal.correlate(\n",
    "                guiamets_df[feature1], guiamets_df[feature2], mode=\"full\"\n",
    "            )\n",
    "\n",
    "            ccf /= np.max(ccf)\n",
    "            ccf = ccf[int((len(ccf) - 1) / 2) :]\n",
    "            lags = np.arange(0, len(ccf))\n",
    "\n",
    "            max_lag = lags[np.argmax(ccf)]\n",
    "\n",
    "            peaks = scipy.signal.find_peaks(guiamets_df[feature1])\"\"\"\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=feature1,\n",
    "                data=scaled_guiamets_df,\n",
    "                label=feature1,\n",
    "            )\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=feature2,\n",
    "                data=scaled_guiamets_df,\n",
    "                label=feature2,\n",
    "            )\n",
    "\n",
    "            plt.xlabel(\"lag\")\n",
    "            plt.ylabel(\"cross-correlation\")\n",
    "            plt.title(f\"{feature1} vs {feature2}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"Min date:\", df[\"DateTime\"].min())\n",
    "    print()\n",
    "    print(\"Max date:\", df[\"DateTime\"].max())\n",
    "    print()\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"Min date:\", df[\"DateTime\"].min())\n",
    "    print()\n",
    "    print(\"Max date:\", df[\"DateTime\"].max())\n",
    "    print()\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    xerta_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, xerta_df = list(xerta_dfs.items())[0]\n",
    "\n",
    "xerta_df = xerta_df[[\"DateTime\", \"Average\"]]\n",
    "\n",
    "xerta_df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "\n",
    "for feature, df in list(xerta_dfs.items())[1:]:\n",
    "    df = df[[\"DateTime\", \"Average\"]]\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    xerta_df = xerta_df.merge(df, on=\"DateTime\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in xerta_df.columns[1:]:\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=\"DateTime\", y=feature, data=xerta_df, label=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=xerta_df[\"ABS254\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"full_dataset.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in xerta_df[\"DateTime\"].dt.year.unique():\n",
    "    quartile_1, quartile_3 = xerta_df[\n",
    "        xerta_df[\"DateTime\"].dt.year == year\n",
    "    ][\"UVA254\"].quantile([0.25, 0.75])\n",
    "\n",
    "    iqr = quartile_3 - quartile_1\n",
    "\n",
    "    lower_bound = max(quartile_1 - 1.5 * iqr, 0)\n",
    "    upper_bound = quartile_3 + 1.5 * iqr\n",
    "\n",
    "    year_data = xerta_df[xerta_df[\"DateTime\"].dt.year == year]\n",
    "\n",
    "    sns.lineplot(x=\"DateTime\", y=\"UVA254\", data=year_data)\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=year_data[\"DateTime\"],\n",
    "        y=[upper_bound] * len(year_data),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark the outliers\n",
    "abs_df = xerta_df[[\"DateTime\", \"UVA254\"]].copy()\n",
    "abs_df[\"is_outlier\"] = False\n",
    "\n",
    "for year in xerta_df[\"DateTime\"].dt.year.unique():\n",
    "    quartile_1, quartile_3 = abs_df[abs_df[\"DateTime\"].dt.year == year][\n",
    "        \"UVA254\"\n",
    "    ].quantile([0.25, 0.75])\n",
    "\n",
    "    iqr = quartile_3 - quartile_1\n",
    "\n",
    "    lower_bound = max(quartile_1 - 1.5 * iqr, 0)\n",
    "    upper_bound = quartile_3 + 1.5 * iqr\n",
    "\n",
    "    abs_df.loc[abs_df[\"DateTime\"].dt.year == year, \"is_outlier\"] = (\n",
    "        abs_df[abs_df[\"DateTime\"].dt.year == year][\"UVA254\"]\n",
    "        > upper_bound\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df[\"is_outlier\"] = abs_df[\"is_outlier\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"DateTime\", y=\"UVA254\", data=abs_df)\n",
    "sns.scatterplot(\n",
    "    x=\"DateTime\",\n",
    "    y=\"UVA254\",\n",
    "    data=abs_df[abs_df[\"is_outlier\"] == 1],\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False is_outlier for the first 3 months of 2020\n",
    "abs_df.loc[\n",
    "    (abs_df[\"DateTime\"].dt.year == 2020)\n",
    "    & (abs_df[\"DateTime\"].dt.month <= 2),\n",
    "    \"is_outlier\",\n",
    "] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"DateTime\", y=\"UVA254\", data=abs_df)\n",
    "sns.scatterplot(\n",
    "    x=\"DateTime\",\n",
    "    y=\"UVA254\",\n",
    "    data=abs_df[abs_df[\"is_outlier\"] == 1],\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"UVA254\")\n",
    "plt.title(\"UVA254 with outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Unique Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df[\"cumulated_rainfall_24h\"] = tortosa_df[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "]\n",
    "xerta_df[\"flowriver\"] = tortosa_df[\"flowriver\"]\n",
    "xerta_df[\"environmental_temperature\"] = guiamets_df[\n",
    "    \"environmental_temperature\"\n",
    "]\n",
    "\n",
    "xerta_df[\"is_outlier\"] = abs_df[\"is_outlier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.to_excel(\n",
    "    os.path.join(raw_data_folder, \"raw_full_dataset.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABS Outliers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df[\"Year\"] = xerta_df[\"DateTime\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a timestamp column\n",
    "xerta_df[\"Timestamp\"] = xerta_df[\"DateTime\"].apply(\n",
    "    lambda x: x.timestamp()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = xerta_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(\n",
    "    [\n",
    "        \"cumulated_rainfall_24h\",\n",
    "        \"flowriver\",\n",
    "        \"environmental_temperature\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.rename(\n",
    "    columns={\n",
    "        \"cumulated_rainfall_24h\": \"Daily Cumulated Rainfall (L/m\\u00b2)\",\n",
    "        \"watertemperature\": \"Water Temperature (\\u00b0C)\",\n",
    "        \"environmental_temperature\": \"Air Temperature (\\u00b0C)\",\n",
    "        \"flowriver\": \"Flow River (m\\u00b3/s)\",\n",
    "        \"Conductivity\": \"Conductivity (\\u00b5S/cm)\",\n",
    "        \"dissolvedoxygen\": \"Dissolved Oxygen (mg/L)\",\n",
    "        \"nitrate\": \"Nitrate (mg/L)\",\n",
    "        \"redoxpotential\": \"Redox Potential (mV)\",\n",
    "        \"turbidity\": \"Turbidity (NTU)\",\n",
    "        \"Ammonium\": \"Ammonium (mg/L)\",\n",
    "        \"ABS254\": \"UVA254\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df.copy()\n",
    "# df.drop(columns=[\"Timestamp\", \"Year\"], inplace=True)\n",
    "abs_col = df.pop(\"UVA254\")\n",
    "df[\"UVA254\"] = abs_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=df.columns.difference([\"DateTime\"]))\n",
    "\n",
    "# add total number or rows per feature\n",
    "result_df.loc[\"Number of Samples\"] = df.count()\n",
    "result_df.loc[\"`%` of Missing Values\"] = (\n",
    "    df.isna().sum() / df.count() * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[\n",
    "    \"Number of Samples after Dropping Missing Values\"\n",
    "] = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel(\n",
    "    os.path.join(raw_data_folder, \"raw_full_dataset_summary.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplots for each feature in a unique plot\n",
    "fig, axs = plt.subplots(1, result_df.shape[1], figsize=(30, 7.5))\n",
    "\n",
    "for i, feature in enumerate(result_df.columns):\n",
    "    if feature == \"Daily Cumulated Rainfall (L/m\\u00b2)\":\n",
    "        sns.boxplot(y=df[df[feature] > 0][feature], ax=axs[i])\n",
    "        zero_values = df[df[feature] == 0][feature].count()\n",
    "    else:\n",
    "        sns.boxplot(y=df[feature], ax=axs[i])\n",
    "    # rotate x-axis labels\n",
    "    axs[i].set_ylabel(\"\")\n",
    "    axs[i].set_xlabel(\n",
    "        feature.replace(\" \", \"\\n\"), fontsize=15, labelpad=5\n",
    "    )\n",
    "\n",
    "# Add more space between the subplots\n",
    "plt.subplots_adjust(wspace=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and drop them\n",
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"is_outlier ~ Timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x=\"DateTime\", y=\"UVA254\", data=full_df)\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"UVA254\"],\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    plt.axvline(pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp + Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"is_outlier ~ Timestamp + Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp + Timestamp:Year + Year + All Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp + Timestamp:Year + Year + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Flow River\") + Nitrate + Ammonium + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\n",
    "    \"Timestamp + Timestamp:Year + Year + All Features\"\n",
    "] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp:Year + C(Year) + All Features\n",
    "\n",
    "Timestamp + Timestamp:Year + C(Year) + All Features si rompe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Flow River\") + Nitrate + Ammonium + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\"Timestamp:Year + C(Year) + All Features\"] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Ammonium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Flow River\") + Nitrate + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\"Timestamp:Year + C(Year) - Ammonium\"] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Flow River\") + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\"Timestamp:Year + C(Year) - Ammonium - Nitrate\"] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Flow River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\n",
    "    \"Timestamp:Year + C(Year) - Ammonium - Nitrate - Flow River\"\n",
    "] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + Conductivity + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\n",
    "    \"Timestamp:Year + C(Year) - Ammonium - Nitrate - Flow River - pH\"\n",
    "] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Water Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + Conductivity + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\n",
    "    \"Timestamp:Year + C(Year) - Ammonium - Nitrate - Flow River - pH - Water Temperature\"\n",
    "] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Years with p-value > 0.05 to 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the years are 2014, 2015, 2016, 2018, 2019\n",
    "# set these years to 2012\n",
    "change_full_df = full_df.copy()\n",
    "change_full_df.loc[\n",
    "    change_full_df[\"Year\"].isin([2014, 2015, 2016, 2018, 2019]), \"Year\"\n",
    "] = 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + Conductivity + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=change_full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_dict[\n",
    "    \"Timestamp:Year + C(Year) - Ammonium - Nitrate - Flow River - pH - Water Temperature - Non Significant Years\"\n",
    "] = results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Results and choose best AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_df = pd.DataFrame(aic_dict.items(), columns=[\"Model\", \"AIC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one with all the features has almost the lowest AIC and it has the maximum likelihood\n",
    "# so we will use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'is_outlier ~ Timestamp:Year + C(Year) + Q(\"Water Temperature\") + Q(\"Daily Cumulated Rainfall\") + Q(\"Air Temperature\") + pH + Conductivity + Q(\"Flow River\") + Nitrate + Ammonium + Q(\"Dissolved Oxygen\") + Turbidity + Q(\"Redox Potential\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM.from_formula(\n",
    "    formula=formula, data=full_df, family=sm.families.Binomial()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_model.fit(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=\"Absorbance 254nm\", data=full_df, ax=axs[0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=full_df[\"DateTime\"],\n",
    "    y=full_df[full_df[\"is_outlier\"] == 1][\"Absorbance 254nm\"],\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    ")\n",
    "\n",
    "# plot vertical lines for the years on the entire plot\n",
    "for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "    for ax in axs:\n",
    "        ax.axvline(\n",
    "            pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.seasonal as smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with datetime and the fitted values\n",
    "fitted_df = pd.DataFrame()\n",
    "fitted_df[\"DateTime\"] = full_df[\"DateTime\"]\n",
    "fitted_df[\"Probabilities\"] = results.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the datetime as the index\n",
    "fitted_df.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smt.STL(fitted_df[\"Probabilities\"], period=365).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(40, 20))\n",
    "sns.lineplot(data=result.observed, ax=axs[0])\n",
    "sns.lineplot(data=result.trend, ax=axs[1])\n",
    "sns.lineplot(data=result.seasonal, ax=axs[2])\n",
    "sns.lineplot(data=result.resid, ax=axs[3])\n",
    "fig.suptitle(feature)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities with other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in full_df.columns.difference(\n",
    "    [\"DateTime\", \"is_outlier\", \"Year\", \"Timestamp\", \"Absorbance 254nm\"]\n",
    "):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(30, 15))\n",
    "\n",
    "    sns.lineplot(x=\"DateTime\", y=feature, data=full_df, ax=axs[0])\n",
    "    sns.lineplot(\n",
    "        x=full_df[\"DateTime\"], y=results.fittedvalues.values, ax=axs[1]\n",
    "    )\n",
    "\n",
    "    # plot vertical lines for the years on the entire plot\n",
    "    for year in full_df[\"DateTime\"].dt.year.unique():\n",
    "        for ax in axs:\n",
    "            ax.axvline(\n",
    "                pd.to_datetime(str(year)), color=\"gray\", linestyle=\"--\"\n",
    "            )\n",
    "\n",
    "    # compute spearman correlation between the feature and the fitted values\n",
    "    spearman_correlation = full_df[feature].corr(\n",
    "        results.fittedvalues, method=\"spearman\"\n",
    "    )\n",
    "    axs[0].set_title(\n",
    "        f\"{feature} - Spearman Correlation: {spearman_correlation.round(3)}\"\n",
    "    )\n",
    "\n",
    "    plt.savefig(os.path.join(probabilities_folder, f\"{feature}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_df = full_df[\n",
    "    [\n",
    "        \"DateTime\",\n",
    "        \"Year\",\n",
    "        \"Timestamp\",\n",
    "        \"UVA254\",\n",
    "        \"Air Temperature (C)\",\n",
    "        \"Daily Cumulated Rainfall (L/m)\",\n",
    "        \"Flow River (m/s)\",\n",
    "        \"Water Temperature (C)\",\n",
    "        \"is_outlier\",\n",
    "    ]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_df = projections_df[\n",
    "    [\"DateTime\", \"Air Temperature (C)\", \"is_outlier\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change is_outlier to Outlier if True else to Regular\n",
    "air_temp_df[\"is_outlier\"] = air_temp_df[\"is_outlier\"].map(\n",
    "    {0: \"UVA254 Regular\", 1: \"UVA254 Peak\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of air temp based on is outlier\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"is_outlier\",\n",
    "    y=\"Air Temperature (C)\",\n",
    "    data=air_temp_df,\n",
    "    palette=colors,\n",
    "    hue=\"is_outlier\",\n",
    ")\n",
    "\n",
    "# put count per category\n",
    "outlier_count = air_temp_df[\"is_outlier\"].value_counts()\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"N Regulars: {outlier_count.iloc[0]}\",\n",
    "        f\"N Peaks: {outlier_count.iloc[1]}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# add text to boxplot\n",
    "plt.text(\n",
    "    0.7,\n",
    "    0.95,\n",
    "    text_string,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=26,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same but with a hist with kde\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "for category in np.sort(air_temp_df[\"is_outlier\"].unique()):\n",
    "    color = colors.pop()\n",
    "\n",
    "    category_df = air_temp_df[air_temp_df[\"is_outlier\"] == category]\n",
    "    # sns.histplot(\n",
    "    #     category_df[\"Air Temperature (C)\"],\n",
    "    #     label=category,\n",
    "    #     kde=True,\n",
    "    #     color=color,\n",
    "    #     stat=\"density\",\n",
    "    # )\n",
    "    sns.kdeplot(\n",
    "        category_df[\"Air Temperature (C)\"],\n",
    "        color=color,\n",
    "        label=category,\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Calculate the mean and variance\n",
    "    mean = category_df[\"Air Temperature (C)\"].mean()\n",
    "    variance = category_df[\"Air Temperature (C)\"].var()\n",
    "\n",
    "    # Plot the mean\n",
    "    plt.axvline(mean, color=color, linestyle=\"--\")\n",
    "\n",
    "    # Plot the variance as a shaded region\n",
    "    plt.fill_betweenx(\n",
    "        [0, plt.gca().get_ylim()[1]],\n",
    "        mean - np.sqrt(variance),\n",
    "        mean + np.sqrt(variance),\n",
    "        color=color,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "plt.title(\"Air Temperature (C) vs UVA254\")\n",
    "plt.xlabel(\"Air Temperature (C)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = projections_df[\n",
    "    [\"DateTime\", \"Daily Cumulated Rainfall (L/m)\", \"is_outlier\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change is_outlier to Outlier if True else to Regular\n",
    "rainfall_df[\"is_outlier\"] = rainfall_df[\"is_outlier\"].map(\n",
    "    {0: \"UVA254 Regular\", 1: \"UVA254 Peak\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = rainfall_df[\n",
    "    rainfall_df[\"Daily Cumulated Rainfall (L/m)\"] > 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of air temp based on is outlier\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"is_outlier\",\n",
    "    y=\"Daily Cumulated Rainfall (L/m)\",\n",
    "    data=rainfall_df[\n",
    "        (rainfall_df[\"Daily Cumulated Rainfall (L/m)\"] > 0)\n",
    "        & (rainfall_df[\"Daily Cumulated Rainfall (L/m)\"] < 30)\n",
    "    ],\n",
    "    palette=colors,\n",
    ")\n",
    "\n",
    "# put count per category\n",
    "outlier_count = rainfall_df[\"is_outlier\"].value_counts()\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"N Regulars: {outlier_count.iloc[0]}\",\n",
    "        f\"N Peaks: {outlier_count.iloc[1]}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# add text to boxplot\n",
    "plt.text(\n",
    "    0.7,\n",
    "    0.95,\n",
    "    text_string,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=26,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Type\")\n",
    "plt.ylabel(\"Rainfall (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same but with a hist with kde\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "for category in np.sort(rainfall_df[\"is_outlier\"].unique()):\n",
    "    color = colors.pop()\n",
    "\n",
    "    category_df = rainfall_df[rainfall_df[\"is_outlier\"] == category]\n",
    "    # sns.histplot(\n",
    "    #     category_df[\"Daily Cumulated Rainfall (L/m)\"],\n",
    "    #     label=category,\n",
    "    #     kde=True,\n",
    "    #     color=color,\n",
    "    #     stat=\"density\",\n",
    "    # )\n",
    "    sns.kdeplot(\n",
    "        category_df[\"Daily Cumulated Rainfall (L/m)\"],\n",
    "        color=color,\n",
    "        label=category,\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Calculate the mean and variance\n",
    "    mean = category_df[\"Daily Cumulated Rainfall (L/m)\"].mean()\n",
    "    variance = category_df[\"Daily Cumulated Rainfall (L/m)\"].var()\n",
    "\n",
    "    # Plot the mean\n",
    "    plt.axvline(mean, color=color, linestyle=\"--\")\n",
    "\n",
    "    # Plot the variance as a shaded region\n",
    "    plt.fill_betweenx(\n",
    "        [0, plt.gca().get_ylim()[1]],\n",
    "        mean - np.sqrt(variance),\n",
    "        mean + np.sqrt(variance),\n",
    "        color=color,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "plt.title(\"Daily Cumulated Rainfall (mm) vs UVA254\")\n",
    "plt.xlabel(\"Daily Cumulated Rainfall (mm)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = projections_df[\n",
    "    [\"DateTime\", \"Flow River (m/s)\", \"is_outlier\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change is_outlier to Outlier if True else to Regular\n",
    "flow_df[\"is_outlier\"] = flow_df[\"is_outlier\"].map(\n",
    "    {0: \"UVA254 Regular\", 1: \"UVA254 Peak\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of air temp based on is outlier\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"is_outlier\", y=\"Flow River (m/s)\", data=flow_df, palette=colors\n",
    ")\n",
    "\n",
    "# put count per category\n",
    "outlier_count = flow_df[\"is_outlier\"].value_counts()\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"N Regulars: {outlier_count.iloc[0]}\",\n",
    "        f\"N Peaks: {outlier_count.iloc[1]}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# add text to boxplot\n",
    "plt.text(\n",
    "    0.3,\n",
    "    0.95,\n",
    "    text_string,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=26,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same but with a hist with kde\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "for category in np.sort(flow_df[\"is_outlier\"].unique()):\n",
    "    color = colors.pop()\n",
    "\n",
    "    category_df = flow_df[flow_df[\"is_outlier\"] == category]\n",
    "    # sns.histplot(\n",
    "    #     category_df[\"Flow River (m/s)\"],\n",
    "    #     label=category,\n",
    "    #     kde=True,\n",
    "    #     color=color,\n",
    "    #     stat=\"density\",\n",
    "    # )\n",
    "    sns.kdeplot(\n",
    "        category_df[\"Flow River (m/s)\"],\n",
    "        color=color,\n",
    "        label=category,\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Calculate the mean and variance\n",
    "    mean = category_df[\"Flow River (m/s)\"].mean()\n",
    "    variance = category_df[\"Flow River (m/s)\"].var()\n",
    "\n",
    "    # Plot the mean\n",
    "    plt.axvline(mean, color=color, linestyle=\"--\")\n",
    "\n",
    "    # Plot the variance as a shaded region\n",
    "    plt.fill_betweenx(\n",
    "        [0, plt.gca().get_ylim()[1]],\n",
    "        mean - np.sqrt(variance),\n",
    "        mean + np.sqrt(variance),\n",
    "        color=color,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "plt.title(\"Flow River (m/s) vs UVA254\")\n",
    "plt.xlabel(\"Flow River (m/s)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_temp_df = projections_df[\n",
    "    [\"DateTime\", \"Water Temperature (C)\", \"is_outlier\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change is_outlier to Outlier if True else to Regular\n",
    "water_temp_df[\"is_outlier\"] = water_temp_df[\"is_outlier\"].map(\n",
    "    {0: \"UVA254 Regular\", 1: \"UVA254 Peak\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of air temp based on is outlier\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"is_outlier\",\n",
    "    y=\"Water Temperature (C)\",\n",
    "    data=water_temp_df,\n",
    "    palette=colors,\n",
    ")\n",
    "\n",
    "# put count per category\n",
    "outlier_count = water_temp_df[\"is_outlier\"].value_counts()\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"N Regulars: {outlier_count.iloc[0]}\",\n",
    "        f\"N Peaks: {outlier_count.iloc[1]}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# add text to boxplot\n",
    "plt.text(\n",
    "    0.7,\n",
    "    0.95,\n",
    "    text_string,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=26,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same but with a hist with kde\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "colors = [\"g\", \"b\"]\n",
    "\n",
    "for category in np.sort(water_temp_df[\"is_outlier\"].unique()):\n",
    "    color = colors.pop()\n",
    "\n",
    "    category_df = water_temp_df[water_temp_df[\"is_outlier\"] == category]\n",
    "    # sns.histplot(\n",
    "    #     category_df[\"Water Temperature (C)\"],\n",
    "    #     label=category,\n",
    "    #     kde=True,\n",
    "    #     color=color,\n",
    "    #     stat=\"density\",\n",
    "    # )\n",
    "    sns.kdeplot(\n",
    "        category_df[\"Water Temperature (C)\"],\n",
    "        color=color,\n",
    "        label=category,\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Calculate the mean and variance\n",
    "    mean = category_df[\"Water Temperature (C)\"].mean()\n",
    "    variance = category_df[\"Water Temperature (C)\"].var()\n",
    "\n",
    "    # Plot the mean\n",
    "    plt.axvline(mean, color=color, linestyle=\"--\")\n",
    "\n",
    "    # Plot the variance as a shaded region\n",
    "    plt.fill_betweenx(\n",
    "        [0, plt.gca().get_ylim()[1]],\n",
    "        mean - np.sqrt(variance),\n",
    "        mean + np.sqrt(variance),\n",
    "        color=color,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "plt.title(\"Water Temperature (C) vs UVA254\")\n",
    "plt.xlabel(\"Water Temperature (C)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
