{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import statsmodels.tsa.seasonal as smt\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests, kpss\n",
    "\n",
    "import pymannkendall as mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "plt.rcParams.update({\"font.size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"data\", \"tarragona\")\n",
    "\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")\n",
    "\n",
    "correlation_folder = os.path.join(data_folder, \"correlation_timeseries\")\n",
    "\n",
    "variation_folder = os.path.join(data_folder, \"daily_variation_by_year\")\n",
    "\n",
    "trend_folder = os.path.join(data_folder, \"trend\")\n",
    "\n",
    "paper_plot_folder = os.path.join(\"..\", \"..\", \"paper plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"tortosa.xlsx\")\n",
    ")\n",
    "guiamets_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"guiamets.xlsx\")\n",
    ")\n",
    "mequinenza_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"mequinenza.xlsx\")\n",
    ")\n",
    "xerta_df = pd.read_excel(os.path.join(clean_data_folder, \"xerta.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same time period for all data\n",
    "min_date = max(\n",
    "    tortosa_df[\"DateTime\"].min(),\n",
    "    guiamets_df[\"DateTime\"].min(),\n",
    "    mequinenza_df[\"DateTime\"].min(),\n",
    "    xerta_df[\"DateTime\"].min(),\n",
    ")\n",
    "max_date = min(\n",
    "    tortosa_df[\"DateTime\"].max(),\n",
    "    guiamets_df[\"DateTime\"].max(),\n",
    "    mequinenza_df[\"DateTime\"].max(),\n",
    "    xerta_df[\"DateTime\"].max(),\n",
    ")\n",
    "\n",
    "tortosa_df = tortosa_df[\n",
    "    (tortosa_df[\"DateTime\"] >= min_date)\n",
    "    & (tortosa_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "guiamets_df = guiamets_df[\n",
    "    (guiamets_df[\"DateTime\"] >= min_date)\n",
    "    & (guiamets_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "mequinenza_df = mequinenza_df[\n",
    "    (mequinenza_df[\"DateTime\"] >= min_date)\n",
    "    & (mequinenza_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "xerta_df = xerta_df[\n",
    "    (xerta_df[\"DateTime\"] >= min_date)\n",
    "    & (xerta_df[\"DateTime\"] <= max_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare common variables\n",
    "\n",
    "Common variables are:\n",
    "* cumulated_rainfall_24h\n",
    "* watertemperature\n",
    "* conductivity\n",
    "\n",
    "The idea is to combine every variable in a single dataset, which in this case is the Xerta dataset, firstly by comparing the redundant variables between each site and secondly by merging the selected variables into the Xerta df.\n",
    "\n",
    "To compare common variables, the same time period must be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulated Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"cumulated_rainfall_24h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# get common datetimes where both tortosa_df and guiamets_df have positive values\n",
    "common_datetimes = tortosa_df[\n",
    "    (tortosa_df[common_variable] > 0)\n",
    "    & (guiamets_df[common_variable] > 0)\n",
    "][\"DateTime\"]\n",
    "\n",
    "tortosa_df = tortosa_df[\n",
    "    tortosa_df[\"DateTime\"].isin(common_datetimes)\n",
    "].sort_values(\"DateTime\")\n",
    "\n",
    "guiamets_df = guiamets_df[\n",
    "    guiamets_df[\"DateTime\"].isin(common_datetimes)\n",
    "].sort_values(\"DateTime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=guiamets_df, label=\"Guiamets\"\n",
    ")\n",
    "# sns.lineplot(\n",
    "#     x=\"DateTime\",\n",
    "#     y=common_variable,\n",
    "#     data=mequinenza_df,\n",
    "#     label=\"Mequinenza\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(\n",
    "    tortosa_df[common_variable],\n",
    "    mequinenza_df[common_variable],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable],\n",
    "    guiamets_df[common_variable],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mequinenza - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(\n",
    "    mequinenza_df[common_variable], guiamets_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    tortosa_df[common_variable].values.reshape(1, -1),\n",
    "    mequinenza_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    tortosa_df[common_variable].values.reshape(1, -1),\n",
    "    guiamets_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mequinenza - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    mequinenza_df[common_variable].values.reshape(1, -1),\n",
    "    guiamets_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], mequinenza_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / np.std(tortosa_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], guiamets_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / np.std(tortosa_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall-Tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(\n",
    "    tortosa_df[common_variable], mequinenza_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(\n",
    "    tortosa_df[common_variable], guiamets_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mequinenza - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(\n",
    "    mequinenza_df[common_variable], guiamets_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=guiamets_df, label=\"Guiamets\"\n",
    ")\n",
    "# sns.lineplot(\n",
    "#     x=\"DateTime\",\n",
    "#     y=common_variable,\n",
    "#     data=mequinenza_df,\n",
    "#     label=\"Mequinenza\",\n",
    "# )\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.2f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[0],\n",
    "    85,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Daily Cumulated Rainfall (mm)\")\n",
    "plt.title(\"Daily Cumulated Rainfall: Tortosa vs Guiamets\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"watertemperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, p_value = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "# add textbox with correlation value\n",
    "text_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Pearson correlation = {value:.4f}\",\n",
    "        f\"P-value = {p_value:.4f}\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "# plt.text(\n",
    "#     xerta_df[\"DateTime\"].iloc[60],\n",
    "#     29,\n",
    "#     s=text_string,\n",
    "#     fontsize=12,\n",
    "#     bbox=props,\n",
    "# )\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Water temperature (°C)\")\n",
    "plt.title(\"Water temperature: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    tortosa_df[common_variable].values.reshape(1, -1),\n",
    "    xerta_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], xerta_df[common_variable]\n",
    "    )\n",
    ")\n",
    "# rmse = rmse / np.std(tortosa_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall-Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(tortosa_df[common_variable], xerta_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.3f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[60],\n",
    "    29,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Water temperature (°C)\")\n",
    "plt.title(\"Water temperature: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"conductivity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Conductivity (µS/cm)\")\n",
    "plt.title(\"Conductivity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    tortosa_df[common_variable].values.reshape(1, -1),\n",
    "    xerta_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], xerta_df[common_variable]\n",
    "    )\n",
    ")\n",
    "# rmse = rmse / np.std(tortosa_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall-Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(tortosa_df[common_variable], xerta_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.3f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[0],\n",
    "    1800,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Conductivity (µS/cm)\")\n",
    "plt.title(\"Conductivity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"turbidity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Turbidity (NTU)\")\n",
    "plt.title(\"Turbidity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.cosine_similarity(\n",
    "    tortosa_df[common_variable].values.reshape(1, -1),\n",
    "    xerta_df[common_variable].values.reshape(1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], xerta_df[common_variable]\n",
    "    )\n",
    ")\n",
    "# rmse / np.std(tortosa_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall-Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(tortosa_df[common_variable], xerta_df[common_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.3f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[0],\n",
    "    143,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Turbidity (NTU)\")\n",
    "plt.title(\"Turbidity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variables = {\n",
    "    \"conductivity\": \"Conductivity\\n(µS/cm)\",\n",
    "    \"turbidity\": \"Turbidity\\n(NTU)\",\n",
    "    \"watertemperature\": \"Water Temperature\\n(°C)\",\n",
    "}\n",
    "# rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort columns\n",
    "tortosa_corr = tortosa_df[tortosa_df.columns.difference([\"DateTime\"])][\n",
    "    common_variables.keys()\n",
    "].corr()\n",
    "xerta_corr = xerta_df[xerta_df.columns.difference([\"DateTime\"])][\n",
    "    common_variables.keys()\n",
    "].corr()\n",
    "\n",
    "# rename columns to common_variables values\n",
    "tortosa_corr = tortosa_corr.rename(\n",
    "    columns=common_variables, index=common_variables\n",
    ")\n",
    "xerta_corr = xerta_corr.rename(\n",
    "    columns=common_variables, index=common_variables\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "sns.heatmap(tortosa_corr, annot=True, cmap=\"coolwarm\", ax=ax[0])\n",
    "ax[0].set_title(\"Tortosa\")\n",
    "\n",
    "# center the axis label\n",
    "\n",
    "sns.heatmap(xerta_corr, annot=True, cmap=\"coolwarm\", ax=ax[1])\n",
    "ax[1].set_title(\"Xerta\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build unique dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# water temperature and conductivity are better in the xerta dataset so no need to merge with tortosa\n",
    "\n",
    "# I decided to take the rainfall from tortosa since it is the closest to the xerta station\n",
    "\n",
    "xerta_df[\"cumulated_rainfall_24h\"] = tortosa_df[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "].values\n",
    "xerta_df[\"environment_temperature\"] = guiamets_df[\n",
    "    \"environmental_temperature\"\n",
    "].values\n",
    "xerta_df[\"flowriver\"] = tortosa_df[\"flowriver\"].values\n",
    "\n",
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"cumulated_rainfall_24h\": \"Daily Cumulated Rainfall\",\n",
    "        \"watertemperature\": \"Water Temperature\",\n",
    "        \"environment_temperature\": \"Air Temperature\",\n",
    "        \"flowriver\": \"Flow River\",\n",
    "        \"conductivity\": \"Conductivity\",\n",
    "        \"dissolvedoxygen\": \"Dissolved Oxygen\",\n",
    "        \"nitrate\": \"Nitrate\",\n",
    "        \"redoxpotential\": \"Redox Potential\",\n",
    "        \"turbidity\": \"Turbidity\",\n",
    "        \"Ammonium\": \"Ammonium\",\n",
    "        \"ABS254\": \"Absorbance 254nm\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first 3 rows of xerta_df since they are the only rows for august 2012\n",
    "xerta_df = xerta_df.iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unit of measurement to the columns\n",
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"Daily Cumulated Rainfall\": \"Daily Cumulated Rainfall (L/m²)\",\n",
    "        \"Water Temperature\": \"Water Temperature (°C)\",\n",
    "        \"Air Temperature\": \"Air Temperature (°C)\",\n",
    "        \"Flow River\": \"Flow River (m³/s)\",\n",
    "        \"Conductivity\": \"Conductivity (µS/cm)\",\n",
    "        \"Dissolved Oxygen\": \"Dissolved Oxygen (mg/L)\",\n",
    "        \"Nitrate\": \"Nitrate (mg/L)\",\n",
    "        \"Redox Potential\": \"Redox Potential (mV)\",\n",
    "        \"Turbidity\": \"Turbidity (NTU)\",\n",
    "        \"Ammonium\": \"Ammonium (mg/L)\",\n",
    "        \"Absorbance 254nm\": \"UVA254\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.to_excel(os.path.join(clean_data_folder, \"full_dataset.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an info dataframe to store the information about the dataset\n",
    "info_df = pd.DataFrame(\n",
    "    index=pd.Index(\n",
    "        [\n",
    "            \"N Samples\",\n",
    "            \"% Missing Values\",\n",
    "            \"Frequency (days)\",\n",
    "            \"Mean\",\n",
    "            \"Std\",\n",
    "            \"Start Date\",\n",
    "            \"End Date\",\n",
    "        ],\n",
    "        name=\"Info\",\n",
    "    ),\n",
    "    columns=xerta_df.columns,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the information in the station_info_df\n",
    "for column in xerta_df.columns:\n",
    "    df = xerta_df[column].copy()\n",
    "\n",
    "    start_date = df.dropna().index.min().strftime(\"%Y-%m-%d\")\n",
    "    end_date = df.dropna().index.max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = df[start_date:end_date]\n",
    "\n",
    "    missing_values = df.isna().sum() / df.shape[0] * 100\n",
    "\n",
    "    info_df.loc[\"N Samples\", column] = (\n",
    "        xerta_df[column].dropna().shape[0]\n",
    "    )\n",
    "    info_df.loc[\n",
    "        \"% Missing Values\", column\n",
    "    ] = missing_values\n",
    "    info_df.loc[\"Frequency (days)\", column] = (\n",
    "        xerta_df.index.to_series().diff().value_counts().index[0].days\n",
    "    )\n",
    "    \n",
    "    info_df.loc[\"Mean\",  column] = df.mean()\n",
    "    info_df.loc[\"Std\", column] = df.std()\n",
    "    \n",
    "    info_df.loc[\"Start Date\", column] = start_date\n",
    "    info_df.loc[\"End Date\", column] = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.to_excel(os.path.join(clean_data_folder, \"info.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall timeseries decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = xerta_df.index.min()\n",
    "max_date = xerta_df.index.max()\n",
    "\n",
    "print(\"Min date:\", min_date)\n",
    "print(\"Max date:\", max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute time difference between min and max date of the dataset in years\n",
    "time_diff = xerta_df.index.max() - xerta_df.index.min()\n",
    "time_diff.total_seconds() / (60 * 60 * 24 * 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    result = smt.STL(xerta_df[feature], period=365).fit()\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(40, 20))\n",
    "    sns.lineplot(data=result.observed, ax=axs[0])\n",
    "    sns.lineplot(data=result.trend, ax=axs[1])\n",
    "    sns.lineplot(data=result.seasonal, ax=axs[2])\n",
    "    sns.lineplot(data=result.resid, ax=axs[3])\n",
    "    fig.suptitle(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly Seasonal Decomposition\n",
    "\n",
    "Every variables seems to have a yearly seasonal component, so the analysis is performed year-by-year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df[\"month\"] = xerta_df.index.month\n",
    "xerta_df[\"year\"] = xerta_df.index.year\n",
    "monthly_average = xerta_df.groupby([\"year\", \"month\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_average.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_average[\"DateTime\"] = pd.to_datetime(\n",
    "    monthly_average[[\"year\", \"month\"]].assign(day=1)\n",
    ")\n",
    "monthly_average.drop(columns=[\"year\", \"month\"], inplace=True)\n",
    "monthly_average.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df = monthly_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add solar radiation data\n",
    "\n",
    "solar_radiation_df = pd.read_excel(os.path.join(clean_data_folder, \"solar_radiation.xlsx\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_radiation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change DateTime day to 1\n",
    "solar_radiation_df[\"DateTime\"] = solar_radiation_df[\"DateTime\"].apply(\n",
    "    lambda x: x.replace(day=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge xerta_df with solar_radiation_df\n",
    "\n",
    "xerta_df = pd.merge(xerta_df, solar_radiation_df, on=\"DateTime\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = (200, 2, 110)\n",
    "color = tuple(map(lambda x: x / 255, rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_results = {}\n",
    "\n",
    "\n",
    "years = xerta_df.index.year.unique()\n",
    "for year in years:\n",
    "    trend_results[year] = {}\n",
    "\n",
    "\n",
    "# year by year extrapolate the trend\n",
    "# for year in years:\n",
    "#     trend_results[year] = {}\n",
    "#     df_year = xerta_df[xerta_df.index.year == year]\n",
    "#     for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "#         result = smt.seasonal_decompose(df_year[feature], period=30)\n",
    "#         trend_results[year][feature] = result.trend.dropna()\n",
    "\n",
    "\n",
    "for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    result = smt.STL(xerta_df[feature], period=12).fit()\n",
    "    trend = result.trend.dropna()\n",
    "    for year in years:\n",
    "        trend_results[year][feature] = trend[trend.index.year == year]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xerta_df.index,\n",
    "            y=xerta_df[feature],\n",
    "            mode=\"lines\",\n",
    "            name=\"Monthly Average\",\n",
    "            line=dict(color=\"black\", width=1.0),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=trend.index,\n",
    "            y=trend,\n",
    "            mode=\"lines\",\n",
    "            name=\"Trend (Moving Average)\",\n",
    "            line=dict(color='rgb(200,2,110)', width=4.0),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{feature}\",\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=feature,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df = pd.DataFrame(trend_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Estimation with insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "linear_estimations = {}\n",
    "\n",
    "for feature, row in trends_df.iterrows():\n",
    "    linear_estimations[feature] = {}\n",
    "    for year in trends_df.columns:\n",
    "        result = sm.OLS(\n",
    "            row[year].values,\n",
    "            sm.add_constant(row[year].index.to_julian_date()),\n",
    "        ).fit()\n",
    "        # result = stats.linregress(row[year].index.to_julian_date(), row[year].values)\n",
    "        linear_estimations[feature][year] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save slope and se for each feature and year\n",
    "slopes = {}\n",
    "ses = {}\n",
    "for feature in linear_estimations:\n",
    "    slopes[feature] = {}\n",
    "    ses[feature] = {}\n",
    "    for year in linear_estimations[feature]:\n",
    "        slopes[feature][year] = (\n",
    "            linear_estimations[feature][year].params[1].round(5)\n",
    "        )\n",
    "        ses[feature][year] = (\n",
    "            linear_estimations[feature][year].bse[1].round(5)\n",
    "        )\n",
    "\n",
    "slopes_df = pd.DataFrame(slopes)\n",
    "ses_df = pd.DataFrame(ses)\n",
    "\n",
    "# create unique table where each entry is a string like 'slope +/- se'\n",
    "slope_se_df = pd.DataFrame()\n",
    "for feature in slopes_df:\n",
    "    slope_se_df[feature] = (\n",
    "        slopes_df[feature].map(str) + \" +/- \" + ses_df[feature].map(str)\n",
    "    )\n",
    "\n",
    "slope_se_df.to_excel(os.path.join(clean_data_folder, \"slope_se.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in linear_estimations.keys():\n",
    "    # for each year I have to plot the slope and the intercept with their confidence intervals\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    feature_data = {}\n",
    "    for year in linear_estimations[feature].keys():\n",
    "        result = linear_estimations[feature][year]\n",
    "        intercept, slope = result.params\n",
    "        beta_0_se, beta_1_se = result.bse\n",
    "        feature_data[year] = {\n",
    "            \"intercept\": intercept,\n",
    "            \"slope\": slope,\n",
    "            \"intercept_se\": beta_0_se,\n",
    "            \"slope_se\": beta_1_se,\n",
    "        }\n",
    "    # plot slope and intercept with their confidence intervals\n",
    "    # as if it is a boxplot\n",
    "    feature_df = pd.DataFrame(feature_data).T\n",
    "    feature_df[\"year\"] = feature_df.index\n",
    "    # add confidence intervals as error bars\n",
    "    # ax.scatter(feature_df[\"year\"], feature_df[\"slope\"], color=\"black\")\n",
    "    ax.errorbar(\n",
    "        feature_df[\"year\"],\n",
    "        feature_df[\"slope\"],\n",
    "        yerr=feature_df[\"slope_se\"] * 2,\n",
    "        color=\"red\",\n",
    "        linestyle=\"None\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=feature_df,\n",
    "        x=\"year\",\n",
    "        y=\"slope\",\n",
    "        ax=ax,\n",
    "        marker=\"o\",\n",
    "        markersize=10,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    ax.set_ylabel(\"Average Variation (unit/day)\")\n",
    "\n",
    "    # plot horizontal line at 0\n",
    "    ax.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    # add every year to the x axis\n",
    "    ax.set_xticks(feature_df[\"year\"])\n",
    "    ax.set_xticklabels(feature_df[\"year\"])\n",
    "    ax.set_xlabel(\"Year\")\n",
    "\n",
    "    plt.title(feature + \" - Daily Variation per Year\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each trend of each variable for each year\n",
    "from seaborn import color_palette\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "for index, row in trends_df.iterrows():\n",
    "    fig, ax = plt.subplots(figsize=(30, 20))\n",
    "    fig.set_facecolor(\"black\")\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    # ax.set_xticks(range(1, 13))\n",
    "    # ax.set_xticklabels(\n",
    "    #     [\n",
    "    #         \"January\",\n",
    "    #         \"February\",\n",
    "    #         \"March\",\n",
    "    #         \"April\",\n",
    "    #         \"May\",\n",
    "    #         \"June\",\n",
    "    #         \"July\",\n",
    "    #         \"August\",\n",
    "    #         \"September\",\n",
    "    #         \"October\",\n",
    "    #         \"November\",\n",
    "    #         \"December\",\n",
    "    #     ],\n",
    "    # )\n",
    "    ax.yaxis.label.set_color(\"white\")\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    ax.tick_params(axis=\"y\", colors=\"white\")\n",
    "    ax.tick_params(axis=\"x\", colors=\"white\")\n",
    "\n",
    "    for column in trends_df.columns:\n",
    "        color = color_palette(\"Set3\", trends_df.columns.size)[\n",
    "            trends_df.columns.get_loc(column)\n",
    "        ]\n",
    "        sns.lineplot(\n",
    "            # NB: month performs the mean of every month\n",
    "            # dayofyear plots every point\n",
    "            x=row[column].index.dayofyear,\n",
    "            y=row[column].values,\n",
    "            linewidth=2.0,\n",
    "            color=color,\n",
    "            # marker=\"o\",\n",
    "            # markersize=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        # Add a dotted line at the end of each line\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[0]\n",
    "        # and y_start to row[column].values[0]\n",
    "        # else x_start = row[column].index.month[0] and y_start = row[column].groupby(row[column].index.month).mean().values[0]\n",
    "\n",
    "        x_start = row[column].index.dayofyear[0]\n",
    "        y_start = row[column].values[0]\n",
    "        x_end = x_start - 1\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # start line label\n",
    "        ax.text(\n",
    "            x_end - 10,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[-1]\n",
    "        # and y_start to row[column].values[-1]\n",
    "        # else x_start = row[column].index.month[-1] and y_start = row[column].groupby(row[column].index.month).mean().values[-1]\n",
    "\n",
    "        x_start = row[column].index.dayofyear[-1]\n",
    "        y_start = row[column].values[-1]\n",
    "        x_end = x_start + 1\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # end line label\n",
    "        ax.text(\n",
    "            x_end,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Day\", color=\"white\")\n",
    "    plt.ylabel(\"Trend\", color=\"white\")\n",
    "    plt.title(str(index), fontsize=20, weight=\"bold\", color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each trend of each variable for each year\n",
    "from seaborn import color_palette\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "for index, row in trends_df.iterrows():\n",
    "    fig, ax = plt.subplots(figsize=(30, 20))\n",
    "    fig.set_facecolor(\"black\")\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"January\",\n",
    "            \"February\",\n",
    "            \"March\",\n",
    "            \"April\",\n",
    "            \"May\",\n",
    "            \"June\",\n",
    "            \"July\",\n",
    "            \"August\",\n",
    "            \"September\",\n",
    "            \"October\",\n",
    "            \"November\",\n",
    "            \"December\",\n",
    "        ],\n",
    "    )\n",
    "    ax.yaxis.label.set_color(\"white\")\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    ax.tick_params(axis=\"y\", colors=\"white\")\n",
    "    ax.tick_params(axis=\"x\", colors=\"white\")\n",
    "\n",
    "    for column in trends_df.columns:\n",
    "        color = color_palette(\"Set3\", trends_df.columns.size)[\n",
    "            trends_df.columns.get_loc(column)\n",
    "        ]\n",
    "        sns.lineplot(\n",
    "            # NB: month performs the mean of every month\n",
    "            # dayofyear plots every point\n",
    "            x=row[column].index.month,\n",
    "            y=row[column].values,\n",
    "            linewidth=2.0,\n",
    "            color=color,\n",
    "            marker=\"o\",\n",
    "            markersize=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        # Add a dotted line at the end of each line\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[0]\n",
    "        # and y_start to row[column].values[0]\n",
    "        # else x_start = row[column].index.month[0] and y_start = row[column].groupby(row[column].index.month).mean().values[0]\n",
    "\n",
    "        x_start = row[column].index.month[0]\n",
    "        y_start = (\n",
    "            row[column]\n",
    "            .groupby(row[column].index.month)\n",
    "            .mean()\n",
    "            .values[0]\n",
    "        )\n",
    "        x_end = x_start - 0.5\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # start line label\n",
    "        ax.text(\n",
    "            x_end - 0.3,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[-1]\n",
    "        # and y_start to row[column].values[-1]\n",
    "        # else x_start = row[column].index.month[-1] and y_start = row[column].groupby(row[column].index.month).mean().values[-1]\n",
    "\n",
    "        x_start = row[column].index.month[-1]\n",
    "        y_start = (\n",
    "            row[column]\n",
    "            .groupby(row[column].index.month)\n",
    "            .mean()\n",
    "            .values[-1]\n",
    "        )\n",
    "        x_end = x_start + 0.5\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # end line label\n",
    "        ax.text(\n",
    "            x_end,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Month\", color=\"white\")\n",
    "    plt.ylabel(\"Trend\", color=\"white\")\n",
    "    plt.title(str(index), fontsize=20, weight=\"bold\", color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = (200, 2, 110)\n",
    "color = tuple(map(lambda x: x / 255, rgb))\n",
    "\n",
    "for feature, row in trends_df.iterrows():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for column in trends_df.columns:\n",
    "        sns.lineplot(\n",
    "            data=row[column],\n",
    "            linewidth=4.0,\n",
    "            color=color,\n",
    "        )\n",
    "    sns.lineplot(\n",
    "        data=xerta_df[feature], linewidth=1.0, color=\"black\", alpha=0.5\n",
    "    )\n",
    "\n",
    "    # result = smt.STL(xerta_df[feature], period=365).fit()\n",
    "    # sns.lineplot(data=result.trend + 0.1, linewidth=2.0, color=\"red\")\n",
    "\n",
    "    plt.title(str(feature) + \" - Trend\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(feature)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests on trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis Test on Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise year comparison of the trends\n",
    "pairwise_kw_results = {}\n",
    "for feature, row in trends_df.iterrows():\n",
    "    pairwise_kw_results[feature] = {}\n",
    "    # compute the Kruskal-Wallis H-test for every pair of years\n",
    "    df = pd.DataFrame(\n",
    "        columns=trends_df.columns, index=trends_df.columns\n",
    "    )\n",
    "    for year1 in trends_df.columns:\n",
    "        for year2 in trends_df.columns:\n",
    "            if year1 != year2:\n",
    "                stat, p = stats.kruskal(row[year1], row[year2])\n",
    "                df.loc[year1, year2] = (stat, p)\n",
    "    pairwise_kw_results[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_kw_results[\"Water Temperature (°C)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall Kruskal-Wallis H-test for each feature\n",
    "overall_kw_results = {}\n",
    "for feature, row in trends_df.iterrows():\n",
    "    stat, p = stats.kruskal(*[row[year] for year in trends_df.columns])\n",
    "    overall_kw_results[feature] = (stat, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_kw_results_df = pd.DataFrame(overall_kw_results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dunn Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dunn_results = {}\n",
    "\n",
    "for feature, row in trends_df.iterrows():\n",
    "    result_df = sp.posthoc_dunn(row.to_list(), p_adjust=\"holm\")\n",
    "    result_df.columns = trends_df.columns\n",
    "    result_df.index = trends_df.columns\n",
    "    trend_dunn_results[feature] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in trend_dunn_results.items():\n",
    "    plt.figure(figsize=(30, 15))\n",
    "\n",
    "    # Create a mask for values > 0.05\n",
    "    mask = df <= 0.05\n",
    "\n",
    "    sns.heatmap(df, annot=True, cmap=\"coolwarm\", center=0, mask=mask)\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dunn_results = {}\n",
    "for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    # split the data for each year\n",
    "    data = []\n",
    "    for year in years:\n",
    "        data.append(xerta_df[feature][xerta_df.index.year == year])\n",
    "    result_df = sp.posthoc_dunn(data, p_adjust=\"holm\")\n",
    "    result_df.columns = years\n",
    "    result_df.index = years\n",
    "    data_dunn_results[feature] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in data_dunn_results.items():\n",
    "    plt.figure(figsize=(30, 15))\n",
    "\n",
    "    # Create a mask for values > 0.05\n",
    "    mask = df <= 0.05\n",
    "\n",
    "    sns.heatmap(df, annot=True, cmap=\"coolwarm\", center=0, mask=mask)\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Seasonal Decomposition\n",
    "\n",
    "For completeness, the analysis is performed also month-by-month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_results = {}\n",
    "\n",
    "for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    result = smt.STL(xerta_df[feature], period=365).fit()\n",
    "    trend = result.trend.dropna()\n",
    "    trend_results[feature] = {}\n",
    "    for year in years:\n",
    "        # get the months of the year\n",
    "        months = trend[trend.index.year == year].index.month.unique()\n",
    "        for month in months:\n",
    "            trend_results[feature][(year, month)] = trend[\n",
    "                (trend.index.year == year)\n",
    "                & (trend.index.month == month)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df = pd.DataFrame(trend_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each trend of each variable for each year\n",
    "from seaborn import color_palette\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "for index, row in trends_df.iterrows():\n",
    "    fig, ax = plt.subplots(figsize=(30, 20))\n",
    "    fig.set_facecolor(\"black\")\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    # ax.set_xticks(range(1, 13))\n",
    "    # ax.set_xticklabels(\n",
    "    #     [\n",
    "    #         \"January\",\n",
    "    #         \"February\",\n",
    "    #         \"March\",\n",
    "    #         \"April\",\n",
    "    #         \"May\",\n",
    "    #         \"June\",\n",
    "    #         \"July\",\n",
    "    #         \"August\",\n",
    "    #         \"September\",\n",
    "    #         \"October\",\n",
    "    #         \"November\",\n",
    "    #         \"December\",\n",
    "    #     ],\n",
    "    # )\n",
    "    ax.yaxis.label.set_color(\"white\")\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    ax.tick_params(axis=\"y\", colors=\"white\")\n",
    "    ax.tick_params(axis=\"x\", colors=\"white\")\n",
    "\n",
    "    for column in trends_df.columns:\n",
    "        color = color_palette(\"Set3\", trends_df.columns.size)[\n",
    "            trends_df.columns.get_loc(column)\n",
    "        ]\n",
    "        sns.lineplot(\n",
    "            # NB: month performs the mean of every month\n",
    "            # dayofyear plots every point\n",
    "            x=row[column].index.dayofyear,\n",
    "            y=row[column].values,\n",
    "            linewidth=2.0,\n",
    "            color=color,\n",
    "            # marker=\"o\",\n",
    "            # markersize=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        # Add a dotted line at the end of each line\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[0]\n",
    "        # and y_start to row[column].values[0]\n",
    "        # else x_start = row[column].index.month[0] and y_start = row[column].groupby(row[column].index.month).mean().values[0]\n",
    "\n",
    "        x_start = row[column].index.dayofyear[0]\n",
    "        y_start = row[column].values[0]\n",
    "        x_end = x_start - 1\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # start line label\n",
    "        ax.text(\n",
    "            x_end - 10,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[-1]\n",
    "        # and y_start to row[column].values[-1]\n",
    "        # else x_start = row[column].index.month[-1] and y_start = row[column].groupby(row[column].index.month).mean().values[-1]\n",
    "\n",
    "        x_start = row[column].index.dayofyear[-1]\n",
    "        y_start = row[column].values[-1]\n",
    "        x_end = x_start + 1\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # end line label\n",
    "        ax.text(\n",
    "            x_end,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Month\", color=\"white\")\n",
    "    plt.ylabel(\"Trend\", color=\"white\")\n",
    "    plt.title(str(index), fontsize=20, weight=\"bold\", color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each trend of each variable for each year\n",
    "from seaborn import color_palette\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "for index, row in trends_df.iterrows():\n",
    "    fig, ax = plt.subplots(figsize=(30, 20))\n",
    "    fig.set_facecolor(\"black\")\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"January\",\n",
    "            \"February\",\n",
    "            \"March\",\n",
    "            \"April\",\n",
    "            \"May\",\n",
    "            \"June\",\n",
    "            \"July\",\n",
    "            \"August\",\n",
    "            \"September\",\n",
    "            \"October\",\n",
    "            \"November\",\n",
    "            \"December\",\n",
    "        ],\n",
    "    )\n",
    "    ax.yaxis.label.set_color(\"white\")\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    ax.tick_params(axis=\"y\", colors=\"white\")\n",
    "    ax.tick_params(axis=\"x\", colors=\"white\")\n",
    "\n",
    "    for column in trends_df.columns:\n",
    "        color = color_palette(\"Set3\", trends_df.columns.size)[\n",
    "            trends_df.columns.get_loc(column)\n",
    "        ]\n",
    "        sns.lineplot(\n",
    "            # NB: month performs the mean of every month\n",
    "            # dayofyear plots every point\n",
    "            x=row[column].index.month,\n",
    "            y=row[column].values,\n",
    "            linewidth=2.0,\n",
    "            color=color,\n",
    "            marker=\"o\",\n",
    "            markersize=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        # Add a dotted line at the end of each line\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[0]\n",
    "        # and y_start to row[column].values[0]\n",
    "        # else x_start = row[column].index.month[0] and y_start = row[column].groupby(row[column].index.month).mean().values[0]\n",
    "\n",
    "        x_start = row[column].index.month[0]\n",
    "        y_start = (\n",
    "            row[column]\n",
    "            .groupby(row[column].index.month)\n",
    "            .mean()\n",
    "            .values[0]\n",
    "        )\n",
    "        x_end = x_start - 0.5\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # start line label\n",
    "        ax.text(\n",
    "            x_end - 0.3,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        # NB: if dayofyear, change x_start to row[column].index.dayofyear[-1]\n",
    "        # and y_start to row[column].values[-1]\n",
    "        # else x_start = row[column].index.month[-1] and y_start = row[column].groupby(row[column].index.month).mean().values[-1]\n",
    "\n",
    "        x_start = row[column].index.month[-1]\n",
    "        y_start = (\n",
    "            row[column]\n",
    "            .groupby(row[column].index.month)\n",
    "            .mean()\n",
    "            .values[-1]\n",
    "        )\n",
    "        x_end = x_start + 0.5\n",
    "        y_end = y_start\n",
    "        ax.plot(\n",
    "            [x_start, x_end],\n",
    "            [y_start, y_end],\n",
    "            \"--\",\n",
    "            color=color,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        # end line label\n",
    "        ax.text(\n",
    "            x_end,\n",
    "            y_end,\n",
    "            str(column),\n",
    "            color=color,\n",
    "            fontsize=14,\n",
    "            weight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Month\", color=\"white\")\n",
    "    plt.ylabel(\"Trend\", color=\"white\")\n",
    "    plt.title(str(index), fontsize=20, weight=\"bold\", color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, row in trends_df.iterrows():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for column in trends_df.columns:\n",
    "        sns.lineplot(\n",
    "            data=row[column],\n",
    "            linewidth=2.0,\n",
    "            color=\"red\",\n",
    "        )\n",
    "    sns.lineplot(data=xerta_df[feature], linewidth=2.0, color=\"blue\")\n",
    "\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests on trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis Test on Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise year comparison of the trends\n",
    "pairwise_kw_results = {}\n",
    "for feature, row in trends_df.iterrows():\n",
    "    pairwise_kw_results[feature] = {}\n",
    "    # compute the Kruskal-Wallis H-test for every pair of years\n",
    "    df = pd.DataFrame(\n",
    "        columns=trends_df.columns, index=trends_df.columns\n",
    "    )\n",
    "    for year1 in trends_df.columns:\n",
    "        for year2 in trends_df.columns:\n",
    "            if year1 != year2:\n",
    "                stat, p = stats.kruskal(row[year1], row[year2])\n",
    "                df.loc[year1, year2] = (stat, p)\n",
    "    pairwise_kw_results[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_kw_results[\"Water Temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall Kruskal-Wallis H-test for each feature\n",
    "overall_kw_results = {}\n",
    "for feature, row in trends_df.iterrows():\n",
    "    stat, p = stats.kruskal(*[row[year] for year in trends_df.columns])\n",
    "    overall_kw_results[feature] = (stat, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_kw_results_df = pd.DataFrame(overall_kw_results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dunn Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dunn_results = {}\n",
    "\n",
    "for feature, row in trends_df.iterrows():\n",
    "    result_df = sp.posthoc_dunn(row.to_list(), p_adjust=\"holm\")\n",
    "    result_df.columns = trends_df.columns\n",
    "    result_df.index = trends_df.columns\n",
    "    trend_dunn_results[feature] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dunn_results[\"ABS254\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in trend_dunn_results.items():\n",
    "    plt.figure(figsize=(30, 15))\n",
    "\n",
    "    # Create a mask for values > 0.05\n",
    "    mask = df <= 0.05\n",
    "\n",
    "    sns.heatmap(df, annot=True, cmap=\"coolwarm\", center=0, mask=mask)\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dunn_results = {}\n",
    "for feature in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    # split the data for each year\n",
    "    data = []\n",
    "    for year in years:\n",
    "        data.append(xerta_df[feature][xerta_df.index.year == year])\n",
    "    result_df = sp.posthoc_dunn(data, p_adjust=\"holm\")\n",
    "    result_df.columns = years\n",
    "    result_df.index = years\n",
    "    data_dunn_results[feature] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dunn_results[\"ABS254\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in data_dunn_results.items():\n",
    "    plt.figure(figsize=(30, 15))\n",
    "\n",
    "    # Create a mask for values > 0.05\n",
    "    mask = df <= 0.05\n",
    "\n",
    "    sns.heatmap(df, annot=True, cmap=\"coolwarm\", center=0, mask=mask)\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition of diff timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_diff_df = xerta_df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in xerta_diff_df.columns.difference([\"DateTime\"]):\n",
    "    result = smt.STL(xerta_diff_df[feature], period=365).fit()\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(40, 20))\n",
    "    sns.lineplot(data=result.observed, ax=axs[0])\n",
    "    sns.lineplot(data=result.trend, ax=axs[1])\n",
    "    sns.lineplot(data=result.seasonal, ax=axs[2])\n",
    "    sns.lineplot(data=result.resid, ax=axs[3])\n",
    "    fig.suptitle(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year by Year Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"Daily Cumulated Rainfall (L/m²)\": \"Daily Cumulated Rainfall (mm)\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform year by year correlation\n",
    "correlation_results = {}\n",
    "\n",
    "for year in xerta_df.index.year.unique():\n",
    "    correlation_results[year] = {}\n",
    "    year_df = xerta_df[xerta_df.index.year == year]\n",
    "    variable_names = year_df.columns.difference([\"DateTime\"]).to_list()\n",
    "    corr_matrix = stats.spearmanr(year_df)\n",
    "    corr_matrix = pd.DataFrame(\n",
    "        corr_matrix.correlation,\n",
    "        columns=variable_names,\n",
    "        index=variable_names,\n",
    "    )\n",
    "    correlation_results[year] = corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in correlation_results.items():\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    sns.heatmap(df, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Coefficients Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each variable, create a plot with the year by year correlation with the other variables\n",
    "for variable in xerta_df.columns.difference([\"DateTime\"]):\n",
    "    # store the correlation of the variable with the other variables\n",
    "    other_variables = {}\n",
    "\n",
    "    for year, df in correlation_results.items():\n",
    "        # take the correlation of the variable with the other variables\n",
    "        correlation = df[variable].drop(variable)\n",
    "\n",
    "        for other_variable, value in correlation.items():\n",
    "            if other_variable not in other_variables:\n",
    "                other_variables[other_variable] = []\n",
    "            # append every year\n",
    "            other_variables[other_variable].append(value)\n",
    "\n",
    "    # plot the correlation of the variable with the other variables\n",
    "    for other_variable, values in other_variables.items():\n",
    "        plt.figure(figsize=(30, 15))\n",
    "        sns.lineplot(\n",
    "            x=years,\n",
    "            y=values,\n",
    "            label=other_variable,\n",
    "            marker=\"o\",\n",
    "            markersize=10,\n",
    "            linewidth=2.0,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "        # plot horizontal line at 0\n",
    "        plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Spearman Correlation Coefficient\")\n",
    "        plt.title(variable + \" - \" + \"Spearman Correlation by Year\")\n",
    "        # increase the x axis year ticks\n",
    "        plt.xticks(years)\n",
    "\n",
    "        # # save the plot to the correlation folder\n",
    "        # if not os.path.exists(os.path.join(correlation_folder, variable)):\n",
    "        #     os.makedirs(os.path.join(correlation_folder, variable))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = os.path.join(data_folder, \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xerta_df = pd.read_excel(\n",
    "#     os.path.join(raw_data_folder, \"raw_full_dataset.xlsx\"), index_col=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each variable, create a plot with the year by year correlation with the other variables\n",
    "variable = \"UVA254\"\n",
    "# store the correlation of the variable with the other variables\n",
    "other_variables = {}\n",
    "\n",
    "skip_variables = [\n",
    "    \"pH\",\n",
    "    \"Ammonium (mg/L)\",\n",
    "    \"Conductivity (µS/cm)\",\n",
    "    \"Dissolved Oxygen (mg/L)\",\n",
    "    \"Nitrate (mg/L)\",\n",
    "    \"Redox Potential (mV)\",\n",
    "    \"Turbidity (NTU)\",\n",
    "    \"Conductivity (µS/cm)\",\n",
    "    \"Nitrate (mg/L)\",\n",
    "]\n",
    "\n",
    "for year, df in correlation_results.items():\n",
    "    # take the correlation of the variable with the other variables\n",
    "    correlation = df[variable].drop(variable)\n",
    "\n",
    "    for other_variable, value in correlation.items():\n",
    "        if other_variable not in skip_variables:\n",
    "            if other_variable not in other_variables:\n",
    "                other_variables[other_variable] = []\n",
    "            # append every year\n",
    "            other_variables[other_variable].append(value)\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "# plot the correlation of the variable with the other variables\n",
    "# give me 4 colors\n",
    "colors = sns.color_palette(\"Set1\", 5)\n",
    "\n",
    "for other_variable, values in other_variables.items():\n",
    "    sns.lineplot(\n",
    "        x=years,\n",
    "        y=values,\n",
    "        label=other_variable,\n",
    "        marker=\"o\",\n",
    "        markersize=10,\n",
    "        linewidth=2.0,\n",
    "        linestyle=\"--\",\n",
    "        color=colors.pop(0),\n",
    "    )\n",
    "# plot horizontal line at 0\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Spearman Correlation Coefficient\")\n",
    "plt.title(variable + \" - \" + \"Spearman Correlation by Year\")\n",
    "# increase the x axis year ticks\n",
    "plt.xticks(years)\n",
    "\n",
    "# # save the plot to the correlation folder\n",
    "# if not os.path.exists(os.path.join(correlation_folder, variable)):\n",
    "#     os.makedirs(os.path.join(correlation_folder, variable))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the solar radiation and the UVA254\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "\n",
    "scaled_uv = MinMaxScaler().fit_transform(xerta_df[\"UVA254\"].values.reshape(-1, 1))\n",
    "scaled_solar = MinMaxScaler().fit_transform(xerta_df[\"Solar Radiation (W/m^2)\"].values.reshape(-1, 1))\n",
    "\n",
    "plt.plot(xerta_df.index, scaled_uv, label=\"UVA254\")\n",
    "plt.plot(xerta_df.index, scaled_solar, label=\"Solar Radiation\")\n",
    "\n",
    "\n",
    "plt.title(\"UVA254 vs Solar Radiation\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"UVA254 and Solar Radiation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation between UVA254 and Solar Radiation\n",
    "\n",
    "# first difference the data\n",
    "xerta_diff_df = xerta_df.diff()\n",
    "\n",
    "# compute the correlation\n",
    "corr = xerta_diff_df[\"UVA254\"].corr(xerta_diff_df[\"Solar Radiation (W/m^2)\"])\n",
    "\n",
    "print(\"Correlation between UVA254 and Solar Radiation:\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot between UVA nad Ammonium with best fit line\n",
    "\n",
    "scatter_folder = os.path.join(paper_plot_folder, 'Tarragona', 'Scatters')\n",
    "\n",
    "fig = px.scatter(\n",
    "    xerta_df,\n",
    "    x=\"Ammonium (mg/L)\",\n",
    "    y=\"UVA254\",\n",
    "    trendline=\"ols\",\n",
    "    trendline_color_override=\"red\",\n",
    ")\n",
    "\n",
    "# udpate the scale of the y axis from 0 to 0.7\n",
    "# fig.update_yaxes(range=[0, 0.7])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"UVA254 vs Ammonium\",\n",
    "    xaxis_title=\"Ammonium (mg/l)\",\n",
    "    yaxis_title=\"UVA254 (1/m)\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.write_image(\n",
    "    os.path.join(scatter_folder, \"UVA254_vs_Ammonium.png\"),\n",
    "    scale=6\n",
    ")\n",
    "\n",
    "\n",
    "# compute correlation between UVA254 and Ammonium\n",
    "\n",
    "corr = xerta_df[\"UVA254\"].corr(xerta_df[\"Ammonium (mg/L)\"])\n",
    "\n",
    "print(\"Correlation between UVA254 and Ammonium:\", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one plot for each variable\n",
    "# do it just for the 305 station since it is the one used in the paper\n",
    "\n",
    "trend_folder = os.path.join(paper_plot_folder, 'Tarragona', 'Trends', 'Single')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['UVA254 (1/m)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "color = 'rgb(200,2,110)'\n",
    "\n",
    "color_mapping = {\n",
    "    'Air Temperature (°C)': colors[0],\n",
    "    'Cumulated Rainfall (mm)': colors[1],\n",
    "    'Ammonium (mg/l)': colors[2],\n",
    "    'Conductivity (µS/cm)': colors[3],\n",
    "    'Dissolved Oxygen (mg/l)': colors[4],\n",
    "    'Flow River Rate (m³/s)': colors[5],\n",
    "    'Nitrate (mg/l)': colors[6],\n",
    "    'pH': colors[7],\n",
    "    'Water Temperature (°C)': colors[8],\n",
    "    'UVA254 (1/m)': colors[9]\n",
    "}\n",
    "\n",
    "station_df = xerta_df.copy()\n",
    "\n",
    "station_df.rename(\n",
    "    columns={\n",
    "        \"UVA254\": \"UVA254 (1/m)\",\n",
    "        \"Ammonium (mg/L)\": \"Ammonium (mg/l)\",\n",
    "        \"Daily Cumulated Rainfall (mm)\": \"Cumulated Rainfall (mm)\",\n",
    "        \"Flow River (m³/s)\": \"Flow River Rate (m³/s)\",\n",
    "        \"Dissolved Oxygen (mg/L)\": \"Dissolved Oxygen (mg/l)\",\n",
    "        \"Nitrate (mg/L)\": \"Nitrate (mg/l)\",\n",
    "        \n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'ds': station_df.index,\n",
    "        'y': station_df[column]\n",
    "    })\n",
    "    \n",
    "    model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(df)\n",
    "    # Make predictions for both columns\n",
    "    future = model.make_future_dataframe(periods=0)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=station_df.index,\n",
    "            y=station_df[column],\n",
    "            mode='lines',\n",
    "            name=column,\n",
    "            line=dict(\n",
    "                color=color_mapping[column],\n",
    "                width=1.5\n",
    "            ),\n",
    "            showlegend=False\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast['ds'],\n",
    "            y=forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "            showlegend=False, # change to trend_show if you want to show the legend\n",
    "            legendrank=np.inf\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "        \n",
    "    # fig.update_yaxes(title_text=column)\n",
    "    \n",
    "    if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "        fig.update_yaxes(range=[0, 0.7])\n",
    "    \n",
    "    if column == 'Air Temperature (°C)':\n",
    "        fig.update_yaxes(range=[-10, 30])\n",
    "    \n",
    "    if column == 'Cumulated Rainfall (mm)':\n",
    "        fig.update_yaxes(range=[0, 8])\n",
    "        \n",
    "    # if column == 'Conductivity (µS/cm)':\n",
    "    #     fig.update_yaxes(range=[0, 1700])\n",
    "    \n",
    "    # if column == 'Nitrate (mg/l)':\n",
    "    #     fig.update_yaxes(range=[0, 20])\n",
    "    \n",
    "    if column == 'pH':\n",
    "        fig.update_yaxes(range=[7.6, 8.8])\n",
    "    \n",
    "    if column == 'Water Temperature (°C)':\n",
    "        fig.update_yaxes(range=[0, 30])\n",
    "        \n",
    "    # if column == 'Flow River Rate (m³/s)':\n",
    "    #     fig.update_yaxes(range=[0, 1300])\n",
    "        \n",
    "    if column == 'Dissolved Oxygen (mg/l)':\n",
    "        fig.update_yaxes(range=[4, 18])\n",
    "\n",
    "\n",
    "    start_year = station_df.index.year.min()\n",
    "    end_year = station_df.index.year.max()\n",
    "    tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "    ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "\n",
    "    fig.update_xaxes(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        title_text=\"Time\"\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=column)  \n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='Tarragona',\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "        ),\n",
    "        legend=dict(\n",
    "            traceorder='normal',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    #reduce the font size of the subplot titles\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=8)\n",
    "\n",
    "    \n",
    "    column_ = column.replace(\"/\", \"_\")\n",
    "\n",
    "    fig.write_image(\n",
    "        os.path.join(trend_folder, f\"{column_}.png\"),\n",
    "        scale=10,\n",
    "    )\n",
    "\n",
    "    # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_folder = os.path.join(paper_plot_folder, 'Tarragona', 'Trends')\n",
    "\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['UVA254 (1/m)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "color = 'rgb(200,2,110)'\n",
    "\n",
    "color_mapping = {\n",
    "    'Air Temperature (°C)': colors[0],\n",
    "    'Cumulated Rainfall (mm)': colors[1],\n",
    "    'Ammonium (mg/l)': colors[2],\n",
    "    'Conductivity (µS/cm)': colors[3],\n",
    "    'Dissolved Oxygen (mg/l)': colors[4],\n",
    "    'Flow River Rate (m³/s)': colors[5],\n",
    "    'Nitrate (mg/l)': colors[6],\n",
    "    'pH': colors[7],\n",
    "    'Water Temperature (°C)': colors[8],\n",
    "    'UVA254 (1/m)': colors[9]\n",
    "}\n",
    "\n",
    "station_df = xerta_df.copy()\n",
    "\n",
    "station_df.rename(\n",
    "    columns={\n",
    "        \"UVA254\": \"UVA254 (1/m)\",\n",
    "        \"Ammonium (mg/L)\": \"Ammonium (mg/l)\",\n",
    "        \"Daily Cumulated Rainfall (L/m²)\": \"Cumulated Rainfall (mm)\",\n",
    "        \"Flow River (m³/s)\": \"Flow River Rate (m³/s)\",\n",
    "        \"Dissolved Oxygen (mg/L)\": \"Dissolved Oxygen (mg/l)\",\n",
    "        \"Nitrate (mg/L)\": \"Nitrate (mg/l)\",\n",
    "        \n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "    \n",
    "fig = make_subplots(\n",
    "    len(columns),\n",
    "    1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=columns,\n",
    "    vertical_spacing=0.02\n",
    ")\n",
    "\n",
    "trend_show = True\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'ds': station_df.index,\n",
    "        'y': station_df[column]\n",
    "    })\n",
    "    \n",
    "    model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(df)\n",
    "    # Make predictions for both columns\n",
    "    future = model.make_future_dataframe(periods=0)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=station_df.index,\n",
    "            y=station_df[column],\n",
    "            mode='lines',\n",
    "            name=column,\n",
    "            line=dict(\n",
    "                color=color_mapping[column],\n",
    "                width=1.5\n",
    "            ),\n",
    "            legendrank=i,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast['ds'],\n",
    "            y=forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "            showlegend=False, # Change to trend_show to show the legend\n",
    "            legendrank=np.inf\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    if trend_show:\n",
    "        trend_show = False\n",
    "        \n",
    "    # fig.update_yaxes(title_text=column, row=i + 1, col=1)\n",
    "    \n",
    "    if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "            fig.update_yaxes(range=[0, 0.7], row=i + 1, col=1)\n",
    "        \n",
    "    if column == 'Air Temperature (°C)':\n",
    "        fig.update_yaxes(range=[-10, 30], row=i + 1, col=1)\n",
    "    \n",
    "    if column == 'Cumulated Rainfall (mm)':\n",
    "        fig.update_yaxes(range=[0, 8], row=i + 1, col=1)\n",
    "        \n",
    "    # if column == 'Conductivity (µS/cm)':\n",
    "    #     fig.update_yaxes(range=[0, 1700], row=i + 1, col=1)\n",
    "    \n",
    "    # if column == 'Nitrate (mg/l)':\n",
    "    #     fig.update_yaxes(range=[0, 20], row=i + 1, col=1)\n",
    "    \n",
    "    if column == 'pH':\n",
    "        fig.update_yaxes(range=[7.6, 8.8], row=i + 1, col=1)\n",
    "    \n",
    "    if column == 'Water Temperature (°C)':\n",
    "        fig.update_yaxes(range=[0, 30], row=i + 1, col=1)\n",
    "        \n",
    "    # if column == 'Flow River Rate (m³/s)':\n",
    "    #     fig.update_yaxes(range=[0, 1300], row=i + 1, col=1)\n",
    "    \n",
    "    if column == 'Dissolved Oxygen (mg/l)':\n",
    "            fig.update_yaxes(range=[4, 18], row=i + 1, col=1)\n",
    "    \n",
    "fig.update_xaxes(title_text=\"Time\", row=len(columns), col=1)\n",
    "    \n",
    "start_year = station_df.index.year.min()\n",
    "end_year = station_df.index.year.max()\n",
    "tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 3)]\n",
    "ticktext = [str(year) for year in range(start_year, end_year + 1, 3)]   \n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickvals=tickvals,\n",
    "    ticktext=ticktext,\n",
    ") \n",
    "    \n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Tarragona\",\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        y=0.99,\n",
    "        font=dict(size=10),\n",
    "    ),\n",
    "    font=dict(size=8),\n",
    "    legend=dict(\n",
    "        traceorder='normal',\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=30,  # Left margin\n",
    "        r=30,  # Right margin\n",
    "        t=50,  # Top margin\n",
    "        b=150  # Bottom margin (increase to add blank space)\n",
    "    )\n",
    "    )\n",
    "\n",
    "#reduce the font size of the subplot titles\n",
    "for annotation in fig['layout']['annotations']:\n",
    "    annotation['font'] = dict(size=8)\n",
    "\n",
    "fig.write_image(\n",
    "    os.path.join(trend_folder, \"trends.png\"),\n",
    "    scale=10,\n",
    "    width=400,\n",
    "    height=220 * len(columns)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "columns = ['Air Temperature (°C)', 'Ammonium (mg/l)', 'UVA254 (1/m)']\n",
    "\n",
    "station_df = xerta_df[['Air Temperature (°C)', 'Ammonium (mg/L)', 'UVA254']].copy()\n",
    "\n",
    "station_df.rename(\n",
    "    columns={\n",
    "        \"UVA254\": \"UVA254 (1/m)\",\n",
    "        \"Ammonium (mg/L)\": \"Ammonium (mg/l)\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# perform year by year correlation\n",
    "correlation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([columns, sorted(station_df.index.year.unique())]),\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "# normalize the data\n",
    "for column in columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "\n",
    "for year in station_df.index.year.unique():\n",
    "    \n",
    "    year_df = station_df[station_df.index.year == year]\n",
    "    \n",
    "    year_df = year_df[columns]\n",
    "    \n",
    "    for column in year_df.columns:\n",
    "        for column2 in year_df.columns:\n",
    "            if column == column2:\n",
    "                continue\n",
    "            \n",
    "            result = pearsonr(year_df[column], year_df[column2])\n",
    "            \n",
    "            correlation_results.loc[(column, year), column2] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation results\n",
    "\n",
    "correlation_folder = os.path.join(paper_plot_folder, 'Tarragona', 'Correlations')\n",
    "\n",
    "color = 'rgb(200,2,110)'\n",
    "\n",
    "for column in columns:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for column2 in columns:\n",
    "        \n",
    "        if column == column2:\n",
    "            continue\n",
    "        \n",
    "        years = correlation_results.loc[(column, slice(None)), column2].index.get_level_values(1)\n",
    "        \n",
    "        correlation = correlation_results.loc[(column, slice(None)), column2]        \n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=correlation.index.get_level_values(1),\n",
    "                y=correlation.apply(lambda x: x[0]),\n",
    "                mode='lines+markers',\n",
    "                name=column2\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title=f\"{column} vs Other Parameters\",\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Pearson Correlation Coefficient\",\n",
    "        legend=dict(\n",
    "            x=0.01,\n",
    "            y=0.99,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig.update_yaxes(range=[-1, 1])\n",
    "    \n",
    "    # add a horizontal line at 0\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=years.min(),\n",
    "        y0=0,\n",
    "        x1=years.max(),\n",
    "        y1=0,\n",
    "        line=dict(\n",
    "            color=\"black\",\n",
    "            width=1,\n",
    "            dash=\"dashdot\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    column_ = column.replace('/', '_')\n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(correlation_folder, f\"{column_}_correlation.png\"),\n",
    "        scale=6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = xerta_df[['Daily Cumulated Rainfall (mm)']].copy()\n",
    "\n",
    "# define classes as [0,1], (1, 2], (2, 3], (3, inf)\n",
    "\n",
    "rainfall_df['Class'] = pd.cut(rainfall_df['Daily Cumulated Rainfall (mm)'], bins=[0, 2, np.inf], labels=['Low', 'High'])\n",
    "\n",
    "rainfall_df['Year'] = rainfall_df.index.year\n",
    "rainfall_df['Month'] = rainfall_df.index.month\n",
    "\n",
    "# analyze if the frequency of the classes changes over time\n",
    "\n",
    "# create a pivot table\n",
    "pivot_table = rainfall_df.pivot_table(index='Year', columns='Class', aggfunc='size', fill_value=0)\n",
    "\n",
    "# plot the pivot table\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in pivot_table.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pivot_table.index,\n",
    "            y=pivot_table[column],\n",
    "            mode='lines+markers',\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    title=\"Rainfall Classes Frequency Over Time\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "def check_stationarity(dataframe, max_diff=2):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary by differencing if required.\n",
    "    \"\"\"\n",
    "    diff_count = 0\n",
    "    while diff_count < max_diff:\n",
    "        adf = adfuller(dataframe)\n",
    "        kp = kpss(dataframe)\n",
    "        if adf[1] > 0.05 or kp[1] < 0.05:\n",
    "            print(f'Data is non-stationary. Differencing the data. Attempt: {diff_count + 1}')\n",
    "            dataframe = dataframe.diff().dropna()\n",
    "            diff_count += 1\n",
    "        else:\n",
    "            break\n",
    "    return dataframe.dropna()\n",
    "\n",
    "def grangers_causation_matrix_multivariate(data, maxlag=12, test='ssr_chi2test', verbose=False):\n",
    "    \"\"\"\n",
    "    Check Granger Causality in a multivariate setting.\n",
    "    \"\"\"\n",
    "    variables = data.columns\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "        \n",
    "    new_data = pd.DataFrame()\n",
    "    # Ensure each series is stationary\n",
    "    for column in data.columns:\n",
    "        new_data[column] = check_stationarity(data[[column]])\n",
    "        \n",
    "    new_data = new_data.dropna()\n",
    "\n",
    "    # Fit the VAR model with automatic lag selection\n",
    "    model = VAR(new_data)\n",
    "    model_fitted = model.fit(ic='bic')\n",
    "\n",
    "    # Create Granger causality matrix\n",
    "    for r in variables:\n",
    "        for c in variables:\n",
    "            if c != r:\n",
    "                test_result = model_fitted.test_causality(c, r)\n",
    "                p_value = round(test_result.pvalue, 4)\n",
    "                df.loc[r, c] = p_value\n",
    "                if verbose:\n",
    "                    print(f'Y = {r}, X = {c}, P-Value = {p_value}')\n",
    "            else:\n",
    "                df.loc[r, c] = 1\n",
    "\n",
    "    # Rename columns and indexes for clarity\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "\n",
    "    # Optional: Return model summary and impulse response functions\n",
    "    return df, model_fitted.summary(), model_fitted.irf(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df = xerta_df[sorted(xerta_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"UVA254\": \"UVA254 (1/m)\",\n",
    "        \"Ammonium (mg/L)\": \"Ammonium (mg/l)\",\n",
    "        \"Daily Cumulated Rainfall (L/m²)\": \"Cumulated Rainfall (mm)\",\n",
    "        \"Flow River (m³/s)\": \"Flow River Rate (m³/s)\",\n",
    "        \"Dissolved Oxygen (mg/L)\": \"Dissolved Oxygen (mg/l)\",\n",
    "        \"Nitrate (mg/L)\": \"Nitrate (mg/l)\",\n",
    "        \n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "xerta_df.drop(\n",
    "    columns=[\n",
    "        \"Redox Potential (mV)\",\n",
    "        \"Turbidity (NTU)\",\n",
    "        \"Solar Radiation (W/m^2)\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrix, summary, irf = grangers_causation_matrix_multivariate(xerta_df, maxlag=1)\n",
    "\n",
    "print(summary)\n",
    "\n",
    "ax = irf.plot(orth=True)\n",
    "ax.set_size_inches(40, 20)\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrix.to_excel(os.path.join(data_folder, 'granger', 'causality_matrix.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = causality_matrix.copy()\n",
    "\n",
    "# remove the _x and _y from the column names\n",
    "matrix.columns = matrix.columns.str.replace('_x', '')\n",
    "matrix.index = matrix.index.str.replace('_y', '')\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes for all effects (rows) and causes (columns)\n",
    "G.add_nodes_from(matrix.columns, bipartite=0)  # Causes\n",
    "G.add_nodes_from(matrix.index, bipartite=1)    # Effects\n",
    "\n",
    "# Add edges for significant Granger causality (p-value < 0.05)\n",
    "threshold = 0.05\n",
    "for cause in matrix.columns:\n",
    "    for effect in matrix.index:\n",
    "        if matrix.loc[effect, cause] < threshold:\n",
    "            G.add_edge(cause, effect)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=3000, edge_color='black',\n",
    "        arrows=True, arrowsize=20, font_size=12, font_color='darkblue')\n",
    "plt.title(f\"Granger Causality Graph - Tarragona\")\n",
    "\n",
    "# make the plot wider\n",
    "plt.savefig(\n",
    "    os.path.join(paper_plot_folder, 'Tarragona', \"granger_causality.png\"),\n",
    "    bbox_inches='tight',\n",
    "    dpi=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests on trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to store the adf and mann-kendall test results for each station\n",
    "\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=xerta_df.columns,\n",
    "    columns=['ADF p-value', 'ADF result', 'MK p-value', 'MK result', 'Slope', 'Slope p-value']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in xerta_df.columns:\n",
    "    df = xerta_df[[column]].copy()\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    date_range = df.index\n",
    "    date_range = date_range.min(), date_range.max()\n",
    "\n",
    "    # make sure that the dataframe starts and finishes in the same month\n",
    "    start_index = df[df.index.month == date_range[1].month].index[0]\n",
    "\n",
    "    # Slice the dataframe to start from the found index\n",
    "    df = df.loc[start_index:]\n",
    "\n",
    "    # ===== Prophet =====\n",
    "\n",
    "    df.index.name = \"ds\"\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df.rename(columns={column: \"y\"}, inplace=True)\n",
    "\n",
    "    # using prophet\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(df)\n",
    "    # Make predictions for both columns\n",
    "    future = model.make_future_dataframe(periods=0)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Merging forecasted data with your original data\n",
    "    forecasting_final = pd.merge(\n",
    "        forecast,\n",
    "        df,\n",
    "        how=\"inner\",\n",
    "        on=\"ds\",\n",
    "    )\n",
    "\n",
    "    # compute linear regression on trend\n",
    "    X = np.arange(df.shape[0])\n",
    "    X = sm.add_constant(X)\n",
    "    y = df[\"y\"].copy()\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # plot the line of the linear regression\n",
    "    line = pd.Series(results.predict(X), index=df['ds'])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['ds'],\n",
    "            y=df[\"y\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Original\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecasting_final[\"ds\"],\n",
    "            y=forecasting_final[\"trend\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Trend\",\n",
    "        )\n",
    "    )    \n",
    "    \n",
    "    # perfrom Augmented Dickey-Fuller test\n",
    "    adf_result = adfuller(df[\"y\"], autolag=\"AIC\")\n",
    "    # perform KPSS test\n",
    "    kpss_result = kpss(df[\"y\"])\n",
    "    \n",
    "    # perfrom Mann-Kendall test        \n",
    "    mk_result = mk.original_test(df[\"y\"] - forecasting_final['yearly'])\n",
    "    \n",
    "    print()\n",
    "    print(f\"{column} - Augmented Dickey-Fuller Test\")\n",
    "    print(f\"ADF P-value: {adf_result[1]:.4f}\")\n",
    "    print(f\"Lag used: {adf_result[2]}\")\n",
    "    if adf_result[1] > 0.05:\n",
    "        print(\"Unit root present, data is non-stationary\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"{column} - KPSS Test\")\n",
    "    print(f\"KPSS P-value: {kpss_result[1]:.4f}\")\n",
    "    if kpss_result[1] < 0.05:\n",
    "        print(\"Unit root present, data is non-stationary\")\n",
    "    print()\n",
    "    \n",
    "    if (adf_result[1] > 0.05 and kpss_result[1] < 0.05) or (adf_result[1] < 0.05 and kpss_result[1] > 0.05):\n",
    "        print(\"=== Consistency between tests! ===\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"{column} - Mann-Kendall Test\")\n",
    "    print(f\"Monotonic Trend: {mk_result.trend}\")\n",
    "    print(f\"p-value: {mk_result.p:.4f}\")\n",
    "    print()\n",
    "    slope = results.params.iloc[1]\n",
    "    print(f\"{column} - Slope: {slope}\")\n",
    "\n",
    "    p_value = results.pvalues.iloc[1]\n",
    "    print(f\"{column} - P-value: {p_value}\")\n",
    "    \n",
    "    statistics_df.loc[column, 'ADF p-value'] = adf_result[1]\n",
    "    statistics_df.loc[column, 'ADF result'] = 'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'\n",
    "    \n",
    "    statistics_df.loc[column, 'MK p-value'] = mk_result.p\n",
    "    statistics_df.loc[column, 'MK result'] = mk_result.trend\n",
    "    \n",
    "    # store the slope\n",
    "    statistics_df.loc[column, 'Slope'] = slope\n",
    "    statistics_df.loc[column, 'Slope p-value'] = p_value\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=line.index,\n",
    "            y=line,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Linear Regression\",\n",
    "            line=dict(dash=\"dash\", color=\"black\"),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    start_date = df['ds'].min()\n",
    "    end_date = df['ds'].max()\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=column,\n",
    "        font=dict(\n",
    "            size=18,\n",
    "        ),\n",
    "        title=f\"{column} - {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')} - Slope: {slope:.4f}\",\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_excel(os.path.join(data_folder, 'statistics', 'statistics.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
