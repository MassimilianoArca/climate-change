{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Raw Data and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join('..', 'data')\n",
    "\n",
    "raw_data_folder = os.path.join(data_folder, 'raw_data')\n",
    "intermediate_data_folder = os.path.join(data_folder, 'intermediate_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = {}\n",
    "\n",
    "datasets_dict['TORTOSA'] = {}\n",
    "datasets_dict['GUIAMETS'] = {}\n",
    "datasets_dict['MEQUINENZA'] = {}\n",
    "datasets_dict['XERTA'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(raw_data_folder):\n",
    "    location = file.split('_')[0]\n",
    "    feature_name = '_'.join(file.split('_')[1:-2])\n",
    "    if file.endswith('.csv'):\n",
    "         datasets_dict[location][feature_name] = pd.read_csv(\n",
    "            filepath_or_buffer=os.path.join(raw_data_folder, file),\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            date_format='%Y-%m-%d %H:%M:%S',\n",
    "            header=0,\n",
    "            encoding='utf-8',\n",
    "        )\n",
    "    elif file.endswith('.xlsx'):\n",
    "        datasets_dict[location][feature_name] = pd.read_excel(\n",
    "            os.path.join(raw_data_folder, file),\n",
    "            date_format='%Y-%m-%d %H:%M:%S',\n",
    "            header=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs = datasets_dict['TORTOSA']\n",
    "guiamets_dfs = datasets_dict['GUIAMETS']\n",
    "mequinenza_dfs = datasets_dict['MEQUINENZA']\n",
    "xerta_dfs = datasets_dict['XERTA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tortosa Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The water temperature has two datasets, but the excel one has no missing values\n",
    "tortosa_dfs['watertemperature'].isna().sum() / tortosa_dfs['watertemperature'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['water_temperature'].isna().sum() / tortosa_dfs['water_temperature'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs.pop('water_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cumulated rainfall data since it is the only csv file\n",
    "tortosa_dfs['cumulated_rainfall_24h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fecha column is the one to take into account since \n",
    "# it is equal to the Fecha acumulado column in the same dataframe\n",
    "# but it has no missing values\n",
    "mask = tortosa_dfs['cumulated_rainfall_24h']['Fecha acumulado'] == tortosa_dfs['cumulated_rainfall_24h']['fecha']\n",
    "tortosa_dfs['cumulated_rainfall_24h'][mask == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['cumulated_rainfall_24h'].isna().sum() / tortosa_dfs['cumulated_rainfall_24h'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['cumulated_rainfall_24h'] = tortosa_dfs['cumulated_rainfall_24h'][['fecha', 'Acumulado']].rename(columns={'fecha': 'DateTime', 'Acumulado': 'Average'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['conductivity'].isna().sum() / tortosa_dfs['conductivity'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['flowriver'].isna().sum() / tortosa_dfs['flowriver'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs['turbidity'].isna().sum() / tortosa_dfs['turbidity'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    if feature != 'cumulated_rainfall_24h':\n",
    "        df.rename(\n",
    "            columns={\n",
    "                'Fecha': 'DateTime',\n",
    "                'Promedio': 'Average',\n",
    "                'Máximo': 'Maximum',\n",
    "                'Mínimo': 'Minimum'\n",
    "            },\n",
    "            inplace=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in tortosa_dfs.values():\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df[df.columns.difference(['DateTime'])] = df[df.columns.difference(['DateTime'])].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    print(f'{feature}: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    tortosa_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df['Average'], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y='Average')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x='DateTime', y='Average', label='Average')\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guiamets Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "guiamets_dfs['cumulated_rainfall_24h'].isna().sum() / guiamets_dfs['cumulated_rainfall_24h'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs['environmental_temperature'].isna().sum() / guiamets_dfs['environmental_temperature'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs['cumulated_rainfall_24h'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs['cumulated_rainfall_24h'].drop(columns=['Fecha m�ximo', 'M�ximo', 'Fecha acumulado'], inplace=True)\n",
    "guiamets_dfs['environmental_temperature'].drop(columns=['Fecha m�ximo', 'Fecha m�nimo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs['cumulated_rainfall_24h'].rename(\n",
    "    columns={\n",
    "        'fecha': 'DateTime',\n",
    "        'Acumulado': 'Average'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "guiamets_dfs['environmental_temperature'].rename(\n",
    "    columns={\n",
    "        'fecha': 'DateTime',\n",
    "        'Media': 'Average',\n",
    "        'M�nimo': 'Minimum',\n",
    "        'M�ximo': 'Maximum'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in guiamets_dfs.values():\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df[df.columns.difference(['DateTime'])] = df[df.columns.difference(['DateTime'])].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    print(f'{feature}: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    guiamets_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df['Average'], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y='Average')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x='DateTime', y='Average', label='Average')\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mequinenza Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs['cumulated_rainfall_24h'].isna().sum() / mequinenza_dfs['cumulated_rainfall_24h'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs['cumulated_rainfall_24h'].drop(columns=['Fecha m�ximo', 'M�ximo', 'Fecha acumulado'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs['cumulated_rainfall_24h'].rename(\n",
    "    columns={\n",
    "        'fecha': 'DateTime',\n",
    "        'Acumulado': 'Average'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs['cumulated_rainfall_24h']['DateTime'] = pd.to_datetime(mequinenza_dfs['cumulated_rainfall_24h']['DateTime'])\n",
    "mequinenza_dfs['cumulated_rainfall_24h'][mequinenza_dfs['cumulated_rainfall_24h'].columns.difference(['DateTime'])] = mequinenza_dfs['cumulated_rainfall_24h'][mequinenza_dfs['cumulated_rainfall_24h'].columns.difference(['DateTime'])].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    print(f'{feature}: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    mequinenza_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df['Average'], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y='Average')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x='DateTime', y='Average', label='Average')\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xerta Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    print('Feature:', feature)\n",
    "    print()\n",
    "    print('% missing values:')\n",
    "    print()\n",
    "    print(df.isna().sum() / df.shape[0])\n",
    "    print()\n",
    "    print('Column names:', df.columns.to_list())\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in xerta_dfs.values():\n",
    "    df.rename(\n",
    "        columns={\n",
    "            'Fecha': 'DateTime',\n",
    "            'Promedio': 'Average',\n",
    "            'Máximo': 'Maximum',\n",
    "            'Mínimo': 'Minimum'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df[df.columns.difference(['DateTime'])] = df[df.columns.difference(['DateTime'])].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in xerta_dfs.items():\n",
    "    print(f'{feature}: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in xerta_dfs.items():\n",
    "    xerta_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df['Average'], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y='Average')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x='DateTime', y='Average', label='Average')\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict['TORTOSA'] = tortosa_dfs\n",
    "datasets_dict['GUIAMETS'] = guiamets_dfs\n",
    "datasets_dict['MEQUINENZA'] = mequinenza_dfs\n",
    "datasets_dict['XERTA'] = xerta_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in datasets_dict.keys():\n",
    "    if not os.path.exists(os.path.join(intermediate_data_folder, location)):\n",
    "        os.makedirs(os.path.join(intermediate_data_folder, location))\n",
    "        \n",
    "    path = os.path.join(intermediate_data_folder, location)\n",
    "    for feature, df in datasets_dict[location].items():\n",
    "        df.to_excel(os.path.join(path, f'{feature}.xlsx'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
