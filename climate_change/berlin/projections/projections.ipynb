{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"data\", \"berlin\")\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")\n",
    "projections_folder = os.path.join(data_folder, \"projections\")\n",
    "cat_projections_folder = os.path.join(projections_folder, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df = pd.read_excel(os.path.join(clean_data_folder, \"surface.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = pd.read_excel(os.path.join(clean_data_folder, \"ground.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_flow_river_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"flow_river.xlsx\")\n",
    ")\n",
    "\n",
    "cat_air_temp_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"air_temp.xlsx\")\n",
    ")\n",
    "\n",
    "cat_precip_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"precip.xlsx\")\n",
    ")\n",
    "\n",
    "cat_water_temp_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"water_temp.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns = [\"DateTime\", \"Station\"]\n",
    "bacteria_columns = [\n",
    "    \"E.Coli (MPN/100ml)\",\n",
    "    \"Enterococcus (MPN/100ml)\",\n",
    "    \"Coliform (MPN/100ml)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, lags: int, rolling_window: int, poly_degree: int):\n",
    "    \n",
    "    initial_features = df.columns\n",
    "    # add polynomial features\n",
    "    poly = PolynomialFeatures(degree=poly_degree)\n",
    "    df_poly = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df_poly, columns=poly.get_feature_names_out(df.columns))\n",
    "    \n",
    "    # add lagged, rolling and expanding features for each variable in df\n",
    "    for col in initial_features.difference([\"Year\", \"Month\"]):\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
    "            \n",
    "        df[f\"{col}_rolling{rolling_window}\"] = df[col].rolling(rolling_window).mean()\n",
    "        \n",
    "    # fill NaN values with bfill\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    df.drop(columns=['1'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    \"Ammonium (mg/l)\",\n",
    "    \"Conductivity (ÂµS/cm)\",\n",
    "    \"Dissolved Oxygen (mg/l)\",\n",
    "    \"Nitrate (mg/l)\",\n",
    "    \"pH\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the models by using all the dataset, then predict on the projections\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# Prepare the data for the models\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    df = surface_df[surface_df['Station'] == station_id]\n",
    "    \n",
    "    # add the year and month columns\n",
    "    df[\"Year\"] = df[\"DateTime\"].dt.year\n",
    "    df[\"Month\"] = df[\"DateTime\"].dt.month\n",
    "    \n",
    "    # Save the datetime column for later (drop diff returns error\n",
    "    # if I remove it before)\n",
    "    datetime_column = df.drop(columns=bacteria_columns).dropna()[\"DateTime\"]\n",
    "    \n",
    "    df = df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    X = df.drop(columns=[\"DOC (mg/l)\"])\n",
    "    y = df[[\"DOC (mg/l)\"]]\n",
    "    \n",
    "    # sort the X columns\n",
    "    X = X.reindex(sorted(X.columns), axis=1)\n",
    "    \n",
    "    X = extend_features(X, lags=1, rolling_window=3, poly_degree=2)\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    cols = X.columns\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "    \n",
    "    # Add the datetime column back\n",
    "    X[\"DateTime\"] = datetime_column.values\n",
    "    y[\"DateTime\"] = datetime_column.values\n",
    "    \n",
    "    \n",
    "    X = X.set_index(\"DateTime\")\n",
    "    y = y.set_index(\"DateTime\")\n",
    "    \n",
    "    datasets[station_id] = (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare projections dataset\n",
    "\n",
    "projections = [\n",
    "    cat_flow_river_projections,\n",
    "    cat_air_temp_projections,\n",
    "    cat_precip_projections,\n",
    "    cat_water_temp_projections\n",
    "]\n",
    "\n",
    "projections_per_site = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    projections_per_site[station_id] = {\n",
    "        'rcp45': pd.DataFrame(),\n",
    "        'rcp85': pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    for projection in projections:\n",
    "\n",
    "        cat_projections_df = projection[projection[\"Station\"] == station_id].copy()\n",
    "        \n",
    "        column = cat_projections_df.columns.to_list()[1]\n",
    "\n",
    "        cat_rcp45 = cat_projections_df[cat_projections_df['label'] == \"rcp45\"]\n",
    "        cat_rcp85 = cat_projections_df[cat_projections_df['label'] == \"rcp85\"]\n",
    "\n",
    "        cat_rcp45.set_index(\"DateTime\", inplace=True)\n",
    "        cat_rcp85.set_index(\"DateTime\", inplace=True)\n",
    "\n",
    "        # Extend cat_rcp45 and cat_rcp85 to a 30 years period\n",
    "\n",
    "        years = cat_rcp45.index.year.unique()\n",
    "        months = cat_rcp45.index.month.unique()\n",
    "\n",
    "        new_cat45_df = pd.DataFrame(columns=['DateTime', column])\n",
    "\n",
    "        for year in years:\n",
    "            for month in months:\n",
    "                value = cat_rcp45.loc[(cat_rcp45.index.year == year) & (cat_rcp45.index.month == month), column].values[0]\n",
    "                # extend the value to the previous 30 years\n",
    "                date_range = pd.date_range(start=f\"{year-30}-{month}-01\", end=f\"{year}-{month}-01\", freq='Y') + pd.offsets.MonthEnd(month)\n",
    "                values = np.full(date_range.shape, value)\n",
    "                new_df = pd.DataFrame({\n",
    "                    'DateTime': date_range,\n",
    "                    column: values,\n",
    "                })\n",
    "                \n",
    "                new_cat45_df = pd.concat([new_cat45_df, new_df])\n",
    "            \n",
    "        new_cat85_df = pd.DataFrame(columns=['DateTime', column])\n",
    "\n",
    "        for year in years:\n",
    "            for month in months:\n",
    "                value = cat_rcp85.loc[(cat_rcp85.index.year == year) & (cat_rcp85.index.month == month), column].values[0]\n",
    "                # extend the value to the previous 30 years\n",
    "                date_range = pd.date_range(start=f\"{year-30}-{month}-01\", end=f\"{year}-{month}-01\", freq='Y') + pd.offsets.MonthEnd(month)\n",
    "                values = np.full(date_range.shape, value)\n",
    "                new_df = pd.DataFrame({\n",
    "                    'DateTime': date_range,\n",
    "                    column: values,\n",
    "                })\n",
    "                \n",
    "                new_cat85_df = pd.concat([new_cat85_df, new_df])\n",
    "            \n",
    "        # sort the dataframes\n",
    "        new_cat45_df.sort_values(by='DateTime', inplace=True)\n",
    "        new_cat85_df.sort_values(by='DateTime', inplace=True)\n",
    "        \n",
    "        if projections_per_site[station_id]['rcp45'].shape[0] == 0:\n",
    "            projections_per_site[station_id]['rcp45'] = new_cat45_df\n",
    "            projections_per_site[station_id]['rcp85'] = new_cat85_df\n",
    "        else:\n",
    "            projections_per_site[station_id]['rcp45'][column] = new_cat45_df[column]\n",
    "            projections_per_site[station_id]['rcp85'][column] = new_cat85_df[column]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the projections for the models\n",
    "\n",
    "projections_datasets = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    projections_datasets[station_id] = {}\n",
    "    \n",
    "    rcp45_df = projections_per_site[station_id]['rcp45']\n",
    "    rcp85_df = projections_per_site[station_id]['rcp85']\n",
    "    \n",
    "    # add the year and month columns\n",
    "    rcp45_df[\"Year\"] = rcp45_df[\"DateTime\"].dt.year\n",
    "    rcp45_df[\"Month\"] = rcp45_df[\"DateTime\"].dt.month\n",
    "    \n",
    "    rcp85_df[\"Year\"] = rcp85_df[\"DateTime\"].dt.year\n",
    "    rcp85_df[\"Month\"] = rcp85_df[\"DateTime\"].dt.month\n",
    "    \n",
    "    # Save the datetime column for later (drop diff returns error\n",
    "    # if I remove it before)\n",
    "    datetime_column = rcp45_df[\"DateTime\"]\n",
    "    \n",
    "    rcp45_df = rcp45_df.drop(columns=['DateTime'])\n",
    "    rcp85_df = rcp85_df.drop(columns=['DateTime'])\n",
    "    \n",
    "    # sort the X columns\n",
    "    rcp45_df = rcp45_df.reindex(sorted(rcp45_df.columns), axis=1)\n",
    "    rcp85_df = rcp85_df.reindex(sorted(rcp85_df.columns), axis=1)\n",
    "    \n",
    "    rcp45_df = extend_features(rcp45_df, lags=1, rolling_window=3, poly_degree=2)\n",
    "    rcp85_df = extend_features(rcp85_df, lags=1, rolling_window=3, poly_degree=2)\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    cols = rcp45_df.columns\n",
    "    \n",
    "    rcp45_df = scaler.fit_transform(rcp45_df)\n",
    "    rcp45_df = pd.DataFrame(rcp45_df, columns=cols)\n",
    "    \n",
    "    rcp85_df = scaler.fit_transform(rcp85_df)\n",
    "    rcp85_df = pd.DataFrame(rcp85_df, columns=cols)\n",
    "    \n",
    "    \n",
    "    # Add the datetime column back\n",
    "    rcp45_df[\"DateTime\"] = datetime_column.values\n",
    "    rcp85_df[\"DateTime\"] = datetime_column.values\n",
    "    \n",
    "    rcp45_df = rcp45_df.set_index(\"DateTime\")\n",
    "    rcp85_df = rcp85_df.set_index(\"DateTime\")\n",
    "    \n",
    "    projections_datasets[station_id]['rcp45'] = rcp45_df\n",
    "    projections_datasets[station_id]['rcp85'] = rcp85_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_studies = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "            \n",
    "    study = optuna.load_study(\n",
    "    study_name=\"Hyperparameter Tuning - XGBoost\"\n",
    "    + \" + \"\n",
    "    + f\"Station{station_id}\",\n",
    "    storage=f\"sqlite:///XGBoost-Station{station_id}-Extended.sqlite3\",\n",
    "    )\n",
    "            \n",
    "    xgb_studies[station_id] = study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = {}\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    params = xgb_studies[station_id].best_params\n",
    "    \n",
    "    params[\"objective\"] = \"reg:squarederror\"\n",
    "    params[\"booster\"] = \"gblinear\"\n",
    "    \n",
    "    X_tr, y_tr = datasets[station_id]\n",
    "    \n",
    "    X_ts_rcp45 = projections_datasets[station_id]['rcp45']\n",
    "    X_ts_rcp85 = projections_datasets[station_id]['rcp85']\n",
    "    \n",
    "    # sort the columns in alphabetical order\n",
    "    X_tr = X_tr.reindex(sorted(X_tr.columns), axis=1)\n",
    "    X_ts_rcp45 = X_ts_rcp45.reindex(sorted(X_ts_rcp45.columns), axis=1)\n",
    "    X_ts_rcp85 = X_ts_rcp85.reindex(sorted(X_ts_rcp85.columns), axis=1)\n",
    "    \n",
    "    n_size = len(X_tr)\n",
    "    predictions_rcp45 = np.zeros((len(X_ts_rcp45), n_iterations))\n",
    "    predictions_rcp85 = np.zeros((len(X_ts_rcp85), n_iterations))\n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "    # Bootstrap sample (random state changes each iteration)\n",
    "        X_resampled, y_resampled = resample(X_tr, y_tr, n_samples=n_size, random_state=i)\n",
    "        \n",
    "        # Train the model with the best hyperparameters\n",
    "        model = xgb.XGBRegressor(**params, random_state=42)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict the projections\n",
    "        y_pred_rcp45 = model.predict(X_ts_rcp45)\n",
    "        predictions_rcp45[:, i] = y_pred_rcp45\n",
    "        \n",
    "        y_pred_rcp85 = model.predict(X_ts_rcp85)\n",
    "        predictions_rcp85[:, i] = y_pred_rcp85\n",
    "        \n",
    "    \n",
    "    # Calculate 95% confidence interval of the predictions\n",
    "    lower_bound_rcp45 = np.percentile(predictions_rcp45, 2.5, axis=1)\n",
    "    upper_bound_rcp45 = np.percentile(predictions_rcp45, 97.5, axis=1)\n",
    "    \n",
    "    lower_bound_rcp85 = np.percentile(predictions_rcp85, 2.5, axis=1)\n",
    "    upper_bound_rcp85 = np.percentile(predictions_rcp85, 97.5, axis=1)\n",
    "    \n",
    "    # Calculate the mean predictions\n",
    "    mean_predictions_rcp45 = np.mean(predictions_rcp45, axis=1)\n",
    "    mean_predictions_rcp85 = np.mean(predictions_rcp85, axis=1)\n",
    "    \n",
    "    xgb_results[station_id] = {\n",
    "        'rcp45': {\n",
    "            'mean': mean_predictions_rcp45,\n",
    "            'lower_bound': lower_bound_rcp45,\n",
    "            'upper_bound': upper_bound_rcp45\n",
    "        },\n",
    "        'rcp85': {\n",
    "            'mean': mean_predictions_rcp85,\n",
    "            'lower_bound': lower_bound_rcp85,\n",
    "            'upper_bound': upper_bound_rcp85\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RCP45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    print(f\"=== Station {station_id} ===\")\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    y_true = datasets[station_id][1]\n",
    "    \n",
    "    end_date = y_true.index[-1]\n",
    "    \n",
    "    mean_rcp45 = xgb_results[station_id]['rcp45']['mean']\n",
    "    lower_bound_rcp45 = xgb_results[station_id]['rcp45']['lower_bound']\n",
    "    upper_bound_rcp45 = xgb_results[station_id]['rcp45']['upper_bound']\n",
    "    \n",
    "    # add the datetime column back\n",
    "    datetime_column = projections_datasets[station_id]['rcp45'].index\n",
    "    \n",
    "    mean_rcp45 = pd.Series(mean_rcp45, index=datetime_column)\n",
    "    lower_bound_rcp45 = pd.Series(lower_bound_rcp45, index=datetime_column)\n",
    "    upper_bound_rcp45 = pd.Series(upper_bound_rcp45, index=datetime_column)\n",
    "    \n",
    "    # make the prediction start from the end of the true data\n",
    "    mean_rcp45 = mean_rcp45.loc[end_date:]\n",
    "    lower_bound_rcp45 = lower_bound_rcp45.loc[end_date:]\n",
    "    upper_bound_rcp45 = upper_bound_rcp45.loc[end_date:]\n",
    "    \n",
    "    # Concatenate historical and projection data\n",
    "    combined_mean = pd.concat([y_true['DOC (mg/l)'], mean_rcp45])\n",
    "    combined_lower_bound = pd.concat([y_true['DOC (mg/l)'], lower_bound_rcp45])\n",
    "    combined_upper_bound = pd.concat([y_true['DOC (mg/l)'], upper_bound_rcp45])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_mean.index,\n",
    "            y=combined_mean,\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            name='RCP4.5 Projections'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_lower_bound.index,\n",
    "            y=combined_lower_bound,\n",
    "            mode='lines',\n",
    "            line=dict(color='blue', width=0),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_upper_bound.index,\n",
    "            y=combined_upper_bound,\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=0),\n",
    "            fill='tonexty',\n",
    "            fillcolor='rgba(0, 100, 80, 0.2)',\n",
    "            name='95% CI',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_true.index,\n",
    "            y=y_true['DOC (mg/l)'],\n",
    "            mode='lines',\n",
    "            line=dict(color='black'),\n",
    "            name='Historical Data'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Station {station_id} - RCP4.5\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"DOC (mg/l)\"\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RCP85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    print(f\"=== Station {station_id} ===\")\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    y_true = datasets[station_id][1]\n",
    "    \n",
    "    end_date = y_true.index[-1]\n",
    "    \n",
    "    mean_rcp85 = xgb_results[station_id]['rcp85']['mean']\n",
    "    lower_bound_rcp85 = xgb_results[station_id]['rcp85']['lower_bound']\n",
    "    upper_bound_rcp85 = xgb_results[station_id]['rcp85']['upper_bound']\n",
    "    \n",
    "    # add the datetime column back\n",
    "    datetime_column = projections_datasets[station_id]['rcp85'].index\n",
    "    \n",
    "    mean_rcp85 = pd.Series(mean_rcp85, index=datetime_column)\n",
    "    lower_bound_rcp85 = pd.Series(lower_bound_rcp85, index=datetime_column)\n",
    "    upper_bound_rcp85 = pd.Series(upper_bound_rcp85, index=datetime_column)\n",
    "    \n",
    "    # make the prediction start from the end of the true data\n",
    "    mean_rcp85 = mean_rcp85.loc[end_date:]\n",
    "    lower_bound_rcp85 = lower_bound_rcp85.loc[end_date:]\n",
    "    upper_bound_rcp85 = upper_bound_rcp85.loc[end_date:]\n",
    "    \n",
    "    # Concatenate historical and projection data\n",
    "    combined_mean = pd.concat([y_true['DOC (mg/l)'], mean_rcp85])\n",
    "    combined_lower_bound = pd.concat([y_true['DOC (mg/l)'], lower_bound_rcp85])\n",
    "    combined_upper_bound = pd.concat([y_true['DOC (mg/l)'], upper_bound_rcp85])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_mean.index,\n",
    "            y=combined_mean,\n",
    "            mode='lines',\n",
    "            line=dict(color='red'),\n",
    "            name='RCP8.5 Projections'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_lower_bound.index,\n",
    "            y=combined_lower_bound,\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=0),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=combined_upper_bound.index,\n",
    "            y=combined_upper_bound,\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=0),\n",
    "            fill='tonexty',\n",
    "            fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "            name='95% CI',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_true.index,\n",
    "            y=y_true['DOC (mg/l)'],\n",
    "            mode='lines',\n",
    "            line=dict(color='black'),\n",
    "            name='Historical Data'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Station {station_id} - RCP8.5\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"DOC (mg/l)\"\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
