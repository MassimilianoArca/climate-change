{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests, kpss\n",
    "\n",
    "import pymannkendall as mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"data\", \"berlin\")\n",
    "plot_folder = os.path.join(data_folder, \"plots\")\n",
    "surface_plot_folder = os.path.join(plot_folder, \"surface\")\n",
    "surface_cross_corr_folder = os.path.join(surface_plot_folder, \"cross_corr\")\n",
    "surface_corr_folder = os.path.join(surface_plot_folder, \"corr\")\n",
    "\n",
    "ground_plot_folder = os.path.join(plot_folder, \"ground\")\n",
    "ground_cross_corr_folder = os.path.join(ground_plot_folder, \"cross_corr\")\n",
    "ground_corr_folder = os.path.join(ground_plot_folder, \"corr\")\n",
    "\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")\n",
    "projections_folder = os.path.join(data_folder, \"projections\")\n",
    "\n",
    "my_projections_folder = os.path.join(projections_folder, \"found_by_me\")\n",
    "cat_projections_folder = os.path.join(projections_folder, \"cat\")\n",
    "\n",
    "paper_plots_folder = os.path.join(\"..\", \"..\", \"paper plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"surface.xlsx\")\n",
    ")\n",
    "ground_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"ground.xlsx\")\n",
    ")\n",
    "\n",
    "flow_river_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"flow_river.xlsx\")\n",
    ")\n",
    "\n",
    "hist_flow_river_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"flow_river_hist.xlsx\")\n",
    ")\n",
    "\n",
    "air_temp_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"air_temp.xlsx\")\n",
    ")\n",
    "\n",
    "hist_air_temp_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"air_temp_hist.xlsx\")\n",
    ")\n",
    "\n",
    "precip_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"precip.xlsx\")\n",
    ")\n",
    "\n",
    "hist_precip_projections = pd.read_excel(\n",
    "    os.path.join(my_projections_folder, \"precip_hist.xlsx\")\n",
    ")\n",
    "\n",
    "cat_flow_river_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"flow_river.xlsx\")\n",
    ")\n",
    "\n",
    "cat_air_temp_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"air_temp.xlsx\")\n",
    ")\n",
    "\n",
    "cat_precip_projections = pd.read_excel(\n",
    "    os.path.join(cat_projections_folder, \"precip.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis post Berlin Wall Fall\n",
    "# surface_df = surface_df[surface_df[\"DateTime\"] >= \"1998-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = ground_df[ground_df[\"DateTime\"] >= \"1998-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conductivity vs Flow River Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Conductivity (µS/cm)', 'Flow River Rate (m³/s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id][['DateTime'] + columns].copy()\n",
    "    station_df.dropna(inplace=True)\n",
    "    \n",
    "    # Granger Causality Test\n",
    "    max_lag = 6\n",
    "    \n",
    "    for column in columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "        \n",
    "    \n",
    "    \n",
    "    cond = station_df['Conductivity (µS/cm)']\n",
    "    flow = station_df['Flow River Rate (m³/s)']\n",
    "    \n",
    "    print()\n",
    "    print('Pearson Correlation')\n",
    "    print(pearsonr(cond, flow))\n",
    "    \n",
    "    # first check for stationarity\n",
    "    \n",
    "    # Augmented Dickey-Fuller test\n",
    "    adf_cond = adfuller(cond)\n",
    "    adf_flow = adfuller(flow)\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print(\"Augmented Dickey-Fuller Test\")\n",
    "    if adf_cond[1] > 0.05 or adf_flow[1] > 0.05:\n",
    "        print(\"Non-stationary data\")\n",
    "        print(\"Differencing data\")\n",
    "        cond = np.diff(cond, n=1)\n",
    "        flow = np.diff(flow, n=1)\n",
    "    \n",
    "    print(\"Granger Causality Test - Conductivity -> Flow\")\n",
    "    df = pd.DataFrame({\n",
    "        'cond': cond,\n",
    "        'flow': flow\n",
    "    })\n",
    "    \n",
    "    grangercausalitytests(df, max_lag, verbose=True)\n",
    "    \n",
    "    print()\n",
    "    print(\"Granger Causality Test - Flow -> Conductivity\")\n",
    "    df = pd.DataFrame({\n",
    "        'flow': flow,\n",
    "        'cond': cond\n",
    "    })\n",
    "    \n",
    "    grangercausalitytests(df, max_lag, verbose=True)\n",
    "    \n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df['DateTime'],\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name=column\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title=f\"Surface Station {station_id}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Value\"\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns = [\"DateTime\", \"Station\"]\n",
    "bacteria_columns = [\n",
    "    \"E.Coli (MPN/100ml)\",\n",
    "    \"Enterococcus (MPN/100ml)\",\n",
    "    \"Coliform (MPN/100ml)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Tests on Stationarity and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to store the adf and mann-kendall test results for each station\n",
    "\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=surface_df.columns.difference(diff_columns + bacteria_columns),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), ['ADF p-value', 'ADF result', 'MK p-value', 'MK result', 'Slope', 'Slope p-value', 'Trend Percentage']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in surface_df[\"Station\"].unique():\n",
    "    station_df = surface_df[surface_df[\"Station\"] == station_id].copy()\n",
    "    \n",
    "    # analysis post Berlin Wall Fall\n",
    "    station_df = station_df[station_df[\"DateTime\"] >= \"1992-01-01\"]\n",
    "\n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        df = station_df[[\"DateTime\", column]].copy()\n",
    "\n",
    "        df.set_index(\"DateTime\", inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        date_range = df.index\n",
    "        date_range = date_range.min(), date_range.max()\n",
    "\n",
    "        # make sure that the dataframe starts and finishes in the same month\n",
    "        start_index = df[df.index.month == date_range[1].month].index[0]\n",
    "\n",
    "        # Slice the dataframe to start from the found index\n",
    "        df = df.loc[start_index:]\n",
    "\n",
    "        # ===== Prophet =====\n",
    "\n",
    "        df.index.name = \"ds\"\n",
    "\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df.rename(columns={column: \"y\"}, inplace=True)\n",
    "\n",
    "        # using prophet\n",
    "\n",
    "        model = Prophet()\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Merging forecasted data with your original data\n",
    "        forecasting_final = pd.merge(\n",
    "            forecast,\n",
    "            df,\n",
    "            how=\"inner\",\n",
    "            on=\"ds\",\n",
    "        )\n",
    "\n",
    "        # compute linear regression on trend\n",
    "        X = np.arange(df.shape[0])\n",
    "        X = sm.add_constant(X)\n",
    "        y = df[\"y\"].copy()\n",
    "\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        # plot the line of the linear regression\n",
    "        line = pd.Series(results.predict(X), index=df['ds'])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['ds'],\n",
    "                y=df[\"y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Original\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecasting_final[\"ds\"],\n",
    "                y=forecasting_final[\"trend\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Trend\",\n",
    "            )\n",
    "        )    \n",
    "        \n",
    "        # perfrom Augmented Dickey-Fuller test\n",
    "        adf_result = adfuller(df[\"y\"], autolag=\"AIC\")\n",
    "        # perform KPSS test\n",
    "        kpss_result = kpss(df[\"y\"])\n",
    "        \n",
    "        # perfrom Mann-Kendall test        \n",
    "        mk_result = mk.original_test(df[\"y\"] - forecasting_final['yearly'])\n",
    "        \n",
    "        print()\n",
    "        print(f\"{column} - Augmented Dickey-Fuller Test\")\n",
    "        print(f\"ADF P-value: {adf_result[1]:.4f}\")\n",
    "        print(f\"Lag used: {adf_result[2]}\")\n",
    "        if adf_result[1] > 0.05:\n",
    "            print(\"Unit root present, data is non-stationary\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"{column} - KPSS Test\")\n",
    "        print(f\"KPSS P-value: {kpss_result[1]:.4f}\")\n",
    "        if kpss_result[1] < 0.05:\n",
    "            print(\"Unit root present, data is non-stationary\")\n",
    "        print()\n",
    "        \n",
    "        if (adf_result[1] > 0.05 and kpss_result[1] < 0.05) or (adf_result[1] < 0.05 and kpss_result[1] > 0.05):\n",
    "            print(\"=== Consistency between tests! ===\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"{column} - Mann-Kendall Test\")\n",
    "        print(f\"Monotonic Trend: {mk_result.trend}\")\n",
    "        print(f\"p-value: {mk_result.p:.4f}\")\n",
    "        print()\n",
    "        slope = results.params.iloc[1]\n",
    "        print(f\"{column} - Slope: {slope}\")\n",
    "\n",
    "        p_value = results.pvalues.iloc[1]\n",
    "        print(f\"{column} - P-value: {p_value}\")\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'ADF p-value')] = adf_result[1]\n",
    "        statistics_df.loc[column, (station_id, 'ADF result')] = 'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'MK p-value')] = mk_result.p\n",
    "        statistics_df.loc[column, (station_id, 'MK result')] = mk_result.trend\n",
    "        \n",
    "        # store the slope\n",
    "        statistics_df.loc[column, (station_id, 'Slope')] = slope\n",
    "        statistics_df.loc[column, (station_id, 'Slope p-value')] = p_value\n",
    "        \n",
    "        # calculate the percentage of the trend\n",
    "        trend_percentage = slope / df['y'].mean() * 100\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'Trend Percentage')] = trend_percentage\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=line.index,\n",
    "                y=line,\n",
    "                mode=\"lines\",\n",
    "                name=f\"Linear Regression\",\n",
    "                line=dict(dash=\"dash\", color=\"black\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        start_date = df['ds'].min()\n",
    "        end_date = df['ds'].max()\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=column,\n",
    "            font=dict(\n",
    "                size=18,\n",
    "            ),\n",
    "            title=f\"{station_id} - {column} - {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')} - Trend Percentage: {trend_percentage:.2f}% - Slope: {slope:.4f}\",\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage change for each subsequent year\n",
    "for station_id in surface_df[\"Station\"].unique():\n",
    "    station_df = surface_df[surface_df[\"Station\"] == station_id].copy()\n",
    "    \n",
    "    # analysis post Berlin Wall Fall\n",
    "    station_df = station_df[station_df[\"DateTime\"] >= \"1992-01-01\"]\n",
    "\n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        df = station_df[[\"DateTime\", column]].copy()\n",
    "\n",
    "        df.set_index(\"DateTime\", inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "        # compute the percentage change with respect to the first complete year\n",
    "        complete_years = df.groupby(df.index.year).filter(lambda x: len(x) == 12)\n",
    "\n",
    "        # Get the first complete year (with measurements for all 12 months)\n",
    "        first_year = complete_years.index.year.min()\n",
    "        \n",
    "        last_year = complete_years.index.year.max()\n",
    "        \n",
    "        first_year_df = complete_years[complete_years.index.year == first_year]\n",
    "        \n",
    "        last_year_df = complete_years[complete_years.index.year == last_year]\n",
    "        \n",
    "        percentage_change = (last_year_df[column].mean() - first_year_df[column].mean()) / first_year_df[column].mean() * 100\n",
    "        \n",
    "        print(f\"{station_id} - {column} - Percentage Change: {percentage_change:.2f}% - First Year: {first_year} - Last Year: {last_year}\")\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_excel(os.path.join(surface_plot_folder, 'trends', \"statistics.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    for column in station_df.columns.difference(['DateTime', 'Station']):\n",
    "        \n",
    "        print(f\"{station_id} - {column}\")\n",
    "        plot_acf(station_df[column], lags=20)\n",
    "        \n",
    "        \n",
    "        plot_pacf(station_df[column], lags=20)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causality and Cointegration\n",
    "\n",
    "\"If two or more time-series are cointegrated, then there must be Granger causality between them - either one-way or in both directions. However, the converse is not true.\"\n",
    "\n",
    "\"So, if your data are cointegrated but you don't find any evidence of causality, you have a conflict in your results. (This might occur if your sample size is too small to satisfy the asymptotics that the cointegration and causality tests rely on.) If you have cointegration and find one-way causality, everything is fine. (You may still be wrong about there being no causality in the other direction.) If your data are not cointegrated, then you have no cross-check on your causality results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Johansen test\n",
    "def johansen_test(data, det_order, k_ar_diff=1):\n",
    "    \"\"\"\n",
    "    Performs the Johansen cointegration test and prints the results.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): The time series data for the cointegration test.\n",
    "    det_order (int): The order of the deterministic terms.\n",
    "                     -1: No constant or trend.\n",
    "                      0: Constant term only.\n",
    "                      1: Constant and trend terms.\n",
    "    k_ar_diff (int): The number of lags to include in the VAR model.\n",
    "    \"\"\"\n",
    "    result = coint_johansen(data, det_order, k_ar_diff)\n",
    "    \n",
    "    print(f'Johansen Test Results (det_order={det_order})')\n",
    "    print('Trace Statistics:', result.trace_stat)\n",
    "    print('Critical Values (Trace):', result.trace_stat_crit_vals)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(df):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        adf = adfuller(df[column])\n",
    "        kp = kpss(df[column])\n",
    "        if adf[1] > 0.05 and kp[1] < 0.05:\n",
    "            print(f'{column} is non-stationary. Differencing the data.')\n",
    "            df[column] = df[column].diff().dropna()\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_dfs = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print()\n",
    "    \n",
    "    df = check_stationarity(station_df)\n",
    "    \n",
    "    coint_df = pd.DataFrame(columns=df.columns, index=df.columns)\n",
    "    \n",
    "    # perfrom Engle-Granger test\n",
    "    for column in df.columns:\n",
    "        for column2 in df.columns:\n",
    "            if column == column2:\n",
    "                continue\n",
    "            result = coint(df[column], df[column2])\n",
    "            \n",
    "            if result[1] < 0.05:\n",
    "                coint_df.loc[column, column2] = True\n",
    "            else:\n",
    "                coint_df.loc[column, column2] = False\n",
    "                \n",
    "    coint_dfs[station_id] = coint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_df\n",
    "\n",
    "# the row is cointrated with the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    station_df = check_stationarity(station_df)\n",
    "    \n",
    "    aic, bic, fpe, hqic = [], [], [], []\n",
    "    model = VAR(station_df)\n",
    "    if station_id == 105:\n",
    "        p = range(0, 7)\n",
    "    else:\n",
    "        p = range(0, 17)\n",
    "    for i in p:\n",
    "        result = model.fit(i)\n",
    "        aic.append(result.aic)\n",
    "        bic.append(result.bic)\n",
    "        fpe.append(result.fpe)\n",
    "        hqic.append(result.hqic)\n",
    "    lags_metrics_df = pd.DataFrame({'AIC': aic, \n",
    "                                    'BIC': bic, \n",
    "                                    'HQIC': hqic,\n",
    "                                    'FPE': fpe}, \n",
    "                                index=p)    \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15, 3), sharex=True)\n",
    "    lags_metrics_df.plot(subplots=True, ax=ax, marker='o')\n",
    "    \n",
    "    # set the title\n",
    "    plt.suptitle(f\"Station {station_id}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max lag = 1 for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate case\n",
    "\n",
    "def check_stationarity(dataframe):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use mann-kendall test\n",
    "    result = mk.original_test(dataframe)\n",
    "    if result.trend == 'no trend':\n",
    "        print(f'{column} has no trend. Differencing the data.')\n",
    "        dataframe = dataframe.diff().dropna()\n",
    "        dataframe = check_stationarity(dataframe)\n",
    "    return dataframe.dropna()\n",
    "\n",
    "def grangers_causation_matrix_multivariate(data, maxlag=12, test='ssr_chi2test', verbose=False):\n",
    "    \"\"\"\n",
    "    Check Granger Causality in a multivariate setting.\n",
    "    \"\"\"\n",
    "    variables = data.columns\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "        \n",
    "    # Ensure data is stationary\n",
    "    for column in data.columns:\n",
    "        data_column = check_stationarity(data[[column]])\n",
    "        data[column] = data_column\n",
    "    \n",
    "    # Select the optimal lag length for the VAR model\n",
    "    \n",
    "    # Fit the VAR model\n",
    "    model = VAR(data)\n",
    "    model_fitted = model.fit(maxlags=maxlag)\n",
    "    \n",
    "    for r in variables:\n",
    "        for c in variables:\n",
    "            if c != r:\n",
    "                test_result = model_fitted.test_causality(c, r, kind=test, verbose=verbose)\n",
    "                p_value = round(test_result.pvalue, 4)\n",
    "                df.loc[r, c] = p_value\n",
    "                if verbose:\n",
    "                    print(f'Y = {r}, X = {c}, P-Value = {p_value}')\n",
    "            else:\n",
    "                df.loc[r, c] = 1\n",
    "                \n",
    "    \n",
    "    \n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    \n",
    "    return df, model_fitted.summary(), model_fitted.irf(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    causality_matrix, summary, irf = grangers_causation_matrix_multivariate(station_df.drop(columns=diff_columns + bacteria_columns).dropna(), maxlag=1)\n",
    "    \n",
    "    causality_matrices[station_id] = causality_matrix\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print(summary)\n",
    "    \n",
    "    ax = irf.plot(orth=True)\n",
    "    ax.set_size_inches(40, 20)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the cointration matrix is consistent with the Granger Causality matrix\n",
    "# if the cointration matrix is True, then the Granger Causality matrix should have a p-value < 0.05\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    coint_df = coint_dfs[station_id]\n",
    "    causality_matrix = causality_matrices[station_id]\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print()\n",
    "    \n",
    "    count = 0\n",
    "    cons_count = 0\n",
    "    \n",
    "    for column in coint_df.columns:\n",
    "        for column2 in coint_df.columns:\n",
    "            \n",
    "            if column == column2:\n",
    "                continue\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if coint_df.loc[column, column2]:\n",
    "                if causality_matrix.loc[column + '_y', column2 + '_x'] < 0.05:\n",
    "                    print(f\"{column} -> {column2} is consistent\")\n",
    "                    cons_count += 1\n",
    "                else:\n",
    "                    print(f\"{column} -> {column2} is not consistent\")\n",
    "            else:\n",
    "                if causality_matrix.loc[column + '_y', column2 + '_x'] < 0.05:\n",
    "                    print(f\"{column} -> {column2} is not consistent\")\n",
    "                else:\n",
    "                    print(f\"{column} -> {column2} is consistent\")\n",
    "                    cons_count += 1\n",
    "                    \n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print(f\"Consistency: {cons_count}/{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=causality_matrix.values,\n",
    "            x=causality_matrix.columns,\n",
    "            y=causality_matrix.index,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    annotations = []\n",
    "    for i in range(causality_matrix.shape[0]):\n",
    "        for j in range(causality_matrix.shape[1]):\n",
    "            \n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            value = causality_matrix.iloc[i, j]\n",
    "            if value < 0.05:\n",
    "                annotations.append(\n",
    "                    dict(\n",
    "                        x=causality_matrix.columns[j],\n",
    "                        y=causality_matrix.index[i],\n",
    "                        text=f\"{value:.2f}\",\n",
    "                        showarrow=False,\n",
    "                        font=dict(color=\"white\"),\n",
    "                        xref=\"x\",\n",
    "                        yref=\"y\"\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Granger Causality p-value Matrix - Station {station_id}\",\n",
    "        xaxis_title=\"X\",\n",
    "        yaxis=dict(\n",
    "            title=\"Y\",\n",
    "            autorange='reversed'  # Reverse the order of the y-axis\n",
    "        ),\n",
    "        annotations= annotations + [\n",
    "                dict(\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    x=-0.2,\n",
    "                    y=-0.6,\n",
    "                    showarrow=False,\n",
    "                    text='Note: if a given p-value is < significance level (0.05), then, <br> the corresponding X series (column) causes the Y (row).',\n",
    "                    font=dict(\n",
    "                        size=12\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results in an excel file\n",
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    causality_matrix.to_excel(os.path.join(surface_plot_folder, 'granger', f\"{station_id}.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Granger Causality Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    matrix = causality_matrices[station_id]\n",
    "\n",
    "    # remove the _x and _y from the column names\n",
    "    matrix.columns = matrix.columns.str.replace('_x', '')\n",
    "    matrix.index = matrix.index.str.replace('_y', '')\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes for all effects (rows) and causes (columns)\n",
    "    G.add_nodes_from(matrix.columns, bipartite=0)  # Causes\n",
    "    G.add_nodes_from(matrix.index, bipartite=1)    # Effects\n",
    "\n",
    "    # Add edges for significant Granger causality (p-value < 0.05)\n",
    "    threshold = 0.05\n",
    "    for cause in matrix.columns:\n",
    "        for effect in matrix.index:\n",
    "            if matrix.loc[effect, cause] < threshold:\n",
    "                G.add_edge(cause, effect)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=3000, edge_color='black',\n",
    "            arrows=True, arrowsize=20, font_size=12, font_color='darkblue')\n",
    "    plt.title(f\"Granger Causality Graph - Station {station_id}\")\n",
    "\n",
    "    # make the plot wider\n",
    "    plt.savefig(\n",
    "        os.path.join(paper_plots_folder, 'Berlin', f\"granger_causality_{station_id}.png\"),\n",
    "        bbox_inches='tight',\n",
    "        dpi=600\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate case\n",
    "\n",
    "def select_best_lag(data, maxlag):\n",
    "    \"\"\"\n",
    "    Select the best lag length using information criteria.\n",
    "    \"\"\"\n",
    "    model = VAR(data)\n",
    "    lag_order = model.select_order()\n",
    "    return lag_order.aic\n",
    "\n",
    "\n",
    "# Check for stationarity using both adfuller and kpss tests\n",
    "def check_stationarity(series):\n",
    "    # use mann-kendall test\n",
    "    result = mk.original_test(series)\n",
    "    if result.p < 0.05:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def grangers_causation_matrix(data, variables, maxlag=12, test='ssr_chi2test', verbose=False):\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    df = df.astype(object)\n",
    "    \n",
    "    lag_df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            if c != r:\n",
    "                granger_df = data[[c, r]]\n",
    "                if data[c].isna().any() or data[r].isna().any():\n",
    "                    granger_df = granger_df[[r, c]].dropna()\n",
    "                \n",
    "                try:\n",
    "                    adfuller(granger_df[c])\n",
    "                    adfuller(granger_df[r])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                \n",
    "                if not check_stationarity(granger_df[c]):\n",
    "                    print(f\"{c} is non-stationary\")\n",
    "                    print(\"Differencing data\")\n",
    "                    granger_df[c] = granger_df[c].diff().dropna()\n",
    "                \n",
    "                if not check_stationarity(granger_df[r]):\n",
    "                    print(f\"{r} is non-stationary\")\n",
    "                    print(\"Differencing data\")\n",
    "                    granger_df[r] = granger_df[r].diff().dropna()\n",
    "                    \n",
    "                granger_df.dropna(inplace=True)\n",
    "                \n",
    "                # Select the best lag\n",
    "                # selected_lag = select_best_lag(granger_df, maxlag)\n",
    "                \n",
    "                test_result = grangercausalitytests(granger_df, maxlag=10, verbose=False)\n",
    "                \n",
    "                # p_values = [round(test_result[i+1][0][test][1], 4) for i in range(selected_lag)]\n",
    "                \n",
    "                # the lag is the index of the list + 1\n",
    "                # store all the p-values to make a plot later\n",
    "                p_values = [round(test_result[i+1][0][test][1], 4) for i in range(10)]\n",
    "                statistics = [test_result[i+1][0][test][0] for i in range(10)]\n",
    "                \n",
    "                # need to store as list to avoid the error\n",
    "                \n",
    "                # store both the p values and the statistics in the same cell of df\n",
    "                df.loc[r, c] = [p_values, statistics]\n",
    "                \n",
    "            else:\n",
    "                df.loc[r, c] = 1\n",
    "                \n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    \n",
    "    return df, lag_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices = {}\n",
    "lag_matrices = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    causality_matrix, lag_matrix = grangers_causation_matrix(station_df, variables=station_df.columns.difference(diff_columns + bacteria_columns), maxlag=12)\n",
    "    \n",
    "    causality_matrices[station_id] = causality_matrix\n",
    "    lag_matrices[station_id] = lag_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices[station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    \n",
    "    for i in range(causality_matrix.shape[0]):\n",
    "        for j in range(causality_matrix.shape[1]):\n",
    "            if i != j:\n",
    "                test_result = causality_matrix.iloc[i, j]\n",
    "                \n",
    "                # check if the test result is a list\n",
    "                if not isinstance(test_result, list):\n",
    "                    continue\n",
    "                \n",
    "                p_values = test_result[0]\n",
    "                statistics = test_result[1]\n",
    "                \n",
    "                lags = np.arange(1, len(p_values) + 1)\n",
    "                \n",
    "                fig = go.Figure()\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=lags,\n",
    "                        y=p_values,\n",
    "                        mode='lines',\n",
    "                        name='P-Value'\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # fig.add_trace(\n",
    "                #     go.Scatter(\n",
    "                #         x=lags,\n",
    "                #         y=statistics,\n",
    "                #         mode='lines',\n",
    "                #         name='F-Statistic'\n",
    "                #     )\n",
    "                # )\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    title=f\"Station {station_id} - Granger Causality Test - {causality_matrix.columns[j]} -> {causality_matrix.index[i]}\",\n",
    "                    xaxis_title=\"Lag\",\n",
    "                    yaxis_title=\"Value\"\n",
    "                )\n",
    "                \n",
    "                fig.show()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, lag_matrix in lag_matrices.items():\n",
    "    \n",
    "    px.imshow(\n",
    "        lag_matrix,\n",
    "        labels=dict(x=\"X\", y=\"Y\", color=\"Lag\"),\n",
    "        title=f\"Lag Matrix - Station {station_id}\",\n",
    "        text_auto=True,\n",
    "        color_continuous_scale='Viridis',\n",
    "        width=800,\n",
    "        height=800\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb(200, 2, 110)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns)\n",
    "    \n",
    "    # Analysis post Berlin Wall Fall\n",
    "    station_df = station_df[station_df.index >= \"1992-01-01\"]\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'ds': station_df.index,\n",
    "            'y': station_df[column]\n",
    "        })\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        \n",
    "        # compute linear regression on trend\n",
    "        X = np.arange(df.dropna().shape[0])\n",
    "        X = sm.add_constant(X)\n",
    "        y = df[\"y\"].dropna().copy()\n",
    "        \n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "        \n",
    "        # get the slope\n",
    "        slope = results.params.iloc[1]\n",
    "        \n",
    "        # compute the decade increase or decrease\n",
    "        variation = slope * 120\n",
    "        \n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name='Historical',\n",
    "                line=dict(\n",
    "                    color='black',\n",
    "                    width=0.6\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=forecast['trend'],\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # get the unit of measure for the column\n",
    "        uom = column.split('(')[-1].replace(')', '')\n",
    "        \n",
    "        # add a box with the variation with the plus or minus sign\n",
    "        fig.add_annotation(\n",
    "            go.layout.Annotation(\n",
    "                x=0.05,\n",
    "                y=0.95,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                text=f\"Decade Variation: +{variation:.2f} {uom}\" if variation > 0 else f\"Decade Variation: {variation:.2f} {uom}\",\n",
    "                showarrow=False,\n",
    "                font=dict(\n",
    "                    size=12,\n",
    "                    color='red'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Time\",\n",
    "            yaxis_title=f\"{column}\"\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(os.path.join(surface_plot_folder, 'trends', f\"station_{station_id}\")):\n",
    "            os.makedirs(os.path.join(surface_plot_folder, 'trends', f\"station_{station_id}\")) \n",
    "            \n",
    "        column_ = column.replace(\"/\", \"_\")\n",
    "        \n",
    "        # fig.write_image(\n",
    "        #     os.path.join(\n",
    "        #         surface_plot_folder,\n",
    "        #         'trends',\n",
    "        #         f\"station_{station_id}\",\n",
    "        #         f\"{column_}.png\"\n",
    "        #     ),\n",
    "        #     scale=3\n",
    "        # )\n",
    "        \n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform trend analysis for each month\n",
    "\n",
    "# Build interaction plot\n",
    "\n",
    "months = surface_df['DateTime'].dt.month.unique()\n",
    "months.sort()\n",
    "\n",
    "# Get the names of the months\n",
    "months_name = [pd.to_datetime(f\"{month}-01-2021\").strftime(\"%B\") for month in months]\n",
    "\n",
    "# Create dataframe to store the adf and mann-kendall test results for each station for each month\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([surface_df.columns.difference(diff_columns + bacteria_columns), months_name]),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), ['ADF p-value', 'ADF result', 'MK p-value', 'MK result', 'Slope', 'Slope p-value', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "# Calculate global min and max for each variable\n",
    "global_min_max = {}\n",
    "for column in surface_df.columns.difference(diff_columns + bacteria_columns):\n",
    "    global_min_max[column] = (surface_df[column].min(), surface_df[column].max())\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns)\n",
    "    \n",
    "    # Analysis post Berlin Wall Fall\n",
    "    station_df = station_df[station_df.index >= \"1992-01-01\"]\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            4,\n",
    "            3,\n",
    "            subplot_titles=months_name,\n",
    "            vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "            horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        )\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            \n",
    "            month_df = station_df[station_df.index.month == month]\n",
    "                       \n",
    "            # Perform Augmented Dickey-Fuller test\n",
    "            try:\n",
    "                adf_result = adfuller(month_df[column].dropna(), autolag=\"AIC\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            # Perform Mann-Kendall test\n",
    "            mk_result = mk.original_test(month_df[column])\n",
    "            \n",
    "            # Store the results in the statistics dataframe\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'ADF p-value')] = adf_result[1]\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'ADF result')] = 'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'\n",
    "            \n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'MK p-value')] = mk_result.p\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'MK result')] = mk_result.trend\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': month_df.index,\n",
    "                'y': month_df[column]\n",
    "            })\n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df)\n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute linear regression on trend\n",
    "            X = np.arange(df.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = df[\"y\"].copy()\n",
    "\n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            \n",
    "            # store the slope\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Slope')] = slope\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Slope p-value')] = p_value\n",
    "            \n",
    "            # calculate the percentage of the trend\n",
    "            first_value = forecast['trend'].iloc[0]\n",
    "            last_value = forecast['trend'].iloc[-1]\n",
    "            \n",
    "            trend_percentage = (last_value - first_value) / first_value * 100\n",
    "            \n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Trend Percentage')] = trend_percentage\n",
    "                \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=month_df.index,\n",
    "                    y=month_df[column],\n",
    "                    mode='lines',\n",
    "                    name='Historical',\n",
    "                    line=dict(\n",
    "                        color='black',\n",
    "                        width=0.6\n",
    "                    ),\n",
    "                    showlegend=True if column not in legend_added else False\n",
    "                ),\n",
    "                row=(i // 3) + 1,\n",
    "                col=(i % 3) + 1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=forecast['ds'],\n",
    "                    y=forecast['trend'],\n",
    "                    mode='lines',\n",
    "                    name='Trend',\n",
    "                    line=dict(color='blue'),\n",
    "                    showlegend=True if column not in legend_added else False\n",
    "                ),\n",
    "                row=(i // 3) + 1,\n",
    "                col=(i % 3) + 1\n",
    "            )\n",
    "            \n",
    "            legend_added.add(column)\n",
    "            \n",
    "        # Set the same y-axis range for all subplots\n",
    "        fig.update_yaxes(range=global_min_max[column])\n",
    "        \n",
    "        fig.add_annotation(dict(\n",
    "            x=0.5,\n",
    "            y=-0.08,\n",
    "            showarrow=False,\n",
    "            text=\"Time\",\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            font=dict(size=20)\n",
    "        ))\n",
    "\n",
    "        fig.add_annotation(dict(\n",
    "            x=-0.08,\n",
    "            y=0.5,\n",
    "            showarrow=False,\n",
    "            text=column,\n",
    "            textangle=-90,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            font=dict(size=20)\n",
    "        )) \n",
    "            \n",
    "        fig.update_layout(\n",
    "            height=1000,\n",
    "            width=1200,\n",
    "            title={\n",
    "                'text': f\"Station {station_id}\",\n",
    "                'y': 0.98,  # Vertical position\n",
    "                'x': 0.5,  # Horizontal position\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'\n",
    "            },\n",
    "            font=dict(size=18),\n",
    "            margin=dict(t=80, l=80, b=100, r=40)  # Adjust margins\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(os.path.join(surface_plot_folder, 'trends', 'monthwise', f\"station_{station_id}\")):\n",
    "            os.makedirs(os.path.join(surface_plot_folder, 'trends', 'monthwise', f\"station_{station_id}\")) \n",
    "            \n",
    "        column_ = column.replace(\"/\", \"_\")\n",
    "        \n",
    "        fig.write_image(\n",
    "            os.path.join(\n",
    "                surface_plot_folder,\n",
    "                'trends',\n",
    "                'monthwise',\n",
    "                f\"station_{station_id}\",\n",
    "                f\"{column_}.png\"\n",
    "            ),\n",
    "            scale=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_excel(os.path.join(surface_plot_folder, 'trends', 'monthwise', \"statistics.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Correlation (lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(df):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        adf = adfuller(df[column])\n",
    "        kp = kpss(df[column])\n",
    "        if adf[1] > 0.05 and kp[1] < 0.05:\n",
    "            print(f'{column} is non-stationary. Differencing the data.')\n",
    "            df[column] = df[column].diff().dropna()\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_corr(ts1, ts2, max_lag):\n",
    "    lags = range(-max_lag, max_lag + 1)\n",
    "    cross_corr = [ts1.corr(ts2.shift(lag)) for lag in lags]\n",
    "    return lags, cross_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a time series is stationary, if not, difference it\n",
    "\n",
    "correlation_results_df = pd.DataFrame(\n",
    "    index=surface_df.columns.difference(diff_columns + bacteria_columns),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), surface_df.columns.difference(diff_columns + bacteria_columns)])\n",
    ")\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    station_df = check_stationarity(station_df)\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in station_df.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "        \n",
    "    \n",
    "    max_lag = 12\n",
    "    \n",
    "    for column in station_df.columns:\n",
    "        for column2 in station_df.columns:\n",
    "            if column == column2:\n",
    "                continue\n",
    "            \n",
    "            lags, cross_corr = compute_cross_corr(station_df[column], station_df[column2], max_lag)\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=list(lags),\n",
    "                    y=cross_corr,\n",
    "                    mode='lines+markers',\n",
    "                    name='Cross Correlation'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs {column2}\",\n",
    "                xaxis_title=\"Lag (Months)\",\n",
    "                yaxis_title=\"Cross Correlation\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(os.path.join(surface_cross_corr_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(surface_cross_corr_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            column2_ = column2.replace(\"/\", \"_\")\n",
    "                \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    surface_cross_corr_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}_vs_{column2_}.png\"\n",
    "                ),\n",
    "                scale=3\n",
    "            )\n",
    "            \n",
    "            corr, pvalue = pearsonr(station_df[column], station_df[column2])\n",
    "            \n",
    "            # put the correlation just if the p-value is less than 0.05 and in the upper triangle\n",
    "            if pvalue < 0.05:\n",
    "                correlation_results_df.loc[column, (station_id, column2)] = corr\n",
    "            else:\n",
    "                correlation_results_df.loc[column, (station_id, column2)] = np.nan\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results_df.to_excel(os.path.join(surface_cross_corr_folder, \"correlation_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year by Year Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform year by year correlation\n",
    "correlation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([surface_df.columns.difference(diff_columns + bacteria_columns), sorted(surface_df['DateTime'].dt.year.unique())]),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), surface_df.columns.difference(diff_columns + bacteria_columns)])\n",
    ")\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    if station_id == 305:\n",
    "            # remove flow river\n",
    "            station_df.drop(\n",
    "                columns=['Flow River Rate (m³/s)'],\n",
    "                inplace=True\n",
    "            )\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns).dropna()\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "    \n",
    "    correlation_results[station_id] = {}\n",
    "    \n",
    "    for year in station_df['DateTime'].dt.year.unique():\n",
    "        \n",
    "        year_df = station_df[station_df['DateTime'].dt.year == year]\n",
    "        \n",
    "        year_df.drop(columns=diff_columns, inplace=True)\n",
    "        \n",
    "        for column in year_df.columns:\n",
    "            for column2 in year_df.columns:\n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                result = pearsonr(year_df[column], year_df[column2])\n",
    "                \n",
    "                correlation_results.loc[(column, year), (station_id, column2)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation results\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "        \n",
    "        station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "        \n",
    "        station_df = station_df.drop(columns=bacteria_columns).dropna()\n",
    "        \n",
    "        station_df.set_index('DateTime', inplace=True)\n",
    "        \n",
    "        for column in station_df.columns.difference(diff_columns):\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            for column2 in station_df.columns.difference(diff_columns):\n",
    "                \n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                years = correlation_results.loc[column, (station_id, column2)].index\n",
    "                \n",
    "                correlation = correlation_results.loc[(column, years), (station_id, column2)].dropna()            \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=correlation.index.get_level_values(1),\n",
    "                        y=correlation.apply(lambda x: x[0]),\n",
    "                        mode='lines+markers',\n",
    "                        name=column2\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs Other Parameters\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Pearson Correlation Coefficient\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(os.path.join(surface_corr_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(surface_corr_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            \n",
    "            fig.update_yaxes(range=[-1, 1])\n",
    "            \n",
    "            # add a horizontal line at 0\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=years.min(),\n",
    "                y0=0,\n",
    "                x1=years.max(),\n",
    "                y1=0,\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    surface_corr_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}.png\"\n",
    "                ),\n",
    "                scale=3,\n",
    "                width=1200,\n",
    "            )\n",
    "            \n",
    "            if station_id == 305:\n",
    "                fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results.to_excel(os.path.join(surface_corr_folder, \"correlation_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression for Average Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Month by Month Variation for each Year\n",
    "\n",
    "A time series of each year is built, the trend is computed with Prophet and a linear regression on the trend is computed in order to get the slope, which is the average month variation for the given year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform trend analysis for each year\n",
    "\n",
    "# build interaction plot\n",
    "\n",
    "years = surface_df['DateTime'].dt.year.unique()\n",
    "years.sort()\n",
    "\n",
    "# convert the years to int\n",
    "years = [int(year) for year in years]\n",
    "\n",
    "# create dataframe to store the adf and mann-kendall test results for each station for each year\n",
    "slopes_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([surface_df.columns.difference(diff_columns + bacteria_columns), years]),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), ['Slope', 'P-Value', 'Error', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns)\n",
    "    \n",
    "    # station_df.dropna(inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        # fig = make_subplots(\n",
    "        #     4,\n",
    "        #     3,\n",
    "        #     subplot_titles=years,\n",
    "        #     vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "        #     horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        # )\n",
    "        \n",
    "        for i, year in enumerate(years):\n",
    "            \n",
    "            year_df = station_df[station_df.index.year == year]\n",
    "            \n",
    "            # if the dataframe contains only NaN values, skip the year\n",
    "            if year_df[column].isna().all():\n",
    "                continue\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': year_df.index,\n",
    "                'y': year_df[column]\n",
    "            })\n",
    "             \n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            \n",
    "            model.fit(df)    \n",
    "            \n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute the linear regression on the trend\n",
    "            X = np.arange(forecast.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = forecast['trend'].copy()\n",
    "            \n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            st_error = results.bse.iloc[1]\n",
    "            \n",
    "            # store the results in the dataframe\n",
    "            slopes_df.loc[(column, year), (station_id, 'Slope')] = round(slope, 4)\n",
    "            slopes_df.loc[(column, year), (station_id, 'P-Value')] = round(p_value, 4)\n",
    "            slopes_df.loc[(column, year), (station_id, 'Error')] = round(st_error, 4)\n",
    "            \n",
    "            # compute the percentage of the trend\n",
    "            trend_percentage = (slope / forecast['trend'].mean()) * 100\n",
    "            slopes_df.loc[(column, year), (station_id, 'Trend Percentage')] = round(trend_percentage, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_df.to_excel(os.path.join(surface_plot_folder, 'trends', \"slopes.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year by Year Variation for each Month\n",
    "\n",
    "A time series of each month is built, the trend is computed with Prophet and a linear regression on the trend is computed in order to get the slope, which is the average year variation for the given month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform trend analysis for each month\n",
    "\n",
    "# build interaction plot\n",
    "\n",
    "months = surface_df['DateTime'].dt.month.unique()\n",
    "months.sort()\n",
    "\n",
    "# get the names of the months\n",
    "months_name = [pd.to_datetime(f\"{month}-01-2021\").strftime(\"%B\") for month in months]\n",
    "\n",
    "# create dataframe to store the adf and mann-kendall test results for each station for each month\n",
    "slopes_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([surface_df.columns.difference(diff_columns + bacteria_columns), months_name]),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), ['Slope', 'P-Value', 'Error', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        # fig = make_subplots(\n",
    "        #     4,\n",
    "        #     3,\n",
    "        #     subplot_titles=months_name,\n",
    "        #     vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "        #     horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        # )\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            \n",
    "            month_df = station_df[station_df.index.month == month]\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': month_df.index,\n",
    "                'y': month_df[column]\n",
    "            })\n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df)\n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute the linear regression on the trend\n",
    "            X = np.arange(forecast.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = forecast['trend'].copy()\n",
    "            \n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            st_error = results.bse.iloc[1]\n",
    "            \n",
    "            # store the results in the dataframe\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Slope')] = slope\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'P-Value')] = p_value\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Error')] = st_error\n",
    "            \n",
    "            # compute the percentage of the trend\n",
    "            trend_percentage = (slope / forecast['trend'].mean()) * 100\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Trend Percentage')] = trend_percentage\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_df.to_excel(os.path.join(surface_plot_folder, 'trends', 'monthwise', \"slopes.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per il momento lascia qua, potrebbe tornare utile se si decidesse di calcolare una linear regression tra ogni changepoint\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns + bacteria_columns):\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                'ds': station_df.index,\n",
    "                'y': station_df[column]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        \n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # add the changepoints detected by Prophet\n",
    "        changepoints = model.changepoints\n",
    "    \n",
    "        signif_changepoints = changepoints[\n",
    "            np.abs(np.nanmean(model.params['delta'], axis=0)) >= 0.1\n",
    "        ]\n",
    "        \n",
    "        changepoints_values = forecast.loc[forecast['ds'].isin(signif_changepoints), 'trend']\n",
    "        \n",
    "        trend = forecast['trend']\n",
    "        \n",
    "        # compute linear regression on trend\n",
    "        X = np.arange(trend.shape[0])\n",
    "        X = sm.add_constant(X)\n",
    "        y = trend.copy()\n",
    "        \n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "        \n",
    "        # plot the line of the linear regression\n",
    "        line = pd.Series(results.predict(X), index=forecast['ds'])\n",
    "        \n",
    "        # get the slope with the p-value and the standard error\n",
    "        slope = results.params.iloc[1]\n",
    "        p_value = results.pvalues.iloc[1]\n",
    "        std_err = results.bse.iloc[1]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name='Original',\n",
    "                line=dict(color='black')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=trend,\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=line.index,\n",
    "                y=line,\n",
    "                mode='lines',\n",
    "                name='Linear Regression',\n",
    "                line=dict(color='red', dash='dash')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=signif_changepoints,\n",
    "                y=changepoints_values,\n",
    "                mode='markers',\n",
    "                name='Changepoints',\n",
    "                marker=dict(\n",
    "                    color='green',\n",
    "                    size=10\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"{column} - Slope: {slope:.3f}, P-Value: {p_value:.3f}, Std. Error: {std_err:.3f}\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Value\"\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Comparison same axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = surface_df.columns.difference(diff_columns + bacteria_columns)\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    for first_col, second_col in combinations(feature_columns, 2):\n",
    "        \n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[first_col],\n",
    "                mode='lines',\n",
    "                name=first_col\n",
    "            ),\n",
    "            secondary_y=False\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[second_col],\n",
    "                mode='lines',\n",
    "                name=second_col\n",
    "            ),\n",
    "            secondary_y=True\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"Station {station_id} - {first_col} vs {second_col}\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis=dict(\n",
    "                title=first_col,\n",
    "                showgrid=False\n",
    "            ),\n",
    "            yaxis2=dict(\n",
    "                title=second_col,\n",
    "                overlaying='y',\n",
    "                side='right'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if station_id == 305:\n",
    "            fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Tests on Stationarity and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to store the adf and mann-kendall test results for each station\n",
    "\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=ground_df.columns.difference(diff_columns),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ['ADF p-value', 'ADF result', 'MK p-value', 'MK result', 'Slope', 'Slope p-value']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in ground_df[\"Station\"].unique():\n",
    "    station_df = ground_df[ground_df[\"Station\"] == station_id].copy()\n",
    "\n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        df = station_df[[\"DateTime\", column]].copy()\n",
    "\n",
    "        df.set_index(\"DateTime\", inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        date_range = df.index\n",
    "        date_range = date_range.min(), date_range.max()\n",
    "\n",
    "        # make sure that the dataframe starts and finishes in the same month\n",
    "        start_index = df[df.index.month == date_range[1].month].index[0]\n",
    "\n",
    "        # Slice the dataframe to start from the found index\n",
    "        df = df.loc[start_index:]\n",
    "\n",
    "        # ===== Prophet =====\n",
    "\n",
    "        df.index.name = \"ds\"\n",
    "\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df.rename(columns={column: \"y\"}, inplace=True)\n",
    "\n",
    "        # using prophet\n",
    "\n",
    "        model = Prophet()\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Merging forecasted data with your original data\n",
    "        forecasting_final = pd.merge(\n",
    "            forecast,\n",
    "            df,\n",
    "            how=\"inner\",\n",
    "            on=\"ds\",\n",
    "        )\n",
    "\n",
    "        # compute linear regression on trend\n",
    "        X = np.arange(df.shape[0])\n",
    "        X = sm.add_constant(X)\n",
    "        y = df[\"y\"].copy()\n",
    "\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        # plot the line of the linear regression\n",
    "        line = pd.Series(results.predict(X), index=df['ds'])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['ds'],\n",
    "                y=df[\"y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Original\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecasting_final[\"ds\"],\n",
    "                y=forecasting_final[\"trend\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Trend\",\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # perfrom Augmented Dickey-Fuller test\n",
    "        adf_result = adfuller(df[\"y\"], autolag=\"AIC\") if df['y'].unique().shape[0] > 1 else (0, 1, 0, 0, 0, 0)\n",
    "        # perform KPSS test\n",
    "        kpss_result = kpss(df[\"y\"])\n",
    "        \n",
    "        # perfrom Mann-Kendall test        \n",
    "        mk_result = mk.original_test(df[\"y\"] - forecasting_final['yearly'])\n",
    "        \n",
    "        print()\n",
    "        print(f\"{column} - Augmented Dickey-Fuller Test\")\n",
    "        print(f\"ADF P-value: {adf_result[1]:.4f}\")\n",
    "        print(f\"Lag used: {adf_result[2]}\")\n",
    "        if adf_result[1] > 0.05:\n",
    "            print(\"Unit root present, data is non-stationary\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"{column} - KPSS Test\")\n",
    "        print(f\"KPSS P-value: {kpss_result[1]:.4f}\")\n",
    "        if kpss_result[1] < 0.05:\n",
    "            print(\"Unit root present, data is non-stationary\")\n",
    "        print()\n",
    "        \n",
    "        if (adf_result[1] > 0.05 and kpss_result[1] < 0.05) or (adf_result[1] < 0.05 and kpss_result[1] > 0.05):\n",
    "            print(\"=== Consistency between tests! ===\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"{column} - Mann-Kendall Test\")\n",
    "        print(f\"Monotonic Trend: {mk_result.trend}\")\n",
    "        print(f\"p-value: {mk_result.p:.4f}\")\n",
    "        print()\n",
    "        slope = results.params.iloc[1]\n",
    "        print(f\"{column} - Slope: {slope}\")\n",
    "\n",
    "        p_value = results.pvalues.iloc[1]\n",
    "        print(f\"{column} - P-value: {p_value}\")\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'ADF p-value')] = adf_result[1]\n",
    "        statistics_df.loc[column, (station_id, 'ADF result')] = 'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'MK p-value')] = mk_result.p\n",
    "        statistics_df.loc[column, (station_id, 'MK result')] = mk_result.trend\n",
    "        \n",
    "        statistics_df.loc[column, (station_id, 'Slope')] = slope\n",
    "        statistics_df.loc[column, (station_id, 'Slope p-value')] = p_value\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=line.index,\n",
    "                y=line,\n",
    "                mode=\"lines\",\n",
    "                name=f\"Linear Regression\",\n",
    "                line=dict(dash=\"dash\", color=\"black\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        start_date = df['ds'].min()\n",
    "        end_date = df['ds'].max()\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=column,\n",
    "            font=dict(\n",
    "                size=18,\n",
    "            ),\n",
    "            title=f\"{station_id} - {column} - {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}\",\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_excel(os.path.join(ground_plot_folder, 'trends', \"statistics.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    for column in station_df.columns.difference(['DateTime', 'Station']):\n",
    "        \n",
    "        print(f\"{station_id} - {column}\")\n",
    "        plot_acf(station_df[column], lags=20)\n",
    "        \n",
    "        \n",
    "        plot_pacf(station_df[column], lags=20)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causality and Cointegration\n",
    "\n",
    "\"If two or more time-series are cointegrated, then there must be Granger causality between them - either one-way or in both directions. However, the converse is not true.\"\n",
    "\n",
    "\"So, if your data are cointegrated but you don't find any evidence of causality, you have a conflict in your results. (This might occur if your sample size is too small to satisfy the asymptotics that the cointegration and causality tests rely on.) If you have cointegration and find one-way causality, everything is fine. (You may still be wrong about there being no causality in the other direction.) If your data are not cointegrated, then you have no cross-check on your causality results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Johansen test\n",
    "def johansen_test(data, det_order, k_ar_diff=1):\n",
    "    \"\"\"\n",
    "    Performs the Johansen cointegration test and prints the results.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): The time series data for the cointegration test.\n",
    "    det_order (int): The order of the deterministic terms.\n",
    "                     -1: No constant or trend.\n",
    "                      0: Constant term only.\n",
    "                      1: Constant and trend terms.\n",
    "    k_ar_diff (int): The number of lags to include in the VAR model.\n",
    "    \"\"\"\n",
    "    result = coint_johansen(data, det_order, k_ar_diff)\n",
    "    \n",
    "    print(f'Johansen Test Results (det_order={det_order})')\n",
    "    print('Trace Statistics:', result.trace_stat)\n",
    "    print('Critical Values (Trace):', result.trace_stat_crit_vals)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(df):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        adf = adfuller(df[column])\n",
    "        kp = kpss(df[column])\n",
    "        if adf[1] > 0.05 and kp[1] < 0.05:\n",
    "            print(f'{column} is non-stationary. Differencing the data.')\n",
    "            df[column] = df[column].diff().dropna()\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_dfs = {}\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns).dropna()\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print()\n",
    "    \n",
    "    df = check_stationarity(station_df)\n",
    "    \n",
    "    coint_df = pd.DataFrame(columns=df.columns, index=df.columns)\n",
    "    \n",
    "    # perfrom Engle-Granger test\n",
    "    for column in df.columns:\n",
    "        for column2 in df.columns:\n",
    "            if column == column2:\n",
    "                continue\n",
    "            result = coint(df[column], df[column2])\n",
    "            \n",
    "            if result[1] < 0.05:\n",
    "                coint_df.loc[column, column2] = True\n",
    "            else:\n",
    "                coint_df.loc[column, column2] = False\n",
    "                \n",
    "    coint_dfs[station_id] = coint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_df\n",
    "\n",
    "# the row is cointrated with the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns).dropna()\n",
    "    \n",
    "    station_df = check_stationarity(station_df)\n",
    "    \n",
    "    aic, bic, fpe, hqic = [], [], [], []\n",
    "    model = VAR(station_df)\n",
    "    if station_id == 105:\n",
    "        p = range(0, 7)\n",
    "    else:\n",
    "        p = range(0, 17)\n",
    "    for i in p:\n",
    "        result = model.fit(i)\n",
    "        aic.append(result.aic)\n",
    "        bic.append(result.bic)\n",
    "        fpe.append(result.fpe)\n",
    "        hqic.append(result.hqic)\n",
    "    lags_metrics_df = pd.DataFrame({'AIC': aic, \n",
    "                                    'BIC': bic, \n",
    "                                    'HQIC': hqic,\n",
    "                                    'FPE': fpe}, \n",
    "                                index=p)    \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15, 3), sharex=True)\n",
    "    lags_metrics_df.plot(subplots=True, ax=ax, marker='o')\n",
    "    \n",
    "    # set the title\n",
    "    plt.suptitle(f\"Station {station_id}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max lag = 1 for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate case\n",
    "\n",
    "def check_stationarity(df):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        adf = adfuller(df[column])\n",
    "        kp = kpss(df[column])\n",
    "        if adf[1] > 0.05 and kp[1] < 0.05:\n",
    "            print(f'{column} is non-stationary. Differencing the data.')\n",
    "            df[column] = df[column].diff().dropna()\n",
    "    return df.dropna()\n",
    "\n",
    "def grangers_causation_matrix_multivariate(data, maxlag=12, test='ssr_chi2test', verbose=False):\n",
    "    \"\"\"\n",
    "    Check Granger Causality in a multivariate setting.\n",
    "    \"\"\"\n",
    "    variables = data.columns\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "        \n",
    "    # Ensure data is stationary\n",
    "    data = check_stationarity(data)\n",
    "    \n",
    "    # Select the optimal lag length for the VAR model\n",
    "    \n",
    "    # Fit the VAR model\n",
    "    model = VAR(data)\n",
    "    model_fitted = model.fit(maxlags=maxlag)\n",
    "    \n",
    "    for r in variables:\n",
    "        for c in variables:\n",
    "            if c != r:\n",
    "                test_result = model_fitted.test_causality(r, c, kind='f')\n",
    "                p_value = round(test_result.pvalue, 4)\n",
    "                df.loc[r, c] = p_value\n",
    "                if verbose:\n",
    "                    print(f'Y = {r}, X = {c}, P-Value = {p_value}')\n",
    "            else:\n",
    "                df.loc[r, c] = 1\n",
    "    \n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    \n",
    "    return df, model_fitted.summary(), model_fitted.irf(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices = {}\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    causality_matrix, summary, irf = grangers_causation_matrix_multivariate(station_df.drop(columns=diff_columns).dropna(), maxlag=1)\n",
    "    \n",
    "    causality_matrices[station_id] = causality_matrix\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print(summary)\n",
    "    \n",
    "    ax = irf.plot(orth=True)\n",
    "    ax.set_size_inches(40, 20)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the cointration matrix is consistent with the Granger Causality matrix\n",
    "# if the cointration matrix is True, then the Granger Causality matrix should have a p-value < 0.05\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    \n",
    "    coint_df = coint_dfs[station_id]\n",
    "    causality_matrix = causality_matrices[station_id]\n",
    "    \n",
    "    print(f\"Station {station_id}\")\n",
    "    print()\n",
    "    \n",
    "    count = 0\n",
    "    cons_count = 0\n",
    "    \n",
    "    for column in coint_df.columns:\n",
    "        for column2 in coint_df.columns:\n",
    "            \n",
    "            if column == column2:\n",
    "                continue\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if coint_df.loc[column, column2]:\n",
    "                if causality_matrix.loc[column + '_y', column2 + '_x'] < 0.05:\n",
    "                    print(f\"{column} -> {column2} is consistent\")\n",
    "                    cons_count += 1\n",
    "                else:\n",
    "                    print(f\"{column} -> {column2} is not consistent\")\n",
    "            else:\n",
    "                if causality_matrix.loc[column + '_y', column2 + '_x'] < 0.05:\n",
    "                    print(f\"{column} -> {column2} is not consistent\")\n",
    "                else:\n",
    "                    print(f\"{column} -> {column2} is consistent\")\n",
    "                    cons_count += 1\n",
    "                    \n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print(f\"Consistency: {cons_count}/{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=causality_matrix.values,\n",
    "            x=causality_matrix.columns,\n",
    "            y=causality_matrix.index,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    annotations = []\n",
    "    for i in range(causality_matrix.shape[0]):\n",
    "        for j in range(causality_matrix.shape[1]):\n",
    "            \n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            value = causality_matrix.iloc[i, j]\n",
    "            if value < 0.05:\n",
    "                annotations.append(\n",
    "                    dict(\n",
    "                        x=causality_matrix.columns[j],\n",
    "                        y=causality_matrix.index[i],\n",
    "                        text=f\"{value:.2f}\",\n",
    "                        showarrow=False,\n",
    "                        font=dict(color=\"white\"),\n",
    "                        xref=\"x\",\n",
    "                        yref=\"y\"\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Granger Causality p-value Matrix - Station {station_id}\",\n",
    "        xaxis_title=\"X\",\n",
    "        yaxis=dict(\n",
    "            title=\"Y\",\n",
    "            autorange='reversed'  # Reverse the order of the y-axis\n",
    "        ),\n",
    "        annotations= annotations + [\n",
    "                dict(\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    x=-0.2,\n",
    "                    y=-0.6,\n",
    "                    showarrow=False,\n",
    "                    text='Note: if a given p-value is < significance level (0.05), then, <br> the corresponding X series (column) causes the Y (row).',\n",
    "                    font=dict(\n",
    "                        size=12\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results in an excel file\n",
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    causality_matrix.to_excel(os.path.join(ground_plot_folder, 'granger', f\"{station_id}.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate case\n",
    "\n",
    "def select_best_lag(data, maxlag):\n",
    "    \"\"\"\n",
    "    Select the best lag length using information criteria.\n",
    "    \"\"\"\n",
    "    model = VAR(data)\n",
    "    lag_order = model.select_order()\n",
    "    return lag_order.aic\n",
    "\n",
    "\n",
    "# Check for stationarity using both adfuller and kpss tests\n",
    "def check_stationarity(series):\n",
    "    adf_result = adfuller(series)\n",
    "    kpss_result = kpss(series)\n",
    "    return adf_result[1] < 0.05 and kpss_result[1] < 0.05\n",
    "\n",
    "def grangers_causation_matrix(data, variables, maxlag=12, test='ssr_chi2test', verbose=False):\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    df = df.astype(object)\n",
    "    \n",
    "    lag_df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            if c != r:\n",
    "                granger_df = data[[c, r]]\n",
    "                if data[c].isna().any() or data[r].isna().any():\n",
    "                    granger_df = granger_df[[r, c]].dropna()\n",
    "                \n",
    "                try:\n",
    "                    adfuller(granger_df[c])\n",
    "                    adfuller(granger_df[r])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                \n",
    "                if not check_stationarity(granger_df[c]):\n",
    "                    print(f\"{c} is non-stationary\")\n",
    "                    print(\"Differencing data\")\n",
    "                    granger_df[c] = granger_df[c].diff().dropna()\n",
    "                \n",
    "                if not check_stationarity(granger_df[r]):\n",
    "                    print(f\"{r} is non-stationary\")\n",
    "                    print(\"Differencing data\")\n",
    "                    granger_df[r] = granger_df[r].diff().dropna()\n",
    "                    \n",
    "                granger_df.dropna(inplace=True)\n",
    "                \n",
    "                # Select the best lag\n",
    "                selected_lag = select_best_lag(granger_df, maxlag)\n",
    "                \n",
    "                test_result = grangercausalitytests(granger_df, maxlag=selected_lag, verbose=False)\n",
    "                \n",
    "                # p_values = [round(test_result[i+1][0][test][1], 4) for i in range(selected_lag)]\n",
    "                \n",
    "                # the lag is the index of the list + 1\n",
    "                # store all the p-values to make a plot later\n",
    "                p_values = [round(test_result[i+1][0][test][1], 4) for i in range(selected_lag)]\n",
    "                statistics = [test_result[i+1][0][test][0] for i in range(selected_lag)]\n",
    "                \n",
    "                # need to store as list to avoid the error\n",
    "                \n",
    "                # store both the p values and the statistics in the same cell of df\n",
    "                df.loc[r, c] = [p_values, statistics]\n",
    "                \n",
    "            else:\n",
    "                df.loc[r, c] = 1\n",
    "                \n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    \n",
    "    return df, lag_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices = {}\n",
    "lag_matrices = {}\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    causality_matrix, lag_matrix = grangers_causation_matrix(station_df, variables=station_df.columns.difference(diff_columns), maxlag=12)\n",
    "    \n",
    "    causality_matrices[station_id] = causality_matrix\n",
    "    lag_matrices[station_id] = lag_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causality_matrices[station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, causality_matrix in causality_matrices.items():\n",
    "    \n",
    "    for i in range(causality_matrix.shape[0]):\n",
    "        for j in range(causality_matrix.shape[1]):\n",
    "            if i != j:\n",
    "                test_result = causality_matrix.iloc[i, j]\n",
    "                \n",
    "                # check if the test result is a list\n",
    "                if not isinstance(test_result, list):\n",
    "                    continue\n",
    "                \n",
    "                p_values = test_result[0]\n",
    "                statistics = test_result[1]\n",
    "                \n",
    "                lags = np.arange(1, len(p_values) + 1)\n",
    "                \n",
    "                fig = go.Figure()\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=lags,\n",
    "                        y=p_values,\n",
    "                        mode='lines',\n",
    "                        name='P-Value'\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # fig.add_trace(\n",
    "                #     go.Scatter(\n",
    "                #         x=lags,\n",
    "                #         y=statistics,\n",
    "                #         mode='lines',\n",
    "                #         name='F-Statistic'\n",
    "                #     )\n",
    "                # )\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    title=f\"Station {station_id} - Granger Causality Test - {causality_matrix.columns[j]} -> {causality_matrix.index[i]}\",\n",
    "                    xaxis_title=\"Lag\",\n",
    "                    yaxis_title=\"Value\"\n",
    "                )\n",
    "                \n",
    "                fig.show()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, lag_matrix in lag_matrices.items():\n",
    "    \n",
    "    px.imshow(\n",
    "        lag_matrix,\n",
    "        labels=dict(x=\"X\", y=\"Y\", color=\"Lag\"),\n",
    "        title=f\"Lag Matrix - Station {station_id}\",\n",
    "        text_auto=True,\n",
    "        color_continuous_scale='Viridis',\n",
    "        width=800,\n",
    "        height=800\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb(200, 2, 110)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'ds': station_df.index,\n",
    "            'y': station_df[column]\n",
    "        })\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name='Historical',\n",
    "                line=dict(\n",
    "                    color='black',\n",
    "                    width=0.6\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=forecast['trend'],\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Time\",\n",
    "            yaxis_title=f\"{column}\"\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(os.path.join(ground_plot_folder, 'trends', f\"station_{station_id}\")):\n",
    "            os.makedirs(os.path.join(ground_plot_folder, 'trends', f\"station_{station_id}\")) \n",
    "            \n",
    "        column_ = column.replace(\"/\", \"_\")\n",
    "        \n",
    "        fig.write_image(\n",
    "            os.path.join(\n",
    "                ground_plot_folder,\n",
    "                'trends',\n",
    "                f\"station_{station_id}\",\n",
    "                f\"{column_}.png\"\n",
    "            ),\n",
    "            scale=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform trend analysis for each month\n",
    "\n",
    "# Build interaction plot\n",
    "\n",
    "months = ground_df['DateTime'].dt.month.unique()\n",
    "months.sort()\n",
    "\n",
    "# Get the names of the months\n",
    "months_name = [pd.to_datetime(f\"{month}-01-2021\").strftime(\"%B\") for month in months]\n",
    "\n",
    "# Create dataframe to store the adf and mann-kendall test results for each station for each month\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([ground_df.columns.difference(diff_columns), months_name]),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ['ADF p-value', 'ADF result', 'MK p-value', 'MK result', 'Slope', 'Slope p-value', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "# Calculate global min and max for each variable\n",
    "global_min_max = {}\n",
    "for column in ground_df.columns.difference(diff_columns):\n",
    "    global_min_max[column] = (ground_df[column].min(), ground_df[column].max())\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    \n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    # Analysis post Berlin Wall Fall\n",
    "    station_df = station_df[station_df.index >= \"1992-01-01\"]\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            4,\n",
    "            3,\n",
    "            subplot_titles=months_name,\n",
    "            vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "            horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        )\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            \n",
    "            month_df = station_df[station_df.index.month == month]\n",
    "                       \n",
    "            # Perform Augmented Dickey-Fuller test\n",
    "            try:\n",
    "                adf_result = adfuller(month_df[column].dropna(), autolag=\"AIC\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            # Perform Mann-Kendall test\n",
    "            mk_result = mk.original_test(month_df[column])\n",
    "            \n",
    "            # Store the results in the statistics dataframe\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'ADF p-value')] = adf_result[1]\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'ADF result')] = 'Stationary' if adf_result[1] < 0.05 else 'Non-Stationary'\n",
    "            \n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'MK p-value')] = mk_result.p\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'MK result')] = mk_result.trend\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': month_df.index,\n",
    "                'y': month_df[column]\n",
    "            })\n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df)\n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute linear regression on trend\n",
    "            X = np.arange(df.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = df[\"y\"].copy()\n",
    "\n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            \n",
    "            # store the slope\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Slope')] = slope\n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Slope p-value')] = p_value\n",
    "            \n",
    "            # calculate the percentage of the trend\n",
    "            first_value = forecast['trend'].iloc[0]\n",
    "            last_value = forecast['trend'].iloc[-1]\n",
    "            \n",
    "            trend_percentage = (last_value - first_value) / first_value * 100\n",
    "            \n",
    "            statistics_df.loc[(column, months_name[i]), (station_id, 'Trend Percentage')] = trend_percentage\n",
    "                \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=month_df.index,\n",
    "                    y=month_df[column],\n",
    "                    mode='lines',\n",
    "                    name='Historical',\n",
    "                    line=dict(\n",
    "                        color='black',\n",
    "                        width=0.6\n",
    "                    ),\n",
    "                    showlegend=True if column not in legend_added else False\n",
    "                ),\n",
    "                row=(i // 3) + 1,\n",
    "                col=(i % 3) + 1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=forecast['ds'],\n",
    "                    y=forecast['trend'],\n",
    "                    mode='lines',\n",
    "                    name='Trend',\n",
    "                    line=dict(color='blue'),\n",
    "                    showlegend=True if column not in legend_added else False\n",
    "                ),\n",
    "                row=(i // 3) + 1,\n",
    "                col=(i % 3) + 1\n",
    "            )\n",
    "            \n",
    "            legend_added.add(column)\n",
    "            \n",
    "        # Set the same y-axis range for all subplots\n",
    "        fig.update_yaxes(range=global_min_max[column])\n",
    "        \n",
    "        fig.add_annotation(dict(\n",
    "            x=0.5,\n",
    "            y=-0.08,\n",
    "            showarrow=False,\n",
    "            text=\"Time\",\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            font=dict(size=20)\n",
    "        ))\n",
    "\n",
    "        fig.add_annotation(dict(\n",
    "            x=-0.08,\n",
    "            y=0.5,\n",
    "            showarrow=False,\n",
    "            text=column,\n",
    "            textangle=-90,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            font=dict(size=20)\n",
    "        )) \n",
    "            \n",
    "        fig.update_layout(\n",
    "            height=1000,\n",
    "            width=1200,\n",
    "            title={\n",
    "                'text': f\"Station {station_id}\",\n",
    "                'y': 0.98,  # Vertical position\n",
    "                'x': 0.5,  # Horizontal position\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'\n",
    "            },\n",
    "            font=dict(size=18),\n",
    "            margin=dict(t=80, l=80, b=100, r=40)  # Adjust margins\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(os.path.join(ground_plot_folder, 'trends', 'monthwise', f\"station_{station_id}\")):\n",
    "            os.makedirs(os.path.join(ground_plot_folder, 'trends', 'monthwise', f\"station_{station_id}\")) \n",
    "            \n",
    "        column_ = column.replace(\"/\", \"_\")\n",
    "        \n",
    "        fig.write_image(\n",
    "            os.path.join(\n",
    "                ground_plot_folder,\n",
    "                'trends',\n",
    "                'monthwise',\n",
    "                f\"station_{station_id}\",\n",
    "                f\"{column_}.png\"\n",
    "            ),\n",
    "            scale=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_excel(os.path.join(ground_plot_folder, 'trends', 'monthwise', \"statistics.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Correlation (lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(df):\n",
    "    \"\"\"\n",
    "    Check and make the time series stationary if required.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        adf = adfuller(df[column])\n",
    "        kp = kpss(df[column])\n",
    "        if adf[1] > 0.05 and kp[1] < 0.05:\n",
    "            print(f'{column} is non-stationary. Differencing the data.')\n",
    "            df[column] = df[column].diff().dropna()\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_corr(ts1, ts2, max_lag):\n",
    "    lags = range(-max_lag, max_lag + 1)\n",
    "    cross_corr = [ts1.corr(ts2.shift(lag)) for lag in lags]\n",
    "    return lags, cross_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a time series is stationary, if not, difference it\n",
    "\n",
    "correlation_results_df = pd.DataFrame(\n",
    "    index=ground_df.columns.difference(diff_columns),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ground_df.columns.difference(diff_columns)])\n",
    ")\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=diff_columns).dropna()\n",
    "    \n",
    "    station_df = check_stationarity(station_df)\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in station_df.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "        \n",
    "    \n",
    "    max_lag = 12\n",
    "    \n",
    "    for column in station_df.columns:\n",
    "        for column2 in station_df.columns:\n",
    "            if column == column2:\n",
    "                continue\n",
    "            \n",
    "            lags, cross_corr = compute_cross_corr(station_df[column], station_df[column2], max_lag)\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=list(lags),\n",
    "                    y=cross_corr,\n",
    "                    mode='lines+markers',\n",
    "                    name='Cross Correlation'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs {column2}\",\n",
    "                xaxis_title=\"Lag (Months)\",\n",
    "                yaxis_title=\"Cross Correlation\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(os.path.join(ground_cross_corr_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(ground_cross_corr_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            column2_ = column2.replace(\"/\", \"_\")\n",
    "                \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    ground_cross_corr_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}_vs_{column2_}.png\"\n",
    "                ),\n",
    "                scale=3\n",
    "            )\n",
    "            \n",
    "            corr, pvalue = pearsonr(station_df[column], station_df[column2])\n",
    "            \n",
    "            # put the correlation just if the p-value is less than 0.05 and in the upper triangle\n",
    "            if pvalue < 0.05:\n",
    "                correlation_results_df.loc[column, (station_id, column2)] = corr\n",
    "            else:\n",
    "                correlation_results_df.loc[column, (station_id, column2)] = np.nan\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results_df.to_excel(os.path.join(ground_cross_corr_folder, \"correlation_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year by Year Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform year by year correlation\n",
    "correlation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([ground_df.columns.difference(diff_columns), sorted(ground_df['DateTime'].dt.year.unique())]),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ground_df.columns.difference(diff_columns)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "    \n",
    "    correlation_results[station_id] = {}\n",
    "    \n",
    "    for year in station_df['DateTime'].dt.year.unique():\n",
    "        \n",
    "        year_df = station_df[station_df['DateTime'].dt.year == year]\n",
    "        \n",
    "        year_df.drop(columns=diff_columns, inplace=True)\n",
    "        \n",
    "        for column in year_df.columns:\n",
    "            for column2 in year_df.columns:\n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                result = pearsonr(year_df[column], year_df[column2])\n",
    "                \n",
    "                correlation_results.loc[(column, year), (station_id, column2)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation results\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "        \n",
    "        station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "        \n",
    "        station_df.set_index('DateTime', inplace=True)\n",
    "        \n",
    "        for column in station_df.columns.difference(diff_columns):\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            for column2 in station_df.columns.difference(diff_columns):\n",
    "                \n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                years = correlation_results.loc[column, (station_id, column2)].index\n",
    "                \n",
    "                correlation = correlation_results.loc[(column, years), (station_id, column2)].dropna()            \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=correlation.index.get_level_values(1),\n",
    "                        y=correlation.apply(lambda x: x[0]),\n",
    "                        mode='lines+markers',\n",
    "                        name=column2\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs Other Parameters\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Pearson Correlation Coefficient\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(os.path.join(ground_corr_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(ground_corr_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    ground_corr_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}.png\"\n",
    "                ),\n",
    "                scale=3,\n",
    "                width=1200,\n",
    "            )\n",
    "            \n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results.to_excel(os.path.join(ground_corr_folder, \"correlation_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression for Average Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Month by Month Variation for each Year\n",
    "\n",
    "A time series of each year is built, the trend is computed with Prophet and a linear regression on the trend is computed in order to get the slope, which is the average month variation for the given year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform trend analysis for each year\n",
    "\n",
    "# build interaction plot\n",
    "\n",
    "years = ground_df['DateTime'].dt.year.unique()\n",
    "years.sort()\n",
    "\n",
    "# convert the years to int\n",
    "years = [int(year) for year in years]\n",
    "\n",
    "# create dataframe to store the adf and mann-kendall test results for each station for each year\n",
    "slopes_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([ground_df.columns.difference(diff_columns), years]),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ['Slope', 'P-Value', 'Error', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    \n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df.dropna(inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        # fig = make_subplots(\n",
    "        #     4,\n",
    "        #     3,\n",
    "        #     subplot_titles=years,\n",
    "        #     vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "        #     horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        # )\n",
    "        \n",
    "        for i, year in enumerate(years):\n",
    "            \n",
    "            if year not in station_df.index.year:\n",
    "                continue\n",
    "            \n",
    "            year_df = station_df[station_df.index.year == year]\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': year_df.index,\n",
    "                'y': year_df[column]\n",
    "            })\n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df)\n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute the linear regression on the trend\n",
    "            X = np.arange(forecast.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = forecast['trend'].copy()\n",
    "            \n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            st_error = results.bse.iloc[1]\n",
    "            \n",
    "            # store the results in the dataframe\n",
    "            slopes_df.loc[(column, year), (station_id, 'Slope')] = round(slope, 4)\n",
    "            slopes_df.loc[(column, year), (station_id, 'P-Value')] = round(p_value, 4)\n",
    "            slopes_df.loc[(column, year), (station_id, 'Error')] = round(st_error, 4)\n",
    "            \n",
    "            # compute the percentage of the trend\n",
    "            trend_percentage = (slope / forecast['trend'].mean()) * 100\n",
    "            slopes_df.loc[(column, year), (station_id, 'Trend Percentage')] = round(trend_percentage, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_df.to_excel(os.path.join(ground_plot_folder, 'trends', \"slopes.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year by Year Variation for each Month\n",
    "\n",
    "A time series of each month is built, the trend is computed with Prophet and a linear regression on the trend is computed in order to get the slope, which is the average year variation for the given month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform trend analysis for each month\n",
    "\n",
    "# build interaction plot\n",
    "\n",
    "months = ground_df['DateTime'].dt.month.unique()\n",
    "months.sort()\n",
    "\n",
    "# get the names of the months\n",
    "months_name = [pd.to_datetime(f\"{month}-01-2021\").strftime(\"%B\") for month in months]\n",
    "\n",
    "# create dataframe to store the adf and mann-kendall test results for each station for each month\n",
    "slopes_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([ground_df.columns.difference(diff_columns), months_name]),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), ['Slope', 'P-Value', 'Error', 'Trend Percentage']])\n",
    ")\n",
    "\n",
    "legend_added = set()\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    \n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        # fig = make_subplots(\n",
    "        #     4,\n",
    "        #     3,\n",
    "        #     subplot_titles=months_name,\n",
    "        #     vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "        #     horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    "        # )\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            \n",
    "            month_df = station_df[station_df.index.month == month]\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'ds': month_df.index,\n",
    "                'y': month_df[column]\n",
    "            })\n",
    "            \n",
    "            model = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df)\n",
    "            # Make predictions for both columns\n",
    "            future = model.make_future_dataframe(periods=0)\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # compute the linear regression on the trend\n",
    "            X = np.arange(forecast.shape[0])\n",
    "            X = sm.add_constant(X)\n",
    "            y = forecast['trend'].copy()\n",
    "            \n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            slope = results.params.iloc[1]\n",
    "            p_value = results.pvalues.iloc[1]\n",
    "            st_error = results.bse.iloc[1]\n",
    "            \n",
    "            # store the results in the dataframe\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Slope')] = slope\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'P-Value')] = p_value\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Error')] = st_error\n",
    "            \n",
    "            # compute the percentage of the trend\n",
    "            trend_percentage = (slope / forecast['trend'].mean()) * 100\n",
    "            slopes_df.loc[(column, months_name[i]), (station_id, 'Trend Percentage')] = trend_percentage\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_df.to_excel(os.path.join(ground_plot_folder, 'trends', 'monthwise', \"slopes.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# per il momento lascia qua, potrebbe tornare utile se si decidesse di calcolare una linear regression tra ogni changepoint\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    \n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    for column in station_df.columns.difference(diff_columns):\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                'ds': station_df.index,\n",
    "                'y': station_df[column]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        \n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # add the changepoints detected by Prophet\n",
    "        changepoints = model.changepoints\n",
    "    \n",
    "        signif_changepoints = changepoints[\n",
    "            np.abs(np.nanmean(model.params['delta'], axis=0)) >= 0.1\n",
    "        ]\n",
    "        \n",
    "        changepoints_values = forecast.loc[forecast['ds'].isin(signif_changepoints), 'trend']\n",
    "        \n",
    "        trend = forecast['trend']\n",
    "        \n",
    "        # compute linear regression on trend\n",
    "        X = np.arange(trend.shape[0])\n",
    "        X = sm.add_constant(X)\n",
    "        y = trend.copy()\n",
    "        \n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "        \n",
    "        # plot the line of the linear regression\n",
    "        line = pd.Series(results.predict(X), index=forecast['ds'])\n",
    "        \n",
    "        # get the slope with the p-value and the standard error\n",
    "        slope = results.params.iloc[1]\n",
    "        p_value = results.pvalues.iloc[1]\n",
    "        std_err = results.bse.iloc[1]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name='Original',\n",
    "                line=dict(color='black')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=trend,\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=line.index,\n",
    "                y=line,\n",
    "                mode='lines',\n",
    "                name='Linear Regression',\n",
    "                line=dict(color='red', dash='dash')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=signif_changepoints,\n",
    "                y=changepoints_values,\n",
    "                mode='markers',\n",
    "                name='Changepoints',\n",
    "                marker=dict(\n",
    "                    color='green',\n",
    "                    size=10\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"Slope: {slope:.3f}, P-Value: {p_value:.3f}, Std. Error: {std_err:.3f}\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Value\"\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = surface_df[surface_df['Station'] == 105][['DateTime', 'Cumulated Rainfall (mm)']].copy()\n",
    "\n",
    "# define classes as [0,1], (1, 2], (2, 3], (3, inf)\n",
    "\n",
    "rainfall_df['Class'] = pd.cut(rainfall_df['Cumulated Rainfall (mm)'], bins=[0, 1, 2, 3, np.inf], labels=['0-1', '1-2', '2-3', '3+'])\n",
    "\n",
    "rainfall_df['Year'] = rainfall_df['DateTime'].dt.year\n",
    "rainfall_df['Month'] = rainfall_df['DateTime'].dt.month\n",
    "\n",
    "# analyze if the frequency of the classes changes over time\n",
    "\n",
    "# create a pivot table\n",
    "pivot_table = rainfall_df.pivot_table(index='Year', columns='Class', aggfunc='size', fill_value=0)\n",
    "\n",
    "# plot the pivot table\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in pivot_table.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pivot_table.index,\n",
    "            y=pivot_table[column],\n",
    "            mode='lines+markers',\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    title=\"Rainfall Classes Frequency Over Time\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the air temperature\n",
    "\n",
    "air_temperature_df = surface_df[surface_df['Station'] == 305][['DateTime', 'Air Temperature (°C)']].copy()\n",
    "\n",
    "air_temperature_df['Class'] = pd.cut(air_temperature_df['Air Temperature (°C)'], bins=[-10, 0, 10, 20, 30, 40, np.inf], labels=['-10-0', '0-10', '10-20', '20-30', '30-40', '40+'])\n",
    "\n",
    "air_temperature_df['Year'] = air_temperature_df['DateTime'].dt.year\n",
    "air_temperature_df['Month'] = air_temperature_df['DateTime'].dt.month\n",
    "\n",
    "# analyze if the frequency of the classes changes over time\n",
    "\n",
    "# create a pivot table\n",
    "pivot_table = air_temperature_df.pivot_table(index='Year', columns='Class', aggfunc='size', fill_value=0)\n",
    "\n",
    "# plot the pivot table\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in pivot_table.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pivot_table.index,\n",
    "            y=pivot_table[column],\n",
    "            mode='lines+markers',\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    title=\"Air Temperature Classes Frequency Over Time\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def largest_factors(x):\n",
    "    # Start with the largest integer close to sqrt(x)\n",
    "    a = math.isqrt(x)\n",
    "    \n",
    "    # Look for the largest divisor of x starting from a\n",
    "    while x % a != 0:\n",
    "        a -= 1\n",
    "    \n",
    "    # Compute the other factor\n",
    "    b = x // a\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_df = surface_df[surface_df['Station'] == 305][['DateTime', 'Air Temperature (°C)']].copy()\n",
    "\n",
    "# define classes as [0,1], (1, 2], (2, 3], (3, inf)\n",
    "\n",
    "# create a plot where for every year the histogram distribution of the air temperature is shown\n",
    "\n",
    "n_years = air_temp_df['DateTime'].dt.year.nunique()\n",
    "\n",
    "rows, cols = largest_factors(n_years)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows,\n",
    "    cols=cols,\n",
    "    subplot_titles=[str(year) for year in air_temp_df['DateTime'].dt.year.unique()],  # Convert year to string\n",
    "    vertical_spacing=0.08,  # Reduce vertical spacing\n",
    "    horizontal_spacing=0.05  # Reduce horizontal spacing\n",
    ")\n",
    "\n",
    "for i, year in enumerate(air_temp_df['DateTime'].dt.year.unique()):\n",
    "        \n",
    "        year_df = air_temp_df[air_temp_df['DateTime'].dt.year == year]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=year_df['Air Temperature (°C)'],\n",
    "                name=str(year),\n",
    "                opacity=0.75,\n",
    "                nbinsx=10,\n",
    "                marker=dict(\n",
    "                    color='blue'\n",
    "                )\n",
    "            ),\n",
    "            row=(i // cols) + 1,\n",
    "            col=(i % cols) + 1\n",
    "        )\n",
    "        \n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    title={\n",
    "        'text': f\"Station 305 - Air Temperature Distribution\",\n",
    "        'y': 0.98,  # Vertical position\n",
    "        'x': 0.5,  # Horizontal position\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    font=dict(size=18),\n",
    "    margin=dict(t=80, l=80, b=100, r=40), # Adjust margins\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_pixels = 90 * 3.779527559"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot\n",
    "\n",
    "For the ground water, it is in the raw_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot between DOC nad Ammonium with best fit line\n",
    "\n",
    "scatter_plots_folder = os.path.join(paper_plots_folder, 'Berlin', 'Scatters', 'Surface')\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    doc_ammonium_df = surface_df[surface_df['Station'] == station_id][['DateTime', 'DOC (mg/l)', 'Ammonium (mg/l)']].copy()\n",
    "\n",
    "    fig = px.scatter(\n",
    "        doc_ammonium_df,\n",
    "        x='Ammonium (mg/l)',\n",
    "        y='DOC (mg/l)',\n",
    "        trendline='ols',\n",
    "        trendline_color_override='red'\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Scatter Plot - DOC (mg/l) vs Ammonium (mg/l) - Station {station_id}\",\n",
    "        xaxis_title=\"Ammonium (mg/l)\",\n",
    "        yaxis_title=\"DOC (mg/l)\"\n",
    "    )\n",
    "\n",
    "    fig.write_image(\n",
    "        os.path.join(scatter_plots_folder, f\"station_{station_id}.png\"),\n",
    "        scale=6,\n",
    "    )\n",
    "        \n",
    "\n",
    "    # compute the correlation between DOC and Ammonium\n",
    "\n",
    "    doc_ammonium_df.dropna(inplace=True)\n",
    "\n",
    "    corr, pvalue = pearsonr(doc_ammonium_df['DOC (mg/l)'], doc_ammonium_df['Ammonium (mg/l)'])\n",
    "\n",
    "    print(f\"Pearson Correlation: {corr:.3f}, P-Value: {pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_pixels = 170 * 3.779527559"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb(200, 2, 110)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one plot for each variable\n",
    "# do it just for the 305 station since it is the one used in the paper\n",
    "\n",
    "trend_folder = os.path.join(paper_plots_folder, 'Berlin', 'Trends', 'Surface', '305')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['DOC (mg/l)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "\n",
    "color_mapping = {\n",
    "    'Air Temperature (°C)': colors[0],\n",
    "    'Cumulated Rainfall (mm)': colors[1],\n",
    "    'Ammonium (mg/l)': colors[2],\n",
    "    'Conductivity (µS/cm)': colors[3],\n",
    "    'Dissolved Oxygen (mg/l)': colors[4],\n",
    "    'Flow River Rate (m³/s)': colors[5],\n",
    "    'Nitrate (mg/l)': colors[6],\n",
    "    'pH': colors[7],\n",
    "    'Water Temperature (°C)': colors[8],\n",
    "    'DOC (mg/l)': colors[9]\n",
    "}\n",
    "\n",
    "surface_df = surface_df[surface_df['DateTime'] >= \"1998-01-01\"]\n",
    "\n",
    "\n",
    "station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "\n",
    "station_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "station_df = station_df.drop(columns=bacteria_columns)\n",
    "\n",
    "station_id = 305\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'ds': station_df.index,\n",
    "        'y': station_df[column]\n",
    "    })\n",
    "    \n",
    "    model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(df)\n",
    "    # Make predictions for both columns\n",
    "    future = model.make_future_dataframe(periods=0)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=station_df.index,\n",
    "            y=station_df[column],\n",
    "            mode='lines',\n",
    "            name=column,\n",
    "            line=dict(\n",
    "                color=color_mapping[column],\n",
    "                width=1.5\n",
    "            ),\n",
    "            showlegend=False\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast['ds'],\n",
    "            y=forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "            showlegend=False, # change to trend_show if you want to show the legend\n",
    "            legendrank=np.inf\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "        \n",
    "    # fig.update_yaxes(title_text=column)\n",
    "    \n",
    "    if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "        fig.update_yaxes(range=[0, 0.7])\n",
    "    \n",
    "    if column == 'Air Temperature (°C)':\n",
    "        fig.update_yaxes(range=[-10, 30])\n",
    "    \n",
    "    if column == 'Cumulated Rainfall (mm)':\n",
    "        fig.update_yaxes(range=[0, 8])\n",
    "        \n",
    "    # if column == 'Conductivity (µS/cm)':\n",
    "    #     fig.update_yaxes(range=[0, 1700])\n",
    "    \n",
    "    # if column == 'Nitrate (mg/l)':\n",
    "    #     fig.update_yaxes(range=[0, 20])\n",
    "    \n",
    "    if column == 'pH':\n",
    "        fig.update_yaxes(range=[7.6, 8.8])\n",
    "    \n",
    "    if column == 'Water Temperature (°C)':\n",
    "        fig.update_yaxes(range=[0, 30])\n",
    "        \n",
    "    # if column == 'Flow River Rate (m³/s)':\n",
    "    #     fig.update_yaxes(range=[0, 1300])\n",
    "        \n",
    "    if column == 'Dissolved Oxygen (mg/l)':\n",
    "        fig.update_yaxes(range=[4, 18])\n",
    "\n",
    "\n",
    "    start_year = station_df.index.year.min()\n",
    "    end_year = station_df.index.year.max()\n",
    "    tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "    ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "\n",
    "    fig.update_xaxes(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        title_text=\"Time\"\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=column)  \n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='Berlin',\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "        ),\n",
    "        legend=dict(\n",
    "            traceorder='normal',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    #reduce the font size of the subplot titles\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=8)\n",
    "\n",
    "    \n",
    "    column_ = column.replace(\"/\", \"_\")\n",
    "\n",
    "    fig.write_image(\n",
    "        os.path.join(trend_folder, f\"{column_}.png\"),\n",
    "        scale=10,\n",
    "    )\n",
    "\n",
    "    # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# one single image with all the trends\n",
    "\n",
    "trend_folder = os.path.join(paper_plots_folder, 'Berlin', 'Trends', 'Surface')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['DOC (mg/l)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "\n",
    "color_mapping = {\n",
    "    'Air Temperature (°C)': colors[0],\n",
    "    'Cumulated Rainfall (mm)': colors[1],\n",
    "    'Ammonium (mg/l)': colors[2],\n",
    "    'Conductivity (µS/cm)': colors[3],\n",
    "    'Dissolved Oxygen (mg/l)': colors[4],\n",
    "    'Flow River Rate (m³/s)': colors[5],\n",
    "    'Nitrate (mg/l)': colors[6],\n",
    "    'pH': colors[7],\n",
    "    'Water Temperature (°C)': colors[8],\n",
    "    'DOC (mg/l)': colors[9]\n",
    "}\n",
    "\n",
    "surface_df = surface_df[surface_df['DateTime'] >= \"1998-01-01\"]\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        len(columns),\n",
    "        1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=columns,\n",
    "        vertical_spacing=0.02\n",
    "    )\n",
    "    \n",
    "    trend_show = True\n",
    "    \n",
    "    for i, column in enumerate(columns):\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'ds': station_df.index,\n",
    "            'y': station_df[column]\n",
    "        })\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                name=column,\n",
    "                line=dict(\n",
    "                    color=color_mapping[column],\n",
    "                    width=1.5\n",
    "                ),\n",
    "                legendrank=i,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i + 1,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=forecast['trend'],\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color, width=1),\n",
    "                showlegend=False, # change to trend_show if you want to show the legend\n",
    "                legendrank=np.inf\n",
    "            ),\n",
    "            row=i + 1,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "        if trend_show:\n",
    "            trend_show = False\n",
    "            \n",
    "        # fig.update_yaxes(title_text=column, row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "            fig.update_yaxes(range=[0, 0.7], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Air Temperature (°C)':\n",
    "            fig.update_yaxes(range=[-10, 30], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Cumulated Rainfall (mm)':\n",
    "            fig.update_yaxes(range=[0, 8], row=i + 1, col=1)\n",
    "            \n",
    "        # if column == 'Conductivity (µS/cm)':\n",
    "        #     fig.update_yaxes(range=[0, 1700], row=i + 1, col=1)\n",
    "        \n",
    "        # if column == 'Nitrate (mg/l)':\n",
    "        #     fig.update_yaxes(range=[0, 20], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'pH':\n",
    "            fig.update_yaxes(range=[7.6, 8.8], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Water Temperature (°C)':\n",
    "            fig.update_yaxes(range=[0, 30], row=i + 1, col=1)\n",
    "            \n",
    "        # if column == 'Flow River Rate (m³/s)':\n",
    "        #     fig.update_yaxes(range=[0, 1300], row=i + 1, col=1)\n",
    "            \n",
    "        if column == 'Dissolved Oxygen (mg/l)':\n",
    "            fig.update_yaxes(range=[4, 18], row=i + 1, col=1)\n",
    "        \n",
    "        \n",
    "    fig.update_xaxes(title_text=\"Time\", row=len(columns), col=1)\n",
    "    \n",
    "    start_year = station_df.index.year.min()\n",
    "    end_year = station_df.index.year.max()\n",
    "    tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "    ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "    )  \n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='Berlin',\n",
    "            x=0.5,\n",
    "            y=0.99,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "            font=dict(size=10),\n",
    "        ),\n",
    "        font=dict(size=8),\n",
    "        legend=dict(\n",
    "            traceorder='normal',\n",
    "        ),\n",
    "        margin=dict(\n",
    "        l=30,  # Left margin\n",
    "        r=30,  # Right margin\n",
    "        t=50,  # Top margin\n",
    "        b=150  # Bottom margin (increase to add blank space)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    #reduce the font size of the subplot titles\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=8)\n",
    "    \n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(trend_folder, f\"station_{station_id}.png\"),\n",
    "        scale=10,\n",
    "        width=400,\n",
    "        height=220 * len(columns)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_folder = os.path.join(paper_plots_folder, 'Berlin', 'Trends', 'Ground')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['UVA254 (1/m)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        len(columns),\n",
    "        1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=columns,\n",
    "    )\n",
    "    \n",
    "    trend_show = True\n",
    "    \n",
    "    for i, column in enumerate(columns):\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'ds': station_df.index,\n",
    "            'y': station_df[column]\n",
    "        })\n",
    "        \n",
    "        model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(df)\n",
    "        # Make predictions for both columns\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=station_df.index,\n",
    "                y=station_df[column],\n",
    "                mode='lines',\n",
    "                line=dict(\n",
    "                    color=colors[i],\n",
    "                    width=1.5\n",
    "                ),\n",
    "                legendrank=i,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i + 1,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=forecast['ds'],\n",
    "                y=forecast['trend'],\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color=color, width=1),\n",
    "                showlegend=trend_show,\n",
    "                legendrank=np.inf\n",
    "            ),\n",
    "            row=i + 1,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "        if trend_show:\n",
    "            trend_show = False\n",
    "            \n",
    "        # fig.update_yaxes(title_text=column, row=i + 1, col=1)\n",
    "        \n",
    "        # Set y-axis range for a specific trace (e.g., the first trace)\n",
    "        if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "            fig.update_yaxes(range=[0, 0.7], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Air Temperature (°C)':\n",
    "            fig.update_yaxes(range=[-10, 30], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Cumulated Rainfall (mm)':\n",
    "            fig.update_yaxes(range=[0, 8], row=i + 1, col=1)\n",
    "            \n",
    "        if column == 'Conductivity (µS/cm)':\n",
    "            fig.update_yaxes(range=[0, 1700], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Nitrate (mg/l)':\n",
    "            fig.update_yaxes(range=[0, 20], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'pH':\n",
    "            fig.update_yaxes(range=[7.6, 8.8], row=i + 1, col=1)\n",
    "        \n",
    "        if column == 'Water Temperature (°C)':\n",
    "            fig.update_yaxes(range=[0, 30], row=i + 1, col=1)\n",
    "            \n",
    "        if column == 'Flow River Rate (m³/s)':\n",
    "            fig.update_yaxes(range=[0, 1300], row=i + 1, col=1)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    # # Add vertical dashed lines for each year\n",
    "    # years = station_df.index.year.unique()\n",
    "    # for year in years:\n",
    "    #     fig.add_vline(\n",
    "    #         x=pd.Timestamp(f'{year}-01-01'),\n",
    "    #         line=dict(color='gray', width=0.5, dash='dash'),\n",
    "    #         layer='above'\n",
    "    #     )\n",
    "        \n",
    "    fig.update_xaxes(title_text=\"Time\", row=len(columns), col=1)\n",
    "    \n",
    "    start_year = station_df.index.year.min()\n",
    "    end_year = station_df.index.year.max()\n",
    "    tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "    ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "    )  \n",
    "    \n",
    "    fig.update_layout(\n",
    "        font=dict(size=8),\n",
    "        legend=dict(\n",
    "            traceorder='normal',\n",
    "        ),\n",
    "        \n",
    "    )\n",
    "    \n",
    "    #reduce the font size of the subplot titles\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=8)\n",
    "    \n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(trend_folder, f\"station_{station_id}.png\"),\n",
    "        scale=10,\n",
    "        width=500,\n",
    "        height=150 * len(columns)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Year by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Air Temperature (°C)', 'Ammonium (mg/l)', 'DOC (mg/l)']\n",
    "\n",
    "# perform year by year correlation\n",
    "correlation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([columns, sorted(surface_df['DateTime'].dt.year.unique())]),\n",
    "    columns=pd.MultiIndex.from_product([surface_df['Station'].unique().tolist(), columns])\n",
    ")\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "    \n",
    "    station_df = station_df.drop(columns=['Flow River Rate (m³/s)'])\n",
    "    \n",
    "    station_df = station_df.drop(columns=bacteria_columns).dropna()\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "    \n",
    "    correlation_results[station_id] = {}\n",
    "    \n",
    "    for year in station_df['DateTime'].dt.year.unique():\n",
    "        \n",
    "        year_df = station_df[station_df['DateTime'].dt.year == year]\n",
    "        \n",
    "        year_df = year_df[columns]\n",
    "        \n",
    "        for column in year_df.columns:\n",
    "            for column2 in year_df.columns:\n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                result = pearsonr(year_df[column], year_df[column2])\n",
    "                \n",
    "                correlation_results.loc[(column, year), (station_id, column2)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation results\n",
    "\n",
    "correlation_folder = os.path.join(paper_plots_folder, 'Berlin', 'Correlations', 'Surface')\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "        \n",
    "        station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "        \n",
    "        station_df = station_df.drop(columns=bacteria_columns).dropna()\n",
    "        \n",
    "        station_df.set_index('DateTime', inplace=True)\n",
    "        \n",
    "        for column in columns:\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            for column2 in columns:\n",
    "                \n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                years = correlation_results.loc[column, (station_id, column2)].index\n",
    "                \n",
    "                correlation = correlation_results.loc[(column, years), (station_id, column2)].dropna()            \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=correlation.index.get_level_values(1),\n",
    "                        y=correlation.apply(lambda x: x[0]),\n",
    "                        mode='lines+markers',\n",
    "                        name=column2\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs Other Parameters\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Pearson Correlation Coefficient\",\n",
    "                # put legend inside the plot\n",
    "                legend=dict(\n",
    "                    x=0.01,\n",
    "                    y=0.99\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            \n",
    "            fig.update_yaxes(range=[-1, 1])\n",
    "            \n",
    "            # add a horizontal line at 0\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=years.min(),\n",
    "                y0=0,\n",
    "                x1=years.max(),\n",
    "                y1=0,\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(os.path.join(correlation_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(correlation_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    correlation_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}.png\"\n",
    "                ),\n",
    "                scale=6,\n",
    "                \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Air Temperature (°C)', 'Ammonium (mg/l)', 'UVA254 (1/m)']\n",
    "\n",
    "# perform year by year correlation\n",
    "correlation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([columns, sorted(ground_df['DateTime'].dt.year.unique())]),\n",
    "    columns=pd.MultiIndex.from_product([ground_df['Station'].unique().tolist(), columns])\n",
    ")\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "    station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "    \n",
    "    # normalize the data\n",
    "    for column in columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        station_df[column] = scaler.fit_transform(station_df[[column]])\n",
    "    \n",
    "    correlation_results[station_id] = {}\n",
    "    \n",
    "    for year in station_df['DateTime'].dt.year.unique():\n",
    "        \n",
    "        year_df = station_df[station_df['DateTime'].dt.year == year]\n",
    "        \n",
    "        year_df = year_df[columns]\n",
    "        \n",
    "        for column in year_df.columns:\n",
    "            for column2 in year_df.columns:\n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                result = pearsonr(year_df[column], year_df[column2])\n",
    "                \n",
    "                correlation_results.loc[(column, year), (station_id, column2)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation results\n",
    "\n",
    "correlation_folder = os.path.join(paper_plots_folder, 'Berlin', 'Correlations', 'Ground')\n",
    "\n",
    "\n",
    "for station_id in ground_df['Station'].unique():\n",
    "        \n",
    "        station_df = ground_df[ground_df['Station'] == station_id].copy()\n",
    "        \n",
    "        station_df.set_index('DateTime', inplace=True)\n",
    "        \n",
    "        for column in columns:\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            for column2 in columns:\n",
    "                \n",
    "                if column == column2:\n",
    "                    continue\n",
    "                \n",
    "                years = correlation_results.loc[column, (station_id, column2)].index\n",
    "                \n",
    "                correlation = correlation_results.loc[(column, years), (station_id, column2)].dropna()            \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=correlation.index.get_level_values(1),\n",
    "                        y=correlation.apply(lambda x: x[0]),\n",
    "                        mode='lines+markers',\n",
    "                        name=column2\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "            fig.update_layout(\n",
    "                title=f\"Station {station_id} - {column} vs Other Parameters\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Pearson Correlation Coefficient\",\n",
    "                # put legend inside the plot\n",
    "                legend=dict(\n",
    "                    x=0.01,\n",
    "                    y=0.99\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            \n",
    "            fig.update_yaxes(range=[-1, 1])\n",
    "            \n",
    "            # add a horizontal line at 0\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=years.min(),\n",
    "                y0=0,\n",
    "                x1=years.max(),\n",
    "                y1=0,\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(os.path.join(correlation_folder, f\"station_{station_id}\")):\n",
    "                os.makedirs(os.path.join(correlation_folder, f\"station_{station_id}\"))\n",
    "                \n",
    "            column_ = column.replace(\"/\", \"_\")\n",
    "            \n",
    "            fig.write_image(\n",
    "                os.path.join(\n",
    "                    correlation_folder,\n",
    "                    f\"station_{station_id}\",\n",
    "                    f\"{column_}.png\"\n",
    "                ),\n",
    "                scale=6,\n",
    "                \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case using all the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one plot for each variable\n",
    "trend_folder = os.path.join(paper_plots_folder, 'Berlin', 'Trends', 'Overall')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['DOC (mg/l)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "# give me two colors for the trend lines different from the other colors\n",
    "\n",
    "station_id = 325\n",
    "\n",
    "station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "\n",
    "station_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "station_df = station_df.drop(columns=bacteria_columns)\n",
    "\n",
    "\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=['MK Result', 'MK p-value', 'Slope', 'Slope p-value'],\n",
    "    columns=pd.MultiIndex.from_product([['Pre 1998', 'Post 1998'], columns])\n",
    ")\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    pre_wall_df = station_df[station_df.index < '1998-01-01']\n",
    "    after_wall_df = station_df[station_df.index >= '1998-01-01']\n",
    "    \n",
    "    pre_df = pd.DataFrame({\n",
    "        'ds': pre_wall_df.index,\n",
    "        'y': pre_wall_df[column]\n",
    "    })\n",
    "    \n",
    "    after_df = pd.DataFrame({\n",
    "        'ds': after_wall_df.index,\n",
    "        'y': after_wall_df[column]\n",
    "    })\n",
    "    \n",
    "    pre_model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    pre_model.fit(pre_df)\n",
    "    # Make predictions for both columns\n",
    "    pre_future = pre_model.make_future_dataframe(periods=0)\n",
    "    pre_forecast = pre_model.predict(pre_future)\n",
    "    \n",
    "    \n",
    "    \n",
    "    after_model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    after_model.fit(after_df)\n",
    "    # Make predictions for both columns\n",
    "    after_future = after_model.make_future_dataframe(periods=0)\n",
    "    after_forecast = after_model.predict(after_future)\n",
    "    \n",
    "    \n",
    "    # compute the Mann-Kendall test for the trend\n",
    "    pre_result = mk.original_test(pre_wall_df[column])\n",
    "    after_result = mk.original_test(after_wall_df[column])\n",
    "    \n",
    "    statistics_df.loc['MK Result', ('Pre 1998', column)] = pre_result.trend\n",
    "    statistics_df.loc['MK Result', ('Post 1998', column)] = after_result.trend\n",
    "    \n",
    "    statistics_df.loc['MK p-value', ('Pre 1998', column)] = pre_result.p\n",
    "    statistics_df.loc['MK p-value', ('Post 1998', column)] = after_result.p\n",
    "    \n",
    "    # compute the linear regression for the trend\n",
    "    X = np.arange(pre_forecast.shape[0])\n",
    "    X = sm.add_constant(X)\n",
    "    y = pre_forecast['trend'].copy()\n",
    "    \n",
    "    pre_model = sm.OLS(y, X)\n",
    "    pre_results = pre_model.fit()\n",
    "    \n",
    "    statistics_df.loc['Slope', ('Pre 1998', column)] = pre_results.params.iloc[1]\n",
    "    statistics_df.loc['Slope p-value', ('Pre 1998', column)] = pre_results.pvalues.iloc[1]\n",
    "    \n",
    "    X = np.arange(after_forecast.shape[0])\n",
    "    X = sm.add_constant(X)\n",
    "    y = after_forecast['trend'].copy()\n",
    "    \n",
    "    after_model = sm.OLS(y, X)\n",
    "    after_results = after_model.fit()\n",
    "    \n",
    "    statistics_df.loc['Slope', ('Post 1998', column)] = after_results.params.iloc[1]\n",
    "    statistics_df.loc['Slope p-value', ('Post 1998', column)] = after_results.pvalues.iloc[1]\n",
    "    \n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pre_wall_df.index,\n",
    "            y=pre_wall_df[column],\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=colors[i],\n",
    "                width=1.5\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pre_forecast['ds'],\n",
    "            y=pre_forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='Pre Wall Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=after_wall_df.index,\n",
    "            y=after_wall_df[column],\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=colors[i],\n",
    "                width=1.5\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=after_forecast['ds'],\n",
    "            y=after_forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='After Wall Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "        ),\n",
    "    )\n",
    "        \n",
    "    # fig.update_yaxes(title_text=column)\n",
    "    \n",
    "    # Set y-axis range for a specific trace (e.g., the first trace)\n",
    "    # if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "    #     fig.update_yaxes(range=[0, 0.7])\n",
    "    \n",
    "    # if column == 'DOC (mg/l)':\n",
    "    #     fig.update_yaxes(range=[4, 12])\n",
    "    \n",
    "    # if column == 'Air Temperature (°C)':\n",
    "    #     fig.update_yaxes(range=[-10, 30])\n",
    "    \n",
    "# # Add vertical dashed lines for each year\n",
    "# years = station_df.index.year.unique()\n",
    "# for year in years:\n",
    "#     fig.add_vline(\n",
    "#         x=pd.Timestamp(f'{year}-01-01'),\n",
    "#         line=dict(color='gray', width=0.5, dash='dash'),\n",
    "#         layer='above'\n",
    "#     )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time\")\n",
    "\n",
    "    start_year = station_df.index.year.min()\n",
    "    end_year = station_df.index.year.max()\n",
    "    tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "    ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "\n",
    "    fig.update_xaxes(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        title_text=\"Time\"\n",
    "    )  \n",
    "    \n",
    "    fig.update_yaxes(title_text=column)\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            traceorder='normal',\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                xref=\"x\",\n",
    "                yref=\"paper\",\n",
    "                x0=pd.Timestamp('1998-01-01'),\n",
    "                y0=0,\n",
    "                x1=pd.Timestamp('1998-01-01'),\n",
    "                y1=1,\n",
    "                line=dict(\n",
    "                    color=\"red\",\n",
    "                    width=1,\n",
    "                    dash=\"dash\",\n",
    "                ),\n",
    "                layer=\"above\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    #reduce the font size of the subplot titles\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(\n",
    "            size=8,\n",
    "            )\n",
    "\n",
    "    # put the annotations above other elements\n",
    "        \n",
    "    column_ = column.replace(\"/\", \"_\")\n",
    "\n",
    "    fig.write_image(\n",
    "        os.path.join(trend_folder, f\"{column_}.png\"),\n",
    "        scale=15,\n",
    "    )\n",
    "\n",
    "    # fig.show()\n",
    "\n",
    "statistics_df.to_excel(\n",
    "    os.path.join(trend_folder, 'statistics.xlsx')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "trend_folder = os.path.join(paper_plots_folder, 'Berlin', 'Trends', 'Overall')\n",
    "\n",
    "# sort the columns into climatic, water quality and DOC as last one\n",
    "climatic_variables = ['Air Temperature (°C)', 'Cumulated Rainfall (mm)']\n",
    "water_quality_variables = ['Ammonium (mg/l)', 'Conductivity (µS/cm)', 'Dissolved Oxygen (mg/l)', 'Flow River Rate (m³/s)', 'Nitrate (mg/l)', 'pH', 'Water Temperature (°C)']\n",
    "doc_variable = ['DOC (mg/l)']\n",
    "\n",
    "columns = climatic_variables + water_quality_variables + doc_variable\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "# give me two colors for the trend lines different from the other colors\n",
    "\n",
    "station_id = 325\n",
    "\n",
    "station_df = surface_df[surface_df['Station'] == station_id].copy()\n",
    "\n",
    "station_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "station_df = station_df.drop(columns=bacteria_columns)\n",
    "\n",
    "\n",
    "statistics_df = pd.DataFrame(\n",
    "    index=['MK Result', 'MK p-value', 'Slope', 'Slope p-value'],\n",
    "    columns=pd.MultiIndex.from_product([['Pre 1998', 'Post 1998'], columns])\n",
    ")\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    len(columns),\n",
    "    1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=columns,\n",
    "    vertical_spacing=0.02\n",
    ")\n",
    "\n",
    "trend_show = True\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    pre_wall_df = station_df[station_df.index < '1998-01-01']\n",
    "    after_wall_df = station_df[station_df.index >= '1998-01-01']\n",
    "    \n",
    "    pre_df = pd.DataFrame({\n",
    "        'ds': pre_wall_df.index,\n",
    "        'y': pre_wall_df[column]\n",
    "    })\n",
    "    \n",
    "    after_df = pd.DataFrame({\n",
    "        'ds': after_wall_df.index,\n",
    "        'y': after_wall_df[column]\n",
    "    })\n",
    "    \n",
    "    pre_model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    pre_model.fit(pre_df)\n",
    "    # Make predictions for both columns\n",
    "    pre_future = pre_model.make_future_dataframe(periods=0)\n",
    "    pre_forecast = pre_model.predict(pre_future)\n",
    "    \n",
    "    \n",
    "    \n",
    "    after_model = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    after_model.fit(after_df)\n",
    "    # Make predictions for both columns\n",
    "    after_future = after_model.make_future_dataframe(periods=0)\n",
    "    after_forecast = after_model.predict(after_future)\n",
    "    \n",
    "    \n",
    "    # compute the Mann-Kendall test for the trend\n",
    "    pre_result = mk.original_test(pre_wall_df[column])\n",
    "    after_result = mk.original_test(after_wall_df[column])\n",
    "    \n",
    "    statistics_df.loc['MK Result', ('Pre 1998', column)] = pre_result.trend\n",
    "    statistics_df.loc['MK Result', ('Post 1998', column)] = after_result.trend\n",
    "    \n",
    "    statistics_df.loc['MK p-value', ('Pre 1998', column)] = pre_result.p\n",
    "    statistics_df.loc['MK p-value', ('Post 1998', column)] = after_result.p\n",
    "    \n",
    "    # compute the linear regression for the trend\n",
    "    X = np.arange(pre_forecast.shape[0])\n",
    "    X = sm.add_constant(X)\n",
    "    y = pre_forecast['trend'].copy()\n",
    "    \n",
    "    pre_model = sm.OLS(y, X)\n",
    "    pre_results = pre_model.fit()\n",
    "    \n",
    "    statistics_df.loc['Slope', ('Pre 1998', column)] = pre_results.params.iloc[1]\n",
    "    statistics_df.loc['Slope p-value', ('Pre 1998', column)] = pre_results.pvalues.iloc[1]\n",
    "    \n",
    "    X = np.arange(after_forecast.shape[0])\n",
    "    X = sm.add_constant(X)\n",
    "    y = after_forecast['trend'].copy()\n",
    "    \n",
    "    after_model = sm.OLS(y, X)\n",
    "    after_results = after_model.fit()\n",
    "    \n",
    "    statistics_df.loc['Slope', ('Post 1998', column)] = after_results.params.iloc[1]\n",
    "    statistics_df.loc['Slope p-value', ('Post 1998', column)] = after_results.pvalues.iloc[1]\n",
    "    \n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pre_wall_df.index,\n",
    "            y=pre_wall_df[column],\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=colors[i],\n",
    "                width=1.5\n",
    "            ),\n",
    "            legendrank=i,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pre_forecast['ds'],\n",
    "            y=pre_forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='Pre Wall Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "            showlegend=False, # change to trend_show if you want to show the legend\n",
    "            legendrank=np.inf\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=after_wall_df.index,\n",
    "            y=after_wall_df[column],\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=colors[i],\n",
    "                width=1.5\n",
    "            ),\n",
    "            legendrank=i,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=after_forecast['ds'],\n",
    "            y=after_forecast['trend'],\n",
    "            mode='lines',\n",
    "            name='After Wall Trend',\n",
    "            line=dict(color=color, width=1),\n",
    "            showlegend=False, # change to trend_show if you want to show the legend\n",
    "            legendrank=np.inf\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "    \n",
    "    if trend_show:\n",
    "        trend_show = False\n",
    "        \n",
    "    # fig.update_yaxes(title_text=column, row=i + 1, col=1)\n",
    "    \n",
    "    # Set y-axis range for a specific trace (e.g., the first trace)\n",
    "    # if column == 'Ammonium (mg/l)':  # Replace with the actual column name\n",
    "    #     fig.update_yaxes(range=[0, 0.7], row=i + 1, col=1)\n",
    "    \n",
    "    # if column == 'DOC (mg/l)':\n",
    "    #     fig.update_yaxes(range=[4, 12], row=i + 1, col=1)\n",
    "    \n",
    "    # if column == 'Air Temperature (°C)':\n",
    "    #     fig.update_yaxes(range=[-10, 30], row=i + 1, col=1)\n",
    "    \n",
    "# # Add vertical dashed lines for each year\n",
    "# years = station_df.index.year.unique()\n",
    "# for year in years:\n",
    "#     fig.add_vline(\n",
    "#         x=pd.Timestamp(f'{year}-01-01'),\n",
    "#         line=dict(color='gray', width=0.5, dash='dash'),\n",
    "#         layer='above'\n",
    "#     )\n",
    "    \n",
    "fig.update_xaxes(title_text=\"Time\", row=len(columns), col=1)\n",
    "\n",
    "start_year = station_df.index.year.min()\n",
    "end_year = station_df.index.year.max()\n",
    "tickvals = [pd.Timestamp(f'{year}-01-01') for year in range(start_year, end_year + 1, 4)]\n",
    "ticktext = [str(year) for year in range(start_year, end_year + 1, 4)]   \n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickvals=tickvals,\n",
    "    ticktext=ticktext,\n",
    ")  \n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(size=8),\n",
    "    legend=dict(\n",
    "        traceorder='normal',\n",
    "    ),\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            x0=pd.Timestamp('1998-01-01'),\n",
    "            y0=0,\n",
    "            x1=pd.Timestamp('1998-01-01'),\n",
    "            y1=1,\n",
    "            line=dict(\n",
    "                color=\"red\",\n",
    "                width=1,\n",
    "                dash=\"dash\",\n",
    "            ),\n",
    "            layer=\"above\"\n",
    "        )\n",
    "    ],\n",
    "    margin=dict(\n",
    "        l=30,  # Left margin\n",
    "        r=30,  # Right margin\n",
    "        t=50,  # Top margin\n",
    "        b=150  # Bottom margin (increase to add blank space)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "#reduce the font size of the subplot titles\n",
    "for annotation in fig['layout']['annotations']:\n",
    "    annotation['font'] = dict(\n",
    "        size=8,\n",
    "        )\n",
    "\n",
    "# put the annotations above other elements\n",
    "    \n",
    "\n",
    "\n",
    "fig.write_image(\n",
    "    os.path.join(trend_folder, f\"station_{station_id}.png\"),\n",
    "    scale=15,\n",
    "    width=400,\n",
    "    height=220 * len(columns)\n",
    ")\n",
    "\n",
    "\n",
    "statistics_df.to_excel(\n",
    "    os.path.join(trend_folder, 'statistics.xlsx')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
