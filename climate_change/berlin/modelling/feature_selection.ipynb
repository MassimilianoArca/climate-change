{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import optuna\n",
    "\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"data\", \"berlin\")\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df = pd.read_excel(os.path.join(clean_data_folder, \"surface.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = pd.read_excel(os.path.join(clean_data_folder, \"ground.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns = [\"DateTime\", \"Station\"]\n",
    "bacteria_columns = [\n",
    "    \"E.Coli (MPN/100ml)\",\n",
    "    \"Enterococcus (MPN/100ml)\",\n",
    "    \"Coliform (MPN/100ml)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Test\n",
    "\n",
    "We use the following rules of thumb for interpreting VIF values:\n",
    "\n",
    "* VIF = 1: There is no correlation between a given predictor variable and any other predictor variables in the model.\n",
    "* VIF between 1 and 5: There is moderate correlation between a given predictor variable and other predictor variables in the model.\n",
    "* VIF > 5: There is severe correlation between a given predictor variable and other predictor variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = {}\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    df = surface_df[surface_df['Station'] == station_id]\n",
    "    \n",
    "    df = df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    #find design matrix for regression model using 'rating' as response variable \n",
    "    y, X = dmatrices(\n",
    "        'Q(\"DOC (mg/l)\") ~ Q(\"Air Temperature (°C)\")+Q(\"Ammonium (mg/l)\")+Q(\"Conductivity (µS/cm)\")+Q(\"Dissolved Oxygen (mg/l)\")+Q(\"Nitrate (mg/l)\")+Q(\"Water Temperature (°C)\")+pH+Q(\"Flow River Rate (m³/s)\")+Q(\"Cumulated Rainfall (mm)\")',\n",
    "        data=df,\n",
    "        return_type='dataframe'\n",
    "    )\n",
    "\n",
    "    #create DataFrame to hold VIF values\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df['variable'] = X.columns \n",
    "\n",
    "    #calculate VIF for each predictor variable \n",
    "    vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    \n",
    "    vifs[station_id] = vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs[305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs[325]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_feature_selection(\n",
    "    X_tr, y_tr, X_ts, y_ts, pvalue_threshold=0.05\n",
    "):\n",
    "\n",
    "    initial_list = list(X_tr.columns)\n",
    "    included = list(X_tr.columns)\n",
    "\n",
    "    summaries = {}\n",
    "    results = {}\n",
    "    bfs_insights = {}\n",
    "    index = 0\n",
    "    excluded_variable = None\n",
    "\n",
    "    changed = True\n",
    "\n",
    "    while True:\n",
    "        changed = False\n",
    "\n",
    "        # Fit the regression model\n",
    "        model = sm.OLS(\n",
    "            y_tr.values, sm.add_constant(X_tr[included])\n",
    "        ).fit()\n",
    "        result = {}\n",
    "\n",
    "        # PREDICTION STEP\n",
    "        predictions = model.get_prediction(\n",
    "            sm.add_constant(X_ts[included])\n",
    "        ).summary_frame(alpha=0.05)\n",
    "\n",
    "        train_res = model.resid\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_ts, predictions[\"mean\"]))\n",
    "        r2 = r2_score(y_ts, predictions[\"mean\"])\n",
    "\n",
    "        residuals = (\n",
    "            y_ts[\"DOC (mg/l)\"].values - predictions[\"mean\"].values\n",
    "        )\n",
    "\n",
    "        model.aic\n",
    "        #### Store Results\n",
    "\n",
    "        result[\"y_pred\"] = predictions[\"mean\"]\n",
    "        result[\"y_lower_bound\"] = predictions[\"obs_ci_lower\"]\n",
    "        result[\"y_upper_bound\"] = predictions[\"obs_ci_upper\"]\n",
    "\n",
    "        result[\"train_res\"] = train_res\n",
    "        result[\"residuals\"] = residuals\n",
    "\n",
    "        result[\"rmse\"] = rmse\n",
    "        result[\"r2\"] = r2\n",
    "        result[\"aic\"] = model.aic\n",
    "\n",
    "        result[\"model\"] = model\n",
    "\n",
    "        results[index] = result\n",
    "\n",
    "        # FEATURE SELECTION STEP\n",
    "        index += 1\n",
    "\n",
    "        # Get the pvalues of the model\n",
    "        pvalues = model.pvalues[1:]\n",
    "\n",
    "        insights = pd.DataFrame(\n",
    "            {\n",
    "                \"step\": index,\n",
    "                \"n_features\": len(included),\n",
    "                \"features\": included,\n",
    "                \"dropped_feature\": excluded_variable,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        bfs_insights[index] = insights\n",
    "        summaries[index] = model.summary2()\n",
    "\n",
    "        # Find the variable with the highest pvalue\n",
    "        highest_pvalue = pvalues.max()\n",
    "        if highest_pvalue >= pvalue_threshold:\n",
    "            changed = True\n",
    "            excluded_variable = pvalues.idxmax()\n",
    "            included.remove(excluded_variable)\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return results, summaries, bfs_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, lags: int, rolling_window: int, poly_degree: int):\n",
    "    \n",
    "    initial_features = df.columns\n",
    "    # add polynomial features\n",
    "    poly = PolynomialFeatures(degree=poly_degree)\n",
    "    df_poly = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df_poly, columns=poly.get_feature_names_out(df.columns))\n",
    "    \n",
    "    # add lagged, rolling and expanding features for each variable in df\n",
    "    for col in initial_features.difference([\"Year\", \"Month\"]):\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
    "            \n",
    "        df[f\"{col}_rolling{rolling_window}\"] = df[col].rolling(rolling_window).mean()\n",
    "        \n",
    "    # fill NaN values with bfill\n",
    "    df.bfill(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "summaries_dict = {}\n",
    "bfs_insights_dict = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    df = surface_df[surface_df['Station'] == station_id]\n",
    "    \n",
    "    # add the year and month columns\n",
    "    df[\"Year\"] = df[\"DateTime\"].dt.year\n",
    "    df[\"Month\"] = df[\"DateTime\"].dt.month\n",
    "    \n",
    "    df = df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    X = df.drop(columns=[\"DOC (mg/l)\"])\n",
    "    y = df[[\"DOC (mg/l)\"]]\n",
    "    \n",
    "    # X = extend_features(X, lags=2, rolling_window=3, poly_degree=2)\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    cols = X.columns\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "    \n",
    "    X_tr, X_ts = X[:int(0.7 * len(X))], X[int(0.7 * len(X)):]\n",
    "    \n",
    "    y_tr, y_ts = y[:int(0.7 * len(y))], y[int(0.7 * len(y)):]\n",
    "    \n",
    "    results, summaries, bfs_insights = backward_feature_selection(\n",
    "        X_tr, y_tr, X_ts, y_ts, pvalue_threshold=0.05\n",
    "    )   \n",
    "    \n",
    "    results_dict[station_id] = results\n",
    "    summaries_dict[station_id] = summaries\n",
    "    bfs_insights_dict[station_id] = bfs_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in surface_df['Station'].unique():\n",
    "    print(f\"=== Station {station_id} ===\")\n",
    "    \n",
    "    summaries = summaries_dict[station_id]\n",
    "    bfs_insights = bfs_insights_dict[station_id]\n",
    "    results = results_dict[station_id]\n",
    "    \n",
    "    for i in summaries.keys():\n",
    "        step = bfs_insights[i][\"step\"].iloc[0]\n",
    "        print(f\"================= Step {step} =================\")\n",
    "        print()\n",
    "        print(f\"N Features: {bfs_insights[step]['n_features'].iloc[0]}\")\n",
    "        print(f\"Features: {bfs_insights[step]['features'].values.tolist()}\")\n",
    "        print(\n",
    "            f\"Dropped Feature: {bfs_insights[step]['dropped_feature'].iloc[0]}\"\n",
    "        )\n",
    "\n",
    "        print()\n",
    "        print(summaries[i])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=============================================\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"Final Features for Station {station_id}\")\n",
    "    print(f\"=================\")\n",
    "    print()\n",
    "    print(f\"N Features: {bfs_insights[step]['n_features'].iloc[0]}\")\n",
    "    print(f\"Features: {bfs_insights[step]['features'].values}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
