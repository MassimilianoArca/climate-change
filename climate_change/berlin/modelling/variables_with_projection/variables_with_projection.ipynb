{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"..\", \"..\", \"data\", \"berlin\")\n",
    "clean_data_folder = os.path.join(data_folder, \"clean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df = pd.read_excel(os.path.join(clean_data_folder, \"surface.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = pd.read_excel(os.path.join(clean_data_folder, \"ground.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns = [\"DateTime\", \"Station\"]\n",
    "bacteria_columns = [\n",
    "    \"E.Coli (MPN/100ml)\",\n",
    "    \"Enterococcus (MPN/100ml)\",\n",
    "    \"Coliform (MPN/100ml)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, lags: int, rolling_window: int, poly_degree: int):\n",
    "    \n",
    "    initial_features = df.columns\n",
    "    # add polynomial features\n",
    "    poly = PolynomialFeatures(degree=poly_degree)\n",
    "    df_poly = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df_poly, columns=poly.get_feature_names_out(df.columns))\n",
    "    \n",
    "    # add lagged, rolling and expanding features for each variable in df\n",
    "    for col in initial_features.difference([\"Year\", \"Month\"]):\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
    "            \n",
    "        df[f\"{col}_rolling{rolling_window}\"] = df[col].rolling(rolling_window).mean()\n",
    "        \n",
    "    # fill NaN values with bfill\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    df.drop(columns=['1'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    \"Ammonium (mg/l)\",\n",
    "    \"Conductivity (ÂµS/cm)\",\n",
    "    \"Dissolved Oxygen (mg/l)\",\n",
    "    \"Nitrate (mg/l)\",\n",
    "    \"pH\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/z5/plf0_b5s39nb0_gctbxmpndc0000gn/T/ipykernel_85690/3521460032.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "# Prepare the data for the models\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    df = surface_df[surface_df['Station'] == station_id]\n",
    "    \n",
    "    # add the year and month columns\n",
    "    df[\"Year\"] = df[\"DateTime\"].dt.year\n",
    "    df[\"Month\"] = df[\"DateTime\"].dt.month\n",
    "    \n",
    "    # Save the datetime column for later (drop diff returns error\n",
    "    # if I remove it before)\n",
    "    datetime_column = df.drop(columns=bacteria_columns).dropna()[\"DateTime\"]\n",
    "    \n",
    "    df = df.drop(columns=diff_columns + bacteria_columns).dropna()\n",
    "    \n",
    "    X = df.drop(columns=[\"DOC (mg/l)\"])\n",
    "    y = df[[\"DOC (mg/l)\"]]\n",
    "    \n",
    "    X = extend_features(X, lags=1, rolling_window=3, poly_degree=2)\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    cols = X.columns\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "    \n",
    "    # Add the datetime column back\n",
    "    X[\"DateTime\"] = datetime_column.values\n",
    "    y[\"DateTime\"] = datetime_column.values\n",
    "    \n",
    "    \n",
    "    X = X.set_index(\"DateTime\")\n",
    "    y = y.set_index(\"DateTime\")\n",
    "    \n",
    "    X_tr, X_ts = X[:int(train_size * len(X))], X[int(train_size * len(X)):]\n",
    "    y_tr, y_ts = y[:int(train_size * len(y))], y[int(train_size * len(y)):]\n",
    "    \n",
    "    datasets[station_id] = (X_tr, X_ts, y_tr, y_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    model = sm.OLS(y_tr, sm.add_constant(X_tr))\n",
    "    results = model.fit()\n",
    "    \n",
    "    predictions = results.get_prediction(sm.add_constant(X_ts)).summary_frame(alpha=0.05)\n",
    "    \n",
    "    lr_results[station_id] = {\n",
    "        \"y_pred\": predictions['mean'],\n",
    "        \"y_pred_lower\": predictions['mean_ci_lower'],\n",
    "        \"y_pred_upper\": predictions['mean_ci_upper'],\n",
    "        \"model\": results,\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_ts, predictions[\"mean\"])),\n",
    "        \"r2\": r2_score(y_ts, predictions[\"mean\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_rf(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    # define the hyperparameters to search over\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 500, step=10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 32),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_rmse = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X_cv)):\n",
    "        cv_rmse[i] = fit_and_validate_rf(\n",
    "            X_cv, y_cv, train_index, test_index, params\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_rmse\", cv_rmse)\n",
    "\n",
    "    return np.mean(cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_studies = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    X_tr, _, y_tr, _ = datasets[station_id]\n",
    "    \n",
    "    if os.path.exists(f\"RandomForest-Station{station_id}-Extended.sqlite3\"):\n",
    "        \n",
    "        study = optuna.load_study(\n",
    "        study_name=\"Hyperparameter Tuning - RandomForest\"\n",
    "        + \" + \"\n",
    "        + f\"Station {station_id}\",\n",
    "        storage=f\"sqlite:///RandomForest-Station{station_id}-Extended.sqlite3\",\n",
    "    )\n",
    "\n",
    "    else:\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            storage=f\"sqlite:///RandomForest-Station{station_id}-Extended.sqlite3\",\n",
    "            study_name=\"Hyperparameter Tuning - RandomForest\"\n",
    "            + \" + \"\n",
    "            + f\"Station {station_id}\",\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "        study.optimize(lambda trial: objective(trial, X_tr, y_tr), n_trials=100, show_progress_bar=True)\n",
    "    \n",
    "    rf_studies[station_id] = study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_results = {}\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    params = rf_studies[station_id].best_params\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    n_size = len(X_tr)\n",
    "    predictions = np.zeros((len(X_ts), n_iterations))\n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "    # Bootstrap sample (random state changes each iteration)\n",
    "        X_resampled, y_resampled = resample(X_tr, y_tr, n_samples=n_size, random_state=i)\n",
    "        \n",
    "        # Train the model with the best hyperparameters\n",
    "        model = RandomForestRegressor(random_state=42, **params)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_ts)\n",
    "        predictions[:, i] = y_pred\n",
    "        \n",
    "        # Calculate and store the metric (e.g., RMSE)\n",
    "        metric = mean_squared_error(y_ts, y_pred, squared=False)\n",
    "        metrics.append(metric)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Convert to a numpy array for easier calculation\n",
    "    metrics = np.array(metrics)\n",
    "    \n",
    "    # Calculate the mean RMSE\n",
    "    mean_rmse = np.mean(metrics)\n",
    "    \n",
    "    # Calculate 95% confidence interval of the predictions\n",
    "    lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "    upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "    \n",
    "    # Calculate the mean predictions\n",
    "    mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "    rf_results[station_id] = {\n",
    "        \"y_pred\": mean_predictions,\n",
    "        \"y_pred_lower\": lower_bound,\n",
    "        \"y_pred_upper\": upper_bound,\n",
    "        \"model\": model,\n",
    "        \"rmse\": mean_rmse,\n",
    "        \"r2\": r2_score(y_ts, mean_predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_xgb_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = xgb.XGBRegressor(random_state=42, **params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    eta = trial.suggest_float(\"eta\", 1e-5, 1, log=True)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1, log=True)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1, log=True)\n",
    "    learning_rate = trial.suggest_float(\n",
    "        \"learning_rate\", 1e-5, 1, log=True\n",
    "    )\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    updater = trial.suggest_categorical(\n",
    "        \"updater\", [\"shotgun\", \"coord_descent\"]\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"booster\": \"gblinear\",\n",
    "        \"eta\": eta,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"updater\": updater,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_rmse = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_cv, y_cv)\n",
    "    ):\n",
    "        cv_rmse[i] = fit_and_validate_xgb_model(\n",
    "            X_cv,\n",
    "            y_cv,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            params,\n",
    "        )\n",
    "\n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_rmse\", cv_rmse)\n",
    "\n",
    "    return np.mean(cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_studies = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    \n",
    "    X_tr, _, y_tr, _ = datasets[station_id]\n",
    "\n",
    "    if os.path.exists(f\"XGBoost-Station{station_id}-Extended.sqlite3\"):\n",
    "            \n",
    "        study = optuna.load_study(\n",
    "        study_name=\"Hyperparameter Tuning - XGBoost\"\n",
    "        + \" + \"\n",
    "        + f\"Station{station_id}\",\n",
    "        storage=f\"sqlite:///XGBoost-Station{station_id}-Extended.sqlite3\",\n",
    "        )\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            storage=f\"sqlite:///XGBoost-Station{station_id}-Extended.sqlite3\",\n",
    "            study_name=\"Hyperparameter Tuning - XGBoost\"\n",
    "            + \" + \"\n",
    "            + f\"Station{station_id}\",\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "        study.optimize(lambda trial: objective(trial, X_tr, y_tr), n_trials=100, show_progress_bar=True)\n",
    "            \n",
    "    xgb_studies[station_id] = study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = {}\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    params = xgb_studies[station_id].best_params\n",
    "    \n",
    "    params[\"objective\"] = \"reg:squarederror\"\n",
    "    params[\"booster\"] = \"gblinear\"\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    n_size = len(X_tr)\n",
    "    predictions = np.zeros((len(X_ts), n_iterations))\n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "    # Bootstrap sample (random state changes each iteration)\n",
    "        X_resampled, y_resampled = resample(X_tr, y_tr, n_samples=n_size, random_state=i)\n",
    "        \n",
    "        # Train the model with the best hyperparameters\n",
    "        model = xgb.XGBRegressor(**params, random_state=42)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_ts)\n",
    "        predictions[:, i] = y_pred\n",
    "        \n",
    "        # Calculate and store the metric (e.g., RMSE)\n",
    "        metric = mean_squared_error(y_ts, y_pred, squared=False)\n",
    "        metrics.append(metric)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Convert to a numpy array for easier calculation\n",
    "    metrics = np.array(metrics)\n",
    "    \n",
    "    # Calculate the mean RMSE\n",
    "    mean_rmse = np.mean(metrics)\n",
    "    \n",
    "    # Calculate 95% confidence interval of the predictions\n",
    "    lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "    upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "    \n",
    "    # Calculate the mean predictions\n",
    "    mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "    xgb_results[station_id] = {\n",
    "        \"y_pred\": mean_predictions,\n",
    "        \"y_pred_lower\": lower_bound,\n",
    "        \"y_pred_upper\": upper_bound,\n",
    "        \"model\": model,\n",
    "        \"rmse\": mean_rmse,\n",
    "        \"r2\": r2_score(y_ts, mean_predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_lgbm_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        random_state=42,\n",
    "        linear_tree=True,\n",
    "    )\n",
    "\n",
    "    if params is not None:\n",
    "        model.set_params(**params)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr)\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    config = {\n",
    "        \"n_estimators\": trial.suggest_int(\n",
    "            \"n_estimators\", 1, 20, step=1\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_float(\n",
    "            \"learning_rate\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16, step=1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20, step=1),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\n",
    "            \"min_data_in_leaf\", 2, 50, step=1\n",
    "        ),\n",
    "        \"lambda_l1\": trial.suggest_float(\n",
    "            \"lambda_l1\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"lambda_l2\": trial.suggest_float(\n",
    "            \"lambda_l2\", 1e-3, 10, log=True\n",
    "        ),\n",
    "        \"min_split_gain\": trial.suggest_float(\n",
    "            \"min_split_gain\", 0, 15, step=0.5\n",
    "        ),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 1e-3, 1, log=True\n",
    "        ),\n",
    "        \"min_child_samples\": trial.suggest_int(\n",
    "            \"min_child_samples\", 20, 1000, log=True\n",
    "        ),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 500, step=10),\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_rmse = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_cv, y_cv)\n",
    "    ):\n",
    "        cv_rmse[i] = fit_and_validate_lgbm_model(\n",
    "            X_cv,\n",
    "            y_cv,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "        \n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_rmse\", cv_rmse)\n",
    "    \n",
    "    return np.mean(cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_studies = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "        \n",
    "        X_tr, _, y_tr, _ = datasets[station_id]\n",
    "    \n",
    "        if os.path.exists(f\"LGBM-Station{station_id}-Extended.sqlite3\"):\n",
    "                \n",
    "            study = optuna.load_study(\n",
    "            study_name=\"Hyperparameter Tuning - LGBM\"\n",
    "            + \" + \"\n",
    "            + f\"Station {station_id}\",\n",
    "            storage=f\"sqlite:///LGBM-Station{station_id}-Extended.sqlite3\",\n",
    "            )\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            study = optuna.create_study(\n",
    "                direction=\"minimize\",\n",
    "                storage=f\"sqlite:///LGBM-Station{station_id}-Extended.sqlite3\",\n",
    "                study_name=\"Hyperparameter Tuning - LGBM\"\n",
    "                + \" + \"\n",
    "                + f\"Station {station_id}\",\n",
    "                load_if_exists=True,\n",
    "            )\n",
    "            study.optimize(lambda trial: objective(trial, X_tr, y_tr), n_trials=100, show_progress_bar=True)\n",
    "                \n",
    "        lgbm_studies[station_id] = study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 689\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.933745\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.839389\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 607\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.730070\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.751490\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 607\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.765000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 608\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 6.050169\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 674\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.825404\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 643\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.798628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 674\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.796495\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.802475\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 605\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.907455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.798888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 680\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.859248\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.874561\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 694\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.685487\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 693\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.853151\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.846005\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 672\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.724284\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 654\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.812536\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.878144\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 602\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.827984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.755014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 655\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.818636\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 682\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.722753\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 592\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.741059\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 703\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.916622\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 672\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.948328\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.812170\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.823773\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 679\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.825540\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.790626\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.791217\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.898801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.790740\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.710051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.741816\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.845721\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 654\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.894070\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 608\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.941079\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 576\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.614320\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.752577\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 646\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.871007\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.813077\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 694\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.887840\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.917238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.751918\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.894365\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.762304\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 595\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.977832\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.644554\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.792292\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 687\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.927559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 687\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.806657\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 657\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.819332\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 696\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.867978\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.793213\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 689\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.904414\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 687\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.858962\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.837053\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 695\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.695140\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 691\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.670277\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 575\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.812169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.891623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 684\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.882885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 698\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.780357\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.900435\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 688\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.747572\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 629\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.811017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.952992\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 680\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.798984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.951864\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.742151\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.813346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 6.018486\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 621\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.766786\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 649\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.741882\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.686258\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 698\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.839141\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.850676\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.929494\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 684\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.945581\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.784222\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.891021\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.854066\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 627\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.688420\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 692\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.783391\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 691\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.800668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.652539\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 703\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.846475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.853204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.803380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.844434\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.714102\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 691\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.789694\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 702\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.780464\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.862377\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.799008\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.915949\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.849253\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 674\n",
      "[LightGBM] [Info] Number of data points in the train set: 64, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 5.755137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008681257378218206, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008681257378218206\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0035375709277243434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035375709277243434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6067749848195905, subsample=0.9444290735841788 will be ignored. Current value: bagging_fraction=0.6067749848195905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=300 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.011827151587395912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.011827151587395912\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.737154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.821487\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.837149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.861417\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.876392\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.812809\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.822650\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.749415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.798755\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.725543\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.947083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.764102\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.806629\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.742940\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.857007\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.838477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.866239\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.776759\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.741995\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.835182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.750075\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.733665\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.863772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.788743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.789374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.922666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.869632\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.771841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.833356\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.782377\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.814826\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.867708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.842668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.866971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.760336\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.896934\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.798169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.830525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.856800\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.765624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.857845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.808907\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.827933\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.779378\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.870271\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.908926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.729290\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.928305\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.805519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.785201\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.831983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.812018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.862750\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.777651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.727326\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.806659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.820790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.858830\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.793924\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.741753\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.972727\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.683902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.773257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.720388\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.759014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.846918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.915731\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.862436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.868014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.889698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.858335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.800000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.887987\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.808577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.933205\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.945460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.794616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.781150\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.775782\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.780448\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.915076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.859634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.912929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.727118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.851115\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.850218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.772956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.705057\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.808689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.834054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.829681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.803029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.736292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.850748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.888724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.934338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.922727\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.894497\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.737013\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 8.808929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001026241895969053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001026241895969053\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0020976851763693017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020976851763693017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11861115933227796, subsample=0.9963871252277148 will be ignored. Current value: bagging_fraction=0.11861115933227796\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=70 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8907662253900199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8907662253900199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2591\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.574072\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2648\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.458718\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.529689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.552057\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2555\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.528107\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2607\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.470986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2568\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.451942\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.526414\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2609\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.448182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2505\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.493938\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.513178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.519713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.446612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2593\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.516585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2600\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.568058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2608\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.466078\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2588\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.544977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2583\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.620982\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2476\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.411664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.536011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2573\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.486307\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.666938\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2614\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.447441\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.593340\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.554888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.532579\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2580\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.513686\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2592\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.511581\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2558\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.643856\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2572\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.552992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.482604\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2540\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.556393\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2627\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.543368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.389919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2559\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.575025\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2570\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.612074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2516\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.570891\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2615\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.539599\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2583\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.556469\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.514130\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2567\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.571703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2577\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.552496\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2498\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.523181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2547\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.626516\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2601\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.515971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2603\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.447373\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2547\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.516691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2589\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.514364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2543\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.564959\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2597\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.564220\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2594\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.524762\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.425491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2570\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.383482\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2614\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.498753\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.386487\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2518\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.486458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2607\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.594153\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2565\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.571058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2591\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.533632\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.501530\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2554\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.530277\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.583246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2570\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.535125\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.518586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2579\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.583464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2568\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.454433\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2551\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.580847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.596608\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2614\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.408287\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2555\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.556361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2600\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.591652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.514600\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2493\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.513762\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.460040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2534\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.553043\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.515098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2524\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.543379\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2541\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.554403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2506\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.528326\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.526082\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2543\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.526668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2525\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.570732\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.524690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2583\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.497915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2609\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.538846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2530\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.495204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2541\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.422451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2579\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.528446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.575870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2612\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.505709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.524063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2553\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.462306\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.413236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.584640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.441977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2620\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.415080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2604\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.508109\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2616\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.511915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.588876\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2551\n",
      "[LightGBM] [Info] Number of data points in the train set: 313, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 7.515502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11286413565654808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11286413565654808\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007973379963012775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007973379963012775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309993452828618, subsample=0.8489681098419225 will be ignored. Current value: bagging_fraction=0.14309993452828618\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=700 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.0022104738088989688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.0022104738088989688\n"
     ]
    }
   ],
   "source": [
    "lgbm_results = {}\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    params = lgbm_studies[station_id].best_params\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    n_size = len(X_tr)\n",
    "    predictions = np.zeros((len(X_ts), n_iterations))\n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "    # Bootstrap sample (random state changes each iteration)\n",
    "        X_resampled, y_resampled = resample(X_tr, y_tr, n_samples=n_size, random_state=i)\n",
    "        \n",
    "        # Train the model with the best hyperparameters\n",
    "        model = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        random_state=42,\n",
    "        linear_tree=True,\n",
    "        )\n",
    "        \n",
    "        model.set_params(**params)\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_ts)\n",
    "        predictions[:, i] = y_pred\n",
    "        \n",
    "        # Calculate and store the metric (e.g., RMSE)\n",
    "        metric = mean_squared_error(y_ts, y_pred, squared=False)\n",
    "        metrics.append(metric)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Convert to a numpy array for easier calculation\n",
    "    metrics = np.array(metrics)\n",
    "    \n",
    "    # Calculate the mean RMSE\n",
    "    mean_rmse = np.mean(metrics)\n",
    "    \n",
    "    # Calculate 95% confidence interval of the predictions\n",
    "    lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "    upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "    \n",
    "    # Calculate the mean predictions\n",
    "    mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "    lgbm_results[station_id] = {\n",
    "        \"y_pred\": mean_predictions,\n",
    "        \"y_pred_lower\": lower_bound,\n",
    "        \"y_pred_upper\": upper_bound,\n",
    "        \"model\": model,\n",
    "        \"rmse\": mean_rmse,\n",
    "        \"r2\": r2_score(y_ts, mean_predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_nn_model(\n",
    "    X,\n",
    "    y,\n",
    "    train_index,\n",
    "    val_index,\n",
    "    params,\n",
    "):\n",
    "    X_tr, X_val = X.iloc[train_index, :], X.iloc[val_index, :]\n",
    "    y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = MLPRegressor(\n",
    "        random_state=42,\n",
    "        hidden_layer_sizes=tuple(params[\"layers\"]),\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    param = params.copy()\n",
    "    param.pop(\"layers\")\n",
    "    model.set_params(**param)\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "    # obtain predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # return metrics\n",
    "    return mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, X_cv, y_cv) -> float:\n",
    "    config = {\n",
    "        \"layers\": [\n",
    "            trial.suggest_int(f\"n_units_{i}\", 50, 100, step=5)\n",
    "            for i in range(trial.suggest_int(\"n_layers\", 2, 2))\n",
    "        ],\n",
    "        \"activation\": trial.suggest_categorical(\n",
    "            \"activation\", [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "        ),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"sgd\", \"adam\"]),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-5, 1),\n",
    "        \"learning_rate\": trial.suggest_categorical(\n",
    "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "        ),\n",
    "        \"power_t\": trial.suggest_float(\"power_t\", 0.1, 1),\n",
    "        \"beta_1\": trial.suggest_float(\"beta_1\", 0.1, 1),\n",
    "        \"beta_2\": trial.suggest_float(\"beta_2\", 0.1, 1),\n",
    "        \"epsilon\": trial.suggest_float(\"epsilon\", 1e-8, 1),\n",
    "        \"early_stopping\": True,\n",
    "    }\n",
    "\n",
    "    n_splits = 5\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_rmse = [None] * n_splits\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        cv.split(X_cv, y_cv)\n",
    "    ):\n",
    "        cv_rmse[i] = fit_and_validate_nn_model(\n",
    "            X_cv,\n",
    "            y_cv,\n",
    "            train_index,\n",
    "            test_index,\n",
    "            config,\n",
    "        )\n",
    "        \n",
    "    # saving the individual fold holdout metrics\n",
    "    # uncomment this line if you don't want this\n",
    "    trial.set_user_attr(\"split_rmse\", cv_rmse)\n",
    "    \n",
    "    return np.mean(cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_studies = {}\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "            \n",
    "    X_tr, _, y_tr, _ = datasets[station_id]\n",
    "\n",
    "    if os.path.exists(f\"MLP-Station{station_id}-Extended.sqlite3\"):\n",
    "            \n",
    "        study = optuna.load_study(\n",
    "        study_name=\"Hyperparameter Tuning - MLP\"\n",
    "        + \" + \"\n",
    "        + f\"Station {station_id}\",\n",
    "        storage=f\"sqlite:///MLP-Station{station_id}-Extended.sqlite3\",\n",
    "        )\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            storage=f\"sqlite:///MLP-Station{station_id}-Extended.sqlite3\",\n",
    "            study_name=\"Hyperparameter Tuning - MLP\"\n",
    "            + \" + \"\n",
    "            + f\"Station {station_id}\",\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "        study.optimize(lambda trial: objective(trial, X_tr, y_tr), n_trials=100, show_progress_bar=True)\n",
    "            \n",
    "    mlp_studies[station_id] = study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/massimilianoarca/Library/Caches/pypoetry/virtualenvs/climate-change-MEYtuKH4-py3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_results = {}\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    params = mlp_studies[station_id].best_params\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    n_size = len(X_tr)\n",
    "    predictions = np.zeros((len(X_ts), n_iterations))\n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # Copy since we will be modifying the params\n",
    "        params_copy = params.copy()\n",
    "        \n",
    "        # Bootstrap sample (random state changes each iteration)\n",
    "        X_resampled, y_resampled = resample(X_tr, y_tr, n_samples=n_size, random_state=i)\n",
    "        \n",
    "        \n",
    "        hidden_layer_sizes = [\n",
    "            params_copy[f\"n_units_{k}\"] for k in range(params_copy[\"n_layers\"])\n",
    "        ]\n",
    "\n",
    "        for j in range(params_copy[\"n_layers\"]):\n",
    "            params_copy.pop(f\"n_units_{j}\")\n",
    "\n",
    "        params_copy.pop(\"n_layers\")\n",
    "            \n",
    "        model = MLPRegressor(\n",
    "            random_state=42,\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            max_iter=1000,\n",
    "        )\n",
    "    \n",
    "        model.set_params(**params_copy)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        model.fit(X_resampled, y_resampled.values.ravel())\n",
    "        y_pred = model.predict(X_ts)\n",
    "        predictions[:, i] = y_pred\n",
    "        \n",
    "        # Calculate and store the metric (e.g., RMSE)\n",
    "        metric = mean_squared_error(y_ts, y_pred, squared=False)\n",
    "        metrics.append(metric)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Convert to a numpy array for easier calculation\n",
    "    metrics = np.array(metrics)\n",
    "    \n",
    "    # Calculate the mean RMSE\n",
    "    mean_rmse = np.mean(metrics)\n",
    "    \n",
    "    # Calculate 95% confidence interval of the predictions\n",
    "    lower_bound = np.percentile(predictions, 2.5, axis=1)\n",
    "    upper_bound = np.percentile(predictions, 97.5, axis=1)\n",
    "    \n",
    "    # Calculate the mean predictions\n",
    "    mean_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "    mlp_results[station_id] = {\n",
    "        \"y_pred\": mean_predictions,\n",
    "        \"y_pred_lower\": lower_bound,\n",
    "        \"y_pred_upper\": upper_bound,\n",
    "        \"model\": model,\n",
    "        \"rmse\": mean_rmse,\n",
    "        \"r2\": r2_score(y_ts, mean_predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Station 105 ===\n",
      "Linear Regression RMSE: 1.4523545291338733\n",
      "Random Forest RMSE: 0.47947562127127646\n",
      "XGBoost RMSE: 0.4434667483009191\n",
      "LightGBM RMSE: 0.4729026078070028\n",
      "Neural Network RMSE: 0.7502811502385773\n",
      "\n",
      "Linear Regression R2: -5.60415433597191\n",
      "Random Forest R2: 0.43202495458589885\n",
      "XGBoost R2: 0.4677063430034678\n",
      "LightGBM R2: 0.5174024740259568\n",
      "Neural Network R2: -0.7433654980645912\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "black"
         },
         "mode": "lines",
         "name": "True",
         "type": "scatter",
         "x": [
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          5.3,
          7,
          6.1,
          5.9,
          6.3,
          5.5,
          5.3,
          5.5,
          5.2,
          5.544444444444444,
          5.855555555555556,
          6.2,
          5.6,
          5.4,
          5.8,
          5.9,
          7.9,
          6.2,
          6.1,
          6.1,
          5.9,
          6.1,
          6.225842696629213,
          6.365168539325842,
          6.5,
          6.6,
          6.5,
          6.6,
          7,
          6.4,
          6.6,
          4.7,
          5.2,
          5.2,
          5.152542372881356,
          5.1,
          6.6,
          6,
          6.1,
          5.7,
          5.7,
          6,
          5.5,
          3.2,
          5.2,
          4.8,
          5.8,
          5.7,
          5.7,
          5.7,
          6.6,
          6.7,
          6.5,
          6.5,
          5.5,
          6,
          5.15,
          4.3,
          4.646067415730337,
          5.029213483146068,
          5.4,
          5.8,
          5.75,
          6.4,
          5.7,
          5.650819672131147,
          5.6,
          5.1,
          4.9,
          5.2,
          5.8,
          5.4,
          5.4,
          6.4,
          5.7,
          5.8,
          6,
          6.5,
          5.890163934426229,
          5.3,
          4.9,
          5.1,
          5.257303370786516,
          5.431460674157303,
          5.6,
          6.3,
          6.9,
          6.5,
          7.1,
          6.362295081967213,
          5.6,
          5.9
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Linear Regression",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.1032193448917536,
          6.62228327670774,
          6.832259067707712,
          4.619799308112118,
          4.700966481314948,
          6.386986936338181,
          4.616901644954177,
          3.3741398801974034,
          3.801782033980522,
          6.738377729481201,
          7.666033108628676,
          8.115861855395227,
          5.641304075127948,
          6.269086832732798,
          5.749631102410612,
          4.990642349045838,
          3.538337127798517,
          5.617212229433885,
          6.436622834624359,
          7.361473790490227,
          9.306643863745052,
          8.895831846800561,
          5.303614415889066,
          6.061584472465109,
          6.20653857901943,
          8.165047155799982,
          4.0899856472447915,
          5.375670275006865
         ]
        },
        {
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          4.0339386317363015,
          4.6722480989906705,
          4.433506725498118,
          2.0718758123635617,
          1.60621930532132,
          2.9100807338380688,
          2.379594719908771,
          0.6297594583748753,
          1.7922652760654758,
          4.710410892645338,
          5.288091853399036,
          4.492456696769874,
          3.240397696626796,
          2.8830277645248112,
          3.169553508060893,
          2.2125015050620265,
          0.0733509060182489,
          1.619975619627514,
          2.455835045973993,
          1.8372330981507634,
          2.460341917971716,
          4.432474274101048,
          0.9197754851723747,
          2.301838094368091,
          2.6683999477665252,
          4.0831970117087435,
          -3.030701717652711,
          0.231094705846834
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,0,255,0.2)",
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          8.172500058047206,
          8.57231845442481,
          9.231011409917306,
          7.1677228038606735,
          7.795713657308577,
          9.863893138838293,
          6.8542085699995825,
          6.118520302019931,
          5.8112987918955685,
          8.766344566317063,
          10.043974363858316,
          11.73926701402058,
          8.0422104536291,
          9.655145900940784,
          8.329708696760331,
          7.768783193029649,
          7.003323349578785,
          9.614448839240255,
          10.417410623274725,
          12.885714482829691,
          16.152945809518386,
          13.359189419500076,
          9.687453346605757,
          9.821330850562127,
          9.744677210272334,
          12.24689729989122,
          11.210673012142294,
          10.520245844166896
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Random Forest",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.071429588014986,
          5.9512140819373265,
          5.842759174570652,
          5.359437732896705,
          5.2643123009592925,
          5.167036660960772,
          5.530616139965311,
          5.568500212183631,
          5.508853343533916,
          5.8647358942759364,
          6.111796622974932,
          6.303804207518218,
          6.170693293851714,
          5.826189631312698,
          5.729002775132779,
          5.456850582994231,
          5.135429294511331,
          5.608084851307281,
          5.752349144114863,
          5.81718386904592,
          5.809178030639668,
          6.034074212319346,
          6.000503869396157,
          6.145259694194364,
          6.003572835095821,
          6.144393545108362,
          5.90388119161393,
          5.531311742007177
         ]
        },
        {
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          5.765015185759178,
          5.521233006156101,
          5.331222249128246,
          4.611489350596251,
          4.916325076103022,
          4.80349395061404,
          5.162739958398726,
          5.169790646882811,
          5.219027675990925,
          5.608766918507045,
          5.757233872530035,
          5.9687471425804,
          5.6989299367170485,
          5.095055496362315,
          5.280965398034019,
          4.968871023289866,
          4.831906582289387,
          5.269640300041371,
          5.415943223458269,
          5.477303260882256,
          5.464624558558816,
          5.65524778549753,
          5.780133991992763,
          5.830180022816311,
          5.738306373498647,
          5.672587853545146,
          5.598180259589304,
          4.71780395359834
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,0,0,0.2)",
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.4807112068965615,
          6.189234120065439,
          6.424156383184807,
          5.938352382797355,
          5.589254712111046,
          5.545409337010067,
          5.835537380218039,
          6.04400693965608,
          5.788262950279126,
          6.28413255521116,
          6.482358442033643,
          6.5776567706315285,
          6.607594876017044,
          6.283006435920614,
          6.0847144617044275,
          5.916911397555362,
          5.429012164896898,
          5.833218563732791,
          5.973558789659474,
          6.026421766406839,
          6.024948632663294,
          6.479529795729468,
          6.579103738860916,
          6.543222345989944,
          6.27781131344441,
          6.490029542812868,
          6.437605143355292,
          6.126585738731746
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "XGBoost",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.129411749839782,
          5.976068019866943,
          5.796537637710571,
          5.442411823272705,
          5.137151551246643,
          5.231981830596924,
          5.389393911361695,
          5.462418451309204,
          5.3729040145874025,
          5.779131183624267,
          6.020998592376709,
          6.01494137763977,
          5.95838351726532,
          5.625937328338623,
          5.539319014549255,
          5.450615916252136,
          5.0133864164352415,
          5.305688829421997,
          5.442609376907349,
          5.531764621734619,
          5.611626062393189,
          5.8772820425033565,
          6.01331485748291,
          6.286449670791626,
          5.971607360839844,
          6.078643703460694,
          5.611772656440735,
          5.483459963798523
         ]
        },
        {
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          5.764611530303955,
          5.640785145759582,
          5.449381399154663,
          5.055895459651947,
          4.672617399692536,
          4.982554817199707,
          5.164404511451721,
          5.201253998279571,
          5.111618423461914,
          5.544314420223236,
          5.791041553020477,
          5.720517838001252,
          5.702947688102722,
          5.199812638759613,
          5.1484945058822635,
          4.97700834274292,
          4.499386179447174,
          5.043661439418793,
          5.153505349159241,
          5.206026065349579,
          5.269018924236297,
          5.5813210010528564,
          5.7871633768081665,
          6.032803654670715,
          5.533577930927277,
          5.648986840248108,
          5.193608295917511,
          4.967469334602356
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,255,0,0.2)",
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.458974516391754,
          6.2580908060073845,
          6.071249389648437,
          5.741870701313019,
          5.45527970790863,
          5.51272748708725,
          5.610896062850952,
          5.720411098003387,
          5.632654547691345,
          6.0017629861831665,
          6.238322651386261,
          6.301236140727997,
          6.259228086471557,
          5.963639557361603,
          5.843559956550598,
          5.7786483526229855,
          5.364059698581696,
          5.576857852935791,
          5.66732017993927,
          5.7621398806571955,
          5.822599172592163,
          6.178451466560364,
          6.287867486476898,
          6.59248960018158,
          6.314613425731658,
          6.4210076332092285,
          5.995839941501617,
          5.941324794292449
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines",
         "name": "LightGBM",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.347490885612482,
          6.108849267038006,
          5.950293974025675,
          5.555299026541684,
          5.296191946908839,
          5.341431735370037,
          5.3285765074661855,
          5.508555895559937,
          5.332216039425025,
          6.2636589814128,
          6.130109969616098,
          6.197440989503723,
          6.180424499919155,
          5.990418107613261,
          5.818572649014076,
          5.821007616596328,
          5.316118660655455,
          5.453516038583148,
          5.482528289954896,
          5.573515796927614,
          5.53608790776541,
          6.063864529395956,
          6.117923744384797,
          6.232892009471573,
          6.292187294462633,
          6.198859030302438,
          6.061935835661279,
          5.820004036073005
         ]
        },
        {
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          5.950942493806466,
          5.4988783535539705,
          5.37927117738921,
          4.959554834634683,
          4.91198482573679,
          4.941375436570545,
          4.749929097438122,
          4.960629813539667,
          4.9410013462329365,
          5.459974511590921,
          5.748951770276278,
          5.889513342380965,
          5.832640855768355,
          5.344903404988598,
          5.0938545679213405,
          5.135111364100159,
          4.950448713592944,
          5.1803975696523255,
          4.933343318279164,
          5.176684210646217,
          5.204957529373758,
          5.418285829522709,
          5.844962524369064,
          6.018439223736496,
          6.021280637095514,
          5.89190126864607,
          5.446476763641614,
          5.191884068020873
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(128,0,128,0.2)",
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.815355237052049,
          6.4533471893841385,
          6.358927793071616,
          6.238778954353895,
          5.651580052279706,
          5.719850052387894,
          5.955911801269833,
          6.3093134460940075,
          5.930596806961784,
          6.923382558647256,
          6.3752486728291275,
          6.675952140185417,
          6.713421376581033,
          6.404997377040141,
          6.315005614969992,
          6.321254490819684,
          5.645113946853821,
          5.952463488795438,
          6.346396358250222,
          6.138591730725507,
          5.990871395207761,
          6.447895347031299,
          6.38701680643071,
          6.5969389856380305,
          6.589952057354785,
          6.672829703819115,
          6.382241983264783,
          6.308157586903216
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Neural Network",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.936732543288145,
          6.76373093684403,
          6.614194123859023,
          6.550985706930034,
          5.97315321125019,
          4.86449109357436,
          5.728946997623877,
          5.6918826835005065,
          5.657330401052418,
          6.382144069544553,
          6.463598819481418,
          6.22384024358283,
          6.408994450682391,
          6.533028257408066,
          6.446148932104333,
          6.4073689061046615,
          5.878269190132219,
          5.594717163117921,
          5.917479861495957,
          6.190058135233833,
          6.278441098936968,
          6.565988649959313,
          6.871744417493729,
          6.962354574413147,
          6.855492676199573,
          6.943125765543879,
          6.866777769450875,
          6.817047092943361
         ]
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          6.755735020926392,
          6.585140427293129,
          6.458676988778693,
          6.414354912790489,
          5.813228516851534,
          4.621720665349182,
          5.491979730210056,
          5.481933967409456,
          5.466466461024929,
          6.228381579145833,
          6.269860635242143,
          6.024159209161916,
          6.226525759805649,
          6.3704165247743365,
          6.301583866542261,
          6.264895464192316,
          5.710893535574391,
          5.367353010861806,
          5.702061793823101,
          5.980324809226107,
          6.060234757045158,
          6.3796979059005565,
          6.714628674237866,
          6.779403523720752,
          6.673727110179009,
          6.769529024494636,
          6.727164224551139,
          6.67899423352241
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,165,0,0.2)",
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00"
         ],
         "y": [
          7.094571554151327,
          6.93402146505072,
          6.778931666529033,
          6.716073960808161,
          6.1570981850531545,
          5.137656141125406,
          5.985148872797375,
          5.914549574481827,
          5.841636027938546,
          6.539801429863505,
          6.615287480266613,
          6.4286892008819025,
          6.623270972770341,
          6.70465913197841,
          6.608264915418972,
          6.560420716525592,
          6.050778939784312,
          5.814229268409791,
          6.137929755768968,
          6.410711330601523,
          6.498033653016028,
          6.739949594856911,
          7.021628578099024,
          7.128378351681281,
          7.020041113805154,
          7.096649189361102,
          7.027423222935477,
          6.979845392387153
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "DOC (mg/l) - Station 105"
        },
        "xaxis": {
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "title": {
          "text": "DOC (mg/l)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Station 305 ===\n",
      "Linear Regression RMSE: 1.1645765110772852\n",
      "Random Forest RMSE: 1.0386456382676683\n",
      "XGBoost RMSE: 1.1060707602592261\n",
      "LightGBM RMSE: 1.2591437629168016\n",
      "Neural Network RMSE: 1.1430613713701858\n",
      "\n",
      "Linear Regression R2: 0.03535718607322469\n",
      "Random Forest R2: 0.26260160333982396\n",
      "XGBoost R2: 0.13938134651117895\n",
      "LightGBM R2: 0.2184771531399231\n",
      "Neural Network R2: 0.07947169913624186\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "black"
         },
         "mode": "lines",
         "name": "True",
         "type": "scatter",
         "x": [
          "2003-01-31T00:00:00",
          "2003-02-28T00:00:00",
          "2003-03-31T00:00:00",
          "2003-04-30T00:00:00",
          "2003-05-31T00:00:00",
          "2003-06-30T00:00:00",
          "2003-07-31T00:00:00",
          "2003-08-31T00:00:00",
          "2003-09-30T00:00:00",
          "2003-10-31T00:00:00",
          "2003-11-30T00:00:00",
          "2003-12-31T00:00:00",
          "2004-01-31T00:00:00",
          "2004-02-29T00:00:00",
          "2004-03-31T00:00:00",
          "2004-04-30T00:00:00",
          "2004-05-31T00:00:00",
          "2004-06-30T00:00:00",
          "2004-07-31T00:00:00",
          "2004-08-31T00:00:00",
          "2004-09-30T00:00:00",
          "2004-10-31T00:00:00",
          "2004-11-30T00:00:00",
          "2004-12-31T00:00:00",
          "2005-01-31T00:00:00",
          "2005-02-28T00:00:00",
          "2005-03-31T00:00:00",
          "2005-04-30T00:00:00",
          "2005-05-31T00:00:00",
          "2005-06-30T00:00:00",
          "2005-07-31T00:00:00",
          "2005-08-31T00:00:00",
          "2005-09-30T00:00:00",
          "2005-10-31T00:00:00",
          "2005-11-30T00:00:00",
          "2005-12-31T00:00:00",
          "2006-01-31T00:00:00",
          "2006-02-28T00:00:00",
          "2006-03-31T00:00:00",
          "2006-04-30T00:00:00",
          "2006-05-31T00:00:00",
          "2006-06-30T00:00:00",
          "2006-07-31T00:00:00",
          "2006-08-31T00:00:00",
          "2006-09-30T00:00:00",
          "2006-10-31T00:00:00",
          "2006-11-30T00:00:00",
          "2006-12-31T00:00:00",
          "2007-01-31T00:00:00",
          "2007-02-28T00:00:00",
          "2007-03-31T00:00:00",
          "2007-04-30T00:00:00",
          "2007-05-31T00:00:00",
          "2007-06-30T00:00:00",
          "2007-07-31T00:00:00",
          "2007-08-31T00:00:00",
          "2007-09-30T00:00:00",
          "2007-10-31T00:00:00",
          "2007-11-30T00:00:00",
          "2007-12-31T00:00:00",
          "2008-01-31T00:00:00",
          "2008-02-29T00:00:00",
          "2008-03-31T00:00:00",
          "2008-04-30T00:00:00",
          "2008-05-31T00:00:00",
          "2008-06-30T00:00:00",
          "2008-07-31T00:00:00",
          "2008-08-31T00:00:00",
          "2008-09-30T00:00:00",
          "2008-10-31T00:00:00",
          "2008-11-30T00:00:00",
          "2008-12-31T00:00:00",
          "2009-01-31T00:00:00",
          "2009-02-28T00:00:00",
          "2009-03-31T00:00:00",
          "2009-04-30T00:00:00",
          "2009-05-31T00:00:00",
          "2009-06-30T00:00:00",
          "2009-07-31T00:00:00",
          "2009-08-31T00:00:00",
          "2009-09-30T00:00:00",
          "2009-10-31T00:00:00",
          "2009-11-30T00:00:00",
          "2009-12-31T00:00:00",
          "2010-01-31T00:00:00",
          "2010-02-28T00:00:00",
          "2010-03-31T00:00:00",
          "2010-04-30T00:00:00",
          "2010-05-31T00:00:00",
          "2010-06-30T00:00:00",
          "2010-07-31T00:00:00",
          "2010-08-31T00:00:00",
          "2010-09-30T00:00:00",
          "2010-10-31T00:00:00",
          "2010-11-30T00:00:00",
          "2010-12-31T00:00:00",
          "2011-01-31T00:00:00",
          "2011-02-28T00:00:00",
          "2011-03-31T00:00:00",
          "2011-04-30T00:00:00",
          "2011-05-31T00:00:00",
          "2011-06-30T00:00:00",
          "2011-07-31T00:00:00",
          "2011-08-31T00:00:00",
          "2011-09-30T00:00:00",
          "2011-10-31T00:00:00",
          "2011-11-30T00:00:00",
          "2011-12-31T00:00:00",
          "2012-01-31T00:00:00",
          "2012-02-29T00:00:00",
          "2012-03-31T00:00:00",
          "2012-04-30T00:00:00",
          "2012-05-31T00:00:00",
          "2012-06-30T00:00:00",
          "2012-07-31T00:00:00",
          "2012-08-31T00:00:00",
          "2012-09-30T00:00:00",
          "2012-10-31T00:00:00",
          "2012-11-30T00:00:00",
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          7.7,
          8.2,
          7.65,
          8.35,
          8.3,
          10.3,
          9.5,
          10.3,
          10.25,
          9.2,
          8.1,
          8.9,
          9.2,
          10.7,
          7.9,
          8.3,
          8.2,
          8.3,
          8,
          8.3,
          7.5,
          8.05,
          7.4,
          7.7,
          7.9,
          8.1,
          8.45,
          8.1,
          8.5,
          8.85,
          8.75,
          9.15,
          8.75,
          7.9,
          7.3,
          7.3,
          8.3,
          7.8,
          8.3,
          8.5,
          8.55,
          8.7,
          9.2,
          8.6,
          8.3,
          8,
          7.5,
          7.5,
          7.6,
          7.6,
          9.4,
          9.1,
          8.9,
          9.5,
          10,
          9.7,
          9.5,
          9.2,
          8.3,
          9.7,
          9.1,
          9.2,
          10,
          10.2,
          10.5,
          10.1,
          9.9,
          9.2,
          8.708196721311475,
          8.2,
          8.8,
          8.7,
          8.4,
          7.6,
          8.8,
          8.8,
          8.8,
          8.5,
          8.5,
          9,
          9.2,
          8.1,
          8.5,
          8.7,
          9.5,
          8.5,
          10.4,
          8.6,
          10,
          10.6,
          10,
          10,
          8.7,
          8.8,
          9.2,
          10.3,
          10.4,
          10.3,
          8.6,
          9.6,
          8.6,
          8.5,
          8.9,
          12.6,
          10.2,
          9.2,
          9.1,
          8.2,
          10.3,
          9.8,
          9.6,
          9.8,
          9.3,
          9.5,
          9.3,
          9.5,
          11.7,
          8.7,
          8.3,
          8.5,
          8.3,
          9,
          9.3,
          8.9,
          9.4,
          9.8,
          9.2,
          9.1,
          8,
          8.7,
          8.4,
          8.2,
          8.46271186440678,
          8.7,
          8.4,
          8.7,
          8.4,
          9,
          8.3,
          8.9,
          8.7,
          8.8,
          8,
          7.3,
          8.7,
          8.2,
          7.8,
          7.5,
          8.4,
          8.3,
          8.2,
          8.250819672131147,
          8.3,
          7,
          7.5,
          8,
          8.3,
          8.2,
          8.2,
          9,
          8.7,
          8.2,
          8.8,
          8.4,
          8,
          8.2,
          7.9,
          7.5,
          7.7,
          7.984745762711865,
          8.3,
          8.4,
          8.1,
          8.3,
          11,
          11,
          9.1,
          9,
          10,
          9.3,
          9.1,
          9.7,
          8.6,
          9.8,
          11,
          11,
          9.7,
          10,
          9.7,
          8.3,
          8.4,
          7.6,
          8,
          8,
          8.1,
          8.6,
          8.2,
          6.7,
          9.2,
          8.7,
          8,
          5.5,
          5,
          4.4,
          8,
          8.7,
          9.1,
          8.804918032786885,
          8.5,
          9.3,
          9.5,
          8.85,
          7.841803278688524,
          6.8,
          8,
          7.9,
          8.3,
          7.2,
          8.1,
          8,
          8
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Linear Regression",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          7.477361294694861,
          8.907043748609416,
          7.283176077871086,
          8.335764280212361,
          8.85185951591493,
          7.807860656204847,
          8.233156507940288,
          8.3129886025038,
          7.982219990205116,
          8.20481185147108,
          8.381301654446283,
          6.639163770907863,
          5.8846551219457055,
          7.256890471747904,
          6.999916483480679,
          7.329592746980735,
          7.8734749260496,
          7.868292492892087,
          7.939375748812963,
          7.585521936054469,
          10.307601611803078,
          10.810313408436224,
          8.86302654122175,
          9.192217303450123,
          9.694591188814307,
          11.384159406914256,
          11.133585655042044,
          11.146924199674809,
          10.217477794106175,
          10.568645983456411,
          9.08674152483965,
          8.80260746480369,
          8.564491055736555,
          8.943987827779003,
          7.981771415574062,
          7.491612918389713,
          7.436823226826929,
          6.9782997783560665,
          7.948717820872206,
          7.135913022635097,
          8.204405845120966,
          7.859365658375888,
          8.142881684096727,
          8.72583246186501,
          8.146206746089605,
          8.81414209477872,
          7.9520514833657066,
          6.755307627580321,
          7.500041200993451,
          8.545491296667917,
          8.510451667561528,
          9.096635366537235,
          9.569209313801077,
          8.5420136776272,
          7.481546589905148,
          8.00990315938594,
          8.150348599986378,
          8.27150025093621,
          7.595312338349712,
          6.831731047329342,
          6.558307978687577,
          6.5642800351244,
          8.28590361422963,
          4.895332039922975,
          7.618524097321562,
          7.739156910019306,
          8.79815285546781
         ]
        },
        {
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          6.203058751691872,
          7.843776510809109,
          6.060532407943054,
          7.43828956218502,
          8.101488154735303,
          7.105922941732739,
          7.526218277331815,
          7.540143293259401,
          7.312422770483297,
          7.557815242711498,
          7.531259045232333,
          5.581602479118851,
          4.39333971071645,
          6.185081339019767,
          5.694249915066398,
          6.368893571075078,
          6.989461433464741,
          7.062654408597971,
          7.043925497454035,
          4.993448500818416,
          8.721576801970034,
          9.441168469486911,
          7.918483493416411,
          7.887344487945923,
          8.394846972026516,
          9.334120258720855,
          9.421887449832523,
          9.339354858376907,
          8.827241330748906,
          8.978331133010053,
          7.807389314780904,
          7.685424821719672,
          7.491199535427459,
          7.64169054676891,
          6.9101145066237475,
          6.390109244473599,
          6.298869591080742,
          5.723674134340504,
          6.702838504729674,
          5.821239274557044,
          6.652988843365087,
          6.561619604424005,
          6.635188870045328,
          7.294373232562591,
          6.9413724307292,
          7.320583921250217,
          6.712012808796161,
          5.396299053191166,
          5.702616573080976,
          6.736397930456359,
          6.600775325242557,
          7.308952311710069,
          7.991272688264094,
          7.081668025351881,
          6.14197762215049,
          6.590212851934099,
          6.722758379008576,
          6.812032182476976,
          6.219664209255379,
          5.4047203748718395,
          4.848496330231355,
          4.774112055223649,
          6.522348894926781,
          2.268852381295686,
          5.7447052945201085,
          5.973614676251149,
          6.601865908869755
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,0,255,0.2)",
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.75166383769785,
          9.970310986409723,
          8.505819747799118,
          9.233238998239703,
          9.602230877094556,
          8.509798370676954,
          8.940094738548762,
          9.0858339117482,
          8.652017209926935,
          8.85180846023066,
          9.231344263660231,
          7.696725062696874,
          7.375970533174961,
          8.328699604476041,
          8.30558305189496,
          8.290291922886393,
          8.75748841863446,
          8.673930577186205,
          8.83482600017189,
          10.177595371290522,
          11.893626421636121,
          12.179458347385538,
          9.80756958902709,
          10.497090118954322,
          10.994335405602099,
          13.434198555107656,
          12.845283860251564,
          12.95449354097271,
          11.607714257463444,
          12.15896083390277,
          10.366093734898397,
          9.91979010788771,
          9.637782576045652,
          10.246285108789095,
          9.053428324524376,
          8.593116592305826,
          8.574776862573117,
          8.232925422371629,
          9.194597137014737,
          8.45058677071315,
          9.755822846876846,
          9.157111712327772,
          9.650574498148126,
          10.15729169116743,
          9.35104106145001,
          10.307700268307224,
          9.192090157935251,
          8.114316201969476,
          9.297465828905926,
          10.354584662879475,
          10.420128009880498,
          10.884318421364402,
          11.147145939338058,
          10.002359329902518,
          8.821115557659805,
          9.429593466837783,
          9.57793882096418,
          9.730968319395444,
          8.970960467444044,
          8.258741719786844,
          8.2681196271438,
          8.354448015025152,
          10.04945833353248,
          7.521811698550264,
          9.492342900123017,
          9.504699143787462,
          10.994439802065866
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Random Forest",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.338455936379836,
          8.420802087534714,
          8.34706007378167,
          8.236927626981654,
          8.41490911667315,
          8.384190663722798,
          8.860663537276222,
          8.624616645260955,
          8.610952524308662,
          8.695838706181274,
          8.739257871986961,
          8.008156003521437,
          7.909881237236378,
          8.026084159356747,
          8.334566632835957,
          8.431602505284845,
          8.353997631427427,
          8.314701969399756,
          8.65109505975471,
          9.120779336369207,
          9.316316989000228,
          9.556659775440757,
          8.925435520560375,
          8.81844620295022,
          8.841157490173078,
          9.412110476478674,
          9.506332536095181,
          9.401140393707927,
          9.424536358470487,
          9.58095010199978,
          9.180995521447679,
          9.191798286851437,
          9.212757735231985,
          9.253023976919058,
          8.864708763022886,
          8.261504264972627,
          8.154795837001235,
          7.971935670911726,
          8.368401173591357,
          8.407978867375032,
          8.35226776729934,
          8.432143894344192,
          8.528365279293848,
          9.16111708310743,
          8.908603301772093,
          9.164364088317601,
          8.936822351664375,
          8.31093315562585,
          8.432684675173626,
          8.407488730294752,
          8.615596270216102,
          8.853974168128996,
          9.057630567060338,
          8.86577639136807,
          8.485231165786756,
          8.971852116029021,
          9.165383527183181,
          9.172874185976198,
          8.700330551041166,
          8.31559185669055,
          8.253574630660063,
          7.993181214112257,
          8.41975854600644,
          8.393403540068185,
          8.444847968429992,
          8.483979058134732,
          8.818503091358059
         ]
        },
        {
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.103670854173254,
          8.17564969226357,
          8.084634200586937,
          7.9921379778030035,
          8.164920708602711,
          8.055061691960699,
          8.482344200554715,
          8.356961095504293,
          8.376705281153662,
          8.41704507260821,
          8.268389151670297,
          7.641117494889195,
          7.622148572701685,
          7.728977969089451,
          8.073196474897932,
          8.144224532475455,
          8.076683376287008,
          8.002517163057828,
          8.36200023160821,
          8.61352557949278,
          8.89201506146914,
          9.011715729639459,
          8.70847557173494,
          8.500282458493485,
          8.466264403914298,
          8.831624419376777,
          8.967459388669361,
          8.815808173354553,
          8.981301193802619,
          8.97485438521147,
          8.80468495037133,
          8.76506470743517,
          8.830765477598373,
          8.763032464284503,
          8.502212051642948,
          8.011271349901893,
          7.976792075394694,
          7.692359217423782,
          8.116541047694861,
          8.145862618009907,
          8.067933144123593,
          8.117694472528944,
          8.185696068745559,
          8.705368771246542,
          8.591550155156611,
          8.696482948174388,
          8.580840950838587,
          8.045566438550368,
          8.142995859436827,
          8.213953339457795,
          8.263558038601248,
          8.487811752981402,
          8.668781727740848,
          8.501215416964234,
          8.21629460211395,
          8.521394595238421,
          8.701075790184754,
          8.796270701293164,
          8.411221885737676,
          8.091509388067704,
          8.056069544740152,
          7.7357034101037625,
          8.123393542917107,
          8.140676098635032,
          8.149792873740045,
          8.225798089227133,
          8.497327136655272
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,0,0,0.2)",
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.614868427134642,
          8.670797705595445,
          8.619470160104006,
          8.522489781920385,
          8.733589196894282,
          8.781936794644434,
          9.474494421130688,
          8.949498804091236,
          8.927812402882115,
          9.0930802383782,
          9.357232213545311,
          8.388972194445914,
          8.323711787030861,
          8.390243651265738,
          8.590594655421993,
          8.74225322149884,
          8.63291298308026,
          8.64106848907744,
          9.197200917467013,
          9.734932735389346,
          10.110390407608325,
          10.348559694245271,
          9.346281105844183,
          9.16227271695929,
          9.482789479845385,
          10.125976289810136,
          10.061111747564672,
          10.100769498507816,
          9.931777128659634,
          10.153533257034567,
          9.674804117975317,
          9.5746014175394,
          9.594318505884294,
          9.745144737273439,
          9.302785022344583,
          8.630887302156928,
          8.452011018137231,
          8.338416898820805,
          8.6144410086027,
          8.679962040675921,
          8.695996260689164,
          8.823312449026211,
          8.905992852425696,
          9.524865726156799,
          9.220139074282836,
          9.827692945309522,
          9.375950648644984,
          8.623639041975952,
          8.730362528644992,
          8.580909925677801,
          8.986711607205505,
          9.292604473034956,
          9.481323952251302,
          9.165935836217802,
          8.8348212724738,
          9.430239748736751,
          9.562912216855269,
          9.558739108854954,
          9.03709929545811,
          8.62415885344866,
          8.542609421543023,
          8.340341063979498,
          8.893883111209332,
          8.705094445623061,
          8.838285093173456,
          8.751409828288853,
          9.314759942137611
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "XGBoost",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.51009181022644,
          8.556493854522705,
          8.48091329574585,
          8.639001455307007,
          8.682016496658326,
          8.655031089782716,
          8.90471004486084,
          8.869706287384034,
          8.88154501914978,
          8.868443613052369,
          8.890734710693359,
          8.410263023376466,
          8.133837385177612,
          8.246824131011962,
          8.468726263046264,
          8.517596464157105,
          8.629052257537841,
          8.669801435470582,
          8.798882923126222,
          8.989655504226684,
          9.395628213882446,
          9.611925687789917,
          9.079960403442383,
          8.948913049697875,
          8.833563680648803,
          8.955200300216674,
          9.210959606170654,
          9.177091369628906,
          9.22102144241333,
          9.492057781219483,
          9.260351142883302,
          9.152506885528565,
          9.171034774780274,
          9.173617181777955,
          8.92913953781128,
          8.669212713241578,
          8.504840030670167,
          8.298788328170776,
          8.710072355270386,
          8.569912900924683,
          8.69852620124817,
          8.690999670028686,
          8.76044472694397,
          9.194148988723756,
          9.026212224960327,
          9.306707105636598,
          9.003109302520752,
          8.618527164459229,
          8.569658393859862,
          8.613392467498779,
          8.869762697219848,
          8.924211940765382,
          9.024870977401733,
          8.952750387191772,
          8.85279341697693,
          9.026636571884156,
          9.112957057952881,
          9.130798988342285,
          8.906969242095947,
          8.674830932617187,
          8.526713008880614,
          8.328869829177856,
          8.705175867080689,
          8.476249294281006,
          8.656916828155518,
          8.768103771209717,
          9.082907886505128
         ]
        },
        {
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.298947024345399,
          8.38272421360016,
          8.297382569313049,
          8.468854546546936,
          8.531680679321289,
          8.532068943977356,
          8.748217701911926,
          8.715373086929322,
          8.693586277961732,
          8.67140564918518,
          8.648934864997864,
          8.246762895584107,
          7.950655460357666,
          8.065523028373718,
          8.269354581832886,
          8.342472362518311,
          8.475829482078552,
          8.535779643058778,
          8.643379187583923,
          8.67864124774933,
          9.073553109169007,
          9.308411049842835,
          8.857663083076478,
          8.739167833328247,
          8.601796126365661,
          8.653597450256347,
          8.937212252616883,
          8.96195924282074,
          9.00735001564026,
          9.249823570251465,
          9.03899700641632,
          8.935644912719727,
          8.932942628860474,
          8.897107124328613,
          8.694844341278076,
          8.47767369747162,
          8.330163931846618,
          8.107128643989563,
          8.524341988563538,
          8.390673303604126,
          8.535522389411927,
          8.53505356311798,
          8.577290225028992,
          8.912455892562866,
          8.806172585487365,
          8.963512778282166,
          8.74856939315796,
          8.430021834373473,
          8.374104142189026,
          8.416798377037049,
          8.683194565773011,
          8.713853240013123,
          8.79421226978302,
          8.785112023353577,
          8.69366488456726,
          8.817256355285645,
          8.86110212802887,
          8.85652940273285,
          8.67286274433136,
          8.464136433601379,
          8.333348274230957,
          8.131115794181824,
          8.497295761108399,
          8.288594269752503,
          8.479870772361755,
          8.598932123184204,
          8.872095537185668
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,255,0,0.2)",
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.72899739742279,
          8.801268577575684,
          8.694376158714295,
          8.809723258018494,
          8.853659343719482,
          8.817164778709412,
          9.10776662826538,
          9.06086232662201,
          9.082131600379943,
          9.078700351715087,
          9.11681969165802,
          8.587037992477416,
          8.37561147212982,
          8.495723700523376,
          8.689450025558472,
          8.726434564590454,
          8.797741317749024,
          8.828934979438781,
          8.995861673355103,
          9.214899778366089,
          9.815205311775207,
          10.085002064704895,
          9.313998484611512,
          9.159076404571532,
          9.09113643169403,
          9.2554461479187,
          9.48282594680786,
          9.414325094223022,
          9.439833879470825,
          9.787713170051575,
          9.514723706245421,
          9.41398229598999,
          9.456001448631287,
          9.487193584442139,
          9.168798422813415,
          8.880005359649658,
          8.711607146263123,
          8.540050935745239,
          8.906762933731079,
          8.787988829612733,
          8.896761417388916,
          8.870535373687744,
          8.982954287528992,
          9.475592708587646,
          9.280538868904113,
          9.66460018157959,
          9.263484668731689,
          8.825794410705566,
          8.807896709442138,
          8.901664423942565,
          9.081504774093627,
          9.14581847190857,
          9.239498376846313,
          9.172647380828858,
          9.05266993045807,
          9.278289866447448,
          9.404830646514892,
          9.435951280593873,
          9.158360457420349,
          8.871666955947877,
          8.741754364967345,
          8.592013192176818,
          8.915679740905762,
          8.733442640304565,
          8.856874632835389,
          8.962468576431274,
          9.354354977607727
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines",
         "name": "LightGBM",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          7.952187106934478,
          8.100409414380788,
          7.834902256736428,
          7.746181422857514,
          7.950034054296707,
          7.997400240335061,
          8.682800720913864,
          8.186938638067765,
          8.192217014515435,
          8.370442828235795,
          8.54970086407421,
          7.687783367122774,
          7.602165577728354,
          7.605746492344796,
          7.742166718079073,
          7.815090960874772,
          7.759135142512703,
          7.741711405114999,
          8.223308803057648,
          8.388121483892254,
          8.721234136490407,
          9.285369832891709,
          8.33169464252853,
          8.160654046497136,
          8.22361369196184,
          8.822216232947326,
          8.691337783565045,
          8.603401647338508,
          8.678742910520182,
          8.86294787154941,
          8.525617579968158,
          8.59363216899093,
          8.468524164907627,
          8.641884818254578,
          8.327680917865557,
          7.547407507547491,
          7.362475166098924,
          7.330270376852431,
          7.652859872484439,
          7.560298592227317,
          7.425402109060038,
          7.585411373871129,
          7.8032211979844215,
          8.18607035041155,
          8.191461726450608,
          8.149387442606146,
          8.138951076008215,
          7.2560874177876995,
          7.560746152179052,
          7.472990477799333,
          7.7001507870373045,
          7.793204128979355,
          8.098785919030586,
          7.6911953785268805,
          7.503264449100117,
          8.181176925193194,
          8.219460737060178,
          8.138563409895989,
          7.585234142058913,
          7.151982574819434,
          7.204455147919789,
          6.940426328821779,
          7.391917316602144,
          7.228113158790462,
          7.29527067642665,
          7.177946237055294,
          7.633388570404638
         ]
        },
        {
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          7.2671240224719105,
          7.396823693086078,
          7.0313014588835125,
          6.961605242810746,
          6.951391996835955,
          7.281146036143138,
          7.795647597933957,
          7.294668399598178,
          7.265866005372758,
          7.531321675194421,
          7.569849353169086,
          6.518864024512714,
          6.696899481283737,
          6.625721386114092,
          6.781862220258958,
          6.917704598339971,
          6.897504438555861,
          6.768738462889656,
          7.079119971223254,
          7.100627752452589,
          6.9891904921912955,
          7.725188864540551,
          7.142506225869188,
          6.729562742254633,
          7.12956882243269,
          7.479869940509039,
          7.230266758331918,
          7.341519272205604,
          7.352312153516759,
          7.477451450586415,
          7.0730701180348134,
          7.450780486519014,
          7.368888738040027,
          7.357630240716832,
          7.016094268559827,
          6.1338347497168915,
          6.177394714399844,
          5.937558907074746,
          6.108041822962731,
          5.966907725144996,
          5.977245050747756,
          6.128812510764329,
          6.138516868978377,
          6.993263352119417,
          6.60455873860474,
          6.738790692074517,
          6.788755380450291,
          5.485745435800254,
          6.198749357608364,
          6.010906208651249,
          5.50693619530977,
          5.733119929704194,
          6.107956869741674,
          5.680961513579985,
          5.7293387552675465,
          6.505760931524688,
          6.666462244035673,
          6.5493318763281145,
          5.614258065435249,
          5.232247638668135,
          5.406077239889943,
          4.9726735889617375,
          5.663876819947749,
          4.732090056707181,
          5.173744531389619,
          5.1635876028038625,
          5.870803046796804
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(128,0,128,0.2)",
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.924701501431157,
          8.842441771143958,
          8.624569031608912,
          8.587826807229893,
          8.750786782816453,
          8.788504344801252,
          9.670421648326641,
          9.03157187528306,
          8.988530077348996,
          9.451765876198454,
          9.608948325023531,
          8.696270722349453,
          8.48767468815034,
          8.255978798276981,
          8.81782860781042,
          8.761557835641272,
          8.796241120342005,
          8.673575564877531,
          9.220588611017115,
          9.62402147622191,
          10.29758837103367,
          10.996594299278177,
          9.647966858360697,
          9.708386517603792,
          9.386886526521463,
          10.320359202191177,
          10.215786884292934,
          10.226434148411906,
          10.191891606224614,
          10.165360887110182,
          10.293399081813781,
          9.824084916452984,
          9.767400768902444,
          9.933154465395441,
          9.49338317355286,
          8.829409059650288,
          8.461743157409654,
          8.36900089793906,
          9.176017349835996,
          8.802266946427322,
          8.570608173288106,
          9.163191484393545,
          9.04638894670437,
          9.723585984907965,
          9.448893049227411,
          9.91783420451279,
          9.757197346245315,
          8.72585017436458,
          8.584869565618744,
          8.661045948572122,
          9.858205638666243,
          9.995430069382028,
          10.203080919850358,
          9.48391591407729,
          8.893892844622624,
          9.617003314007341,
          9.780257014818048,
          9.703761035363987,
          9.247124840170832,
          8.659010818205745,
          8.565540186782414,
          8.208019427366873,
          8.98686165732232,
          8.927768217097093,
          8.86350424467004,
          8.628035593518717,
          9.514902646736706
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Neural Network",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.741672809336148,
          8.858840891638923,
          7.943047821538361,
          8.416070929166056,
          8.614466160491693,
          8.604305830008924,
          8.914556237239378,
          8.996077868324946,
          9.008257076410393,
          9.008674336280084,
          8.95928827912207,
          8.522508152669651,
          7.898532775211173,
          8.165017368647609,
          7.798186507084458,
          7.989519825758179,
          8.459364758572901,
          8.63780878016847,
          8.753909701696381,
          8.691284276926346,
          9.601285211282619,
          9.820291658468204,
          9.47938965617004,
          9.372255011677883,
          9.315739488387077,
          9.30309458682418,
          9.428241490033251,
          9.410277083278588,
          9.584048693167475,
          9.834558874494315,
          9.530773370456808,
          9.299970086741148,
          9.30703099706164,
          9.299721967317767,
          9.105396991222849,
          8.90349291530953,
          8.726931174935753,
          8.461903572354055,
          8.597051314564455,
          8.259719428595458,
          8.692009310437857,
          8.7095628014429,
          8.756784286597872,
          9.198953360123044,
          9.291259901025773,
          9.333464306310459,
          9.253414312206,
          8.94594561777289,
          8.761491037829868,
          8.873970142972363,
          8.989990264915582,
          9.190150776075532,
          9.350003968437193,
          9.21229461711261,
          9.035512095488382,
          9.153207142946437,
          9.253948388575145,
          9.311250087310805,
          9.226098333561175,
          9.036491008600438,
          8.721366994836535,
          8.431222815789017,
          8.590115956401027,
          7.930702858439863,
          8.38511958721288,
          8.834554726804617,
          9.291688487154975
         ]
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.58538395060214,
          8.688570416748094,
          7.648050455593322,
          8.154021705880172,
          8.361812517487023,
          8.438311519051524,
          8.75274006362436,
          8.839710262943871,
          8.824255536663914,
          8.819259910053269,
          8.712097268758168,
          8.341503463080898,
          7.670861687034738,
          7.964800526246277,
          7.459479569097991,
          7.679442845325983,
          8.219012464509996,
          8.460187547909648,
          8.591663951316365,
          8.446624371902987,
          9.414799842317995,
          9.633583236366531,
          9.326961730839443,
          9.214816689729574,
          9.120629857122706,
          9.063887525085883,
          9.10340074214787,
          9.080078790167908,
          9.39070346284594,
          9.636942644787329,
          9.349519245236715,
          9.105434074455749,
          9.096204239276625,
          9.064301348202369,
          8.888228828818312,
          8.720925174424352,
          8.567804155611672,
          8.262028372303273,
          8.314615479752716,
          7.9619528037201786,
          8.46666072956984,
          8.53056290115996,
          8.58299275356716,
          8.976970289962322,
          9.11722251078803,
          9.063449010136786,
          9.052616111801607,
          8.777916081118924,
          8.574052054422612,
          8.677147356436048,
          8.759804600051158,
          8.950442056162561,
          9.12374054644474,
          9.032112495400629,
          8.869150674783635,
          8.971577475364265,
          9.047038583080298,
          9.089578872371726,
          9.056047835388691,
          8.879539815959545,
          8.551443562660344,
          8.234842806308862,
          8.303092552819441,
          7.606887702214942,
          8.107691008764826,
          8.627602006949937,
          9.120724828441594
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,165,0,0.2)",
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00"
         ],
         "y": [
          8.928738850179073,
          9.04737922916184,
          8.26297555710453,
          8.651818489202745,
          8.820566442099356,
          8.769839619344472,
          9.08388890600077,
          9.187361611173237,
          9.213559152902146,
          9.2126764499048,
          9.172146540087246,
          8.721140302536273,
          8.138884898097968,
          8.405671863237618,
          8.128883899419504,
          8.261388299452218,
          8.664791915479565,
          8.799621934167673,
          8.93335836907811,
          8.956837377896237,
          9.85327113703102,
          10.079442950485765,
          9.67522380899093,
          9.553834437533835,
          9.488600055637084,
          9.51074230178357,
          9.7568369506193,
          9.687620387223737,
          9.766942093104511,
          10.009814669018441,
          9.724440551926165,
          9.502870790564913,
          9.537379860646787,
          9.525404146671983,
          9.323932895279167,
          9.119539569990446,
          8.919669107923037,
          8.681565137164903,
          8.832783381826612,
          8.541062773663027,
          8.897634323197417,
          8.89607158383703,
          8.962131623018369,
          9.443849600767926,
          9.505419023505164,
          9.599374223224237,
          9.484374829328262,
          9.154570322973052,
          8.951498886276754,
          9.081411538237452,
          9.205565154735659,
          9.415254725497567,
          9.52831669889818,
          9.397728090961055,
          9.203783219806098,
          9.351029558486623,
          9.482347015618414,
          9.550886438469856,
          9.457456727435343,
          9.246973885495075,
          8.918069633810022,
          8.632380525627982,
          8.832688832999082,
          8.264055283509,
          8.627655707352684,
          9.010576104763294,
          9.470574210297311
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "DOC (mg/l) - Station 305"
        },
        "xaxis": {
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "title": {
          "text": "DOC (mg/l)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Station 325 ===\n",
      "Linear Regression RMSE: 2.910769905701122\n",
      "Random Forest RMSE: 1.0530980061718223\n",
      "XGBoost RMSE: 0.8139665796807232\n",
      "LightGBM RMSE: 0.8469181798027792\n",
      "Neural Network RMSE: 1.3088656665016887\n",
      "\n",
      "Linear Regression R2: -13.274895017920912\n",
      "Random Forest R2: -0.809443026076218\n",
      "XGBoost R2: -0.10700649646879934\n",
      "LightGBM R2: -0.03542972119791754\n",
      "Neural Network R2: -1.8444077848201084\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "black"
         },
         "mode": "lines",
         "name": "True",
         "type": "scatter",
         "x": [
          "1986-11-30T00:00:00",
          "1986-12-31T00:00:00",
          "1987-01-31T00:00:00",
          "1987-02-28T00:00:00",
          "1987-03-31T00:00:00",
          "1987-04-30T00:00:00",
          "1987-05-31T00:00:00",
          "1987-06-30T00:00:00",
          "1987-07-31T00:00:00",
          "1987-08-31T00:00:00",
          "1987-09-30T00:00:00",
          "1987-10-31T00:00:00",
          "1987-11-30T00:00:00",
          "1987-12-31T00:00:00",
          "1988-01-31T00:00:00",
          "1988-02-29T00:00:00",
          "1988-03-31T00:00:00",
          "1988-04-30T00:00:00",
          "1988-05-31T00:00:00",
          "1988-06-30T00:00:00",
          "1988-07-31T00:00:00",
          "1988-08-31T00:00:00",
          "1988-09-30T00:00:00",
          "1988-10-31T00:00:00",
          "1988-11-30T00:00:00",
          "1988-12-31T00:00:00",
          "1989-01-31T00:00:00",
          "1989-02-28T00:00:00",
          "1989-03-31T00:00:00",
          "1989-04-30T00:00:00",
          "1989-05-31T00:00:00",
          "1989-06-30T00:00:00",
          "1989-07-31T00:00:00",
          "1989-08-31T00:00:00",
          "1989-09-30T00:00:00",
          "1989-10-31T00:00:00",
          "1989-11-30T00:00:00",
          "1989-12-31T00:00:00",
          "1990-01-31T00:00:00",
          "1990-02-28T00:00:00",
          "1990-03-31T00:00:00",
          "1990-04-30T00:00:00",
          "1990-05-31T00:00:00",
          "1990-06-30T00:00:00",
          "1990-07-31T00:00:00",
          "1990-08-31T00:00:00",
          "1990-09-30T00:00:00",
          "1990-10-31T00:00:00",
          "1990-11-30T00:00:00",
          "1990-12-31T00:00:00",
          "1991-01-31T00:00:00",
          "1991-02-28T00:00:00",
          "1991-03-31T00:00:00",
          "1991-04-30T00:00:00",
          "1991-05-31T00:00:00",
          "1991-06-30T00:00:00",
          "1991-07-31T00:00:00",
          "1991-08-31T00:00:00",
          "1991-09-30T00:00:00",
          "1991-10-31T00:00:00",
          "1991-11-30T00:00:00",
          "1991-12-31T00:00:00",
          "1992-01-31T00:00:00",
          "1992-02-29T00:00:00",
          "1992-03-31T00:00:00",
          "1992-04-30T00:00:00",
          "1992-05-31T00:00:00",
          "1992-06-30T00:00:00",
          "1992-07-31T00:00:00",
          "1992-08-31T00:00:00",
          "1992-09-30T00:00:00",
          "1992-10-31T00:00:00",
          "1992-11-30T00:00:00",
          "1992-12-31T00:00:00",
          "1993-01-31T00:00:00",
          "1993-02-28T00:00:00",
          "1993-03-31T00:00:00",
          "1993-04-30T00:00:00",
          "1993-05-31T00:00:00",
          "1993-06-30T00:00:00",
          "1993-07-31T00:00:00",
          "1993-08-31T00:00:00",
          "1993-09-30T00:00:00",
          "1993-10-31T00:00:00",
          "1993-11-30T00:00:00",
          "1993-12-31T00:00:00",
          "1994-01-31T00:00:00",
          "1994-02-28T00:00:00",
          "1994-03-31T00:00:00",
          "1994-04-30T00:00:00",
          "1994-05-31T00:00:00",
          "1994-06-30T00:00:00",
          "1994-07-31T00:00:00",
          "1994-08-31T00:00:00",
          "1994-09-30T00:00:00",
          "1994-10-31T00:00:00",
          "1994-11-30T00:00:00",
          "1994-12-31T00:00:00",
          "1995-01-31T00:00:00",
          "1995-02-28T00:00:00",
          "1995-03-31T00:00:00",
          "1995-04-30T00:00:00",
          "1995-05-31T00:00:00",
          "1995-06-30T00:00:00",
          "1995-07-31T00:00:00",
          "1995-08-31T00:00:00",
          "1995-09-30T00:00:00",
          "1995-10-31T00:00:00",
          "1995-11-30T00:00:00",
          "1995-12-31T00:00:00",
          "1996-01-31T00:00:00",
          "1996-02-29T00:00:00",
          "1996-03-31T00:00:00",
          "1996-04-30T00:00:00",
          "1996-05-31T00:00:00",
          "1996-06-30T00:00:00",
          "1996-07-31T00:00:00",
          "1996-08-31T00:00:00",
          "1996-09-30T00:00:00",
          "1996-10-31T00:00:00",
          "1996-11-30T00:00:00",
          "1996-12-31T00:00:00",
          "1997-01-31T00:00:00",
          "1997-02-28T00:00:00",
          "1997-03-31T00:00:00",
          "1997-04-30T00:00:00",
          "1997-05-31T00:00:00",
          "1997-06-30T00:00:00",
          "1997-07-31T00:00:00",
          "1997-08-31T00:00:00",
          "1997-09-30T00:00:00",
          "1997-10-31T00:00:00",
          "1997-11-30T00:00:00",
          "1997-12-31T00:00:00",
          "1998-01-31T00:00:00",
          "1998-02-28T00:00:00",
          "1998-03-31T00:00:00",
          "1998-04-30T00:00:00",
          "1998-05-31T00:00:00",
          "1998-06-30T00:00:00",
          "1998-07-31T00:00:00",
          "1998-08-31T00:00:00",
          "1998-09-30T00:00:00",
          "1998-10-31T00:00:00",
          "1998-11-30T00:00:00",
          "1998-12-31T00:00:00",
          "1999-01-31T00:00:00",
          "1999-02-28T00:00:00",
          "1999-03-31T00:00:00",
          "1999-04-30T00:00:00",
          "1999-05-31T00:00:00",
          "1999-06-30T00:00:00",
          "1999-07-31T00:00:00",
          "1999-08-31T00:00:00",
          "1999-09-30T00:00:00",
          "1999-10-31T00:00:00",
          "1999-11-30T00:00:00",
          "1999-12-31T00:00:00",
          "2000-01-31T00:00:00",
          "2000-02-29T00:00:00",
          "2000-03-31T00:00:00",
          "2000-04-30T00:00:00",
          "2000-05-31T00:00:00",
          "2000-06-30T00:00:00",
          "2000-07-31T00:00:00",
          "2000-08-31T00:00:00",
          "2000-09-30T00:00:00",
          "2000-10-31T00:00:00",
          "2000-11-30T00:00:00",
          "2000-12-31T00:00:00",
          "2001-01-31T00:00:00",
          "2001-02-28T00:00:00",
          "2001-03-31T00:00:00",
          "2001-04-30T00:00:00",
          "2001-05-31T00:00:00",
          "2001-06-30T00:00:00",
          "2001-07-31T00:00:00",
          "2001-08-31T00:00:00",
          "2001-09-30T00:00:00",
          "2001-10-31T00:00:00",
          "2001-11-30T00:00:00",
          "2001-12-31T00:00:00",
          "2002-01-31T00:00:00",
          "2002-02-28T00:00:00",
          "2002-03-31T00:00:00",
          "2002-04-30T00:00:00",
          "2002-05-31T00:00:00",
          "2002-06-30T00:00:00",
          "2002-07-31T00:00:00",
          "2002-08-31T00:00:00",
          "2002-09-30T00:00:00",
          "2002-10-31T00:00:00",
          "2002-11-30T00:00:00",
          "2002-12-31T00:00:00",
          "2003-01-31T00:00:00",
          "2003-02-28T00:00:00",
          "2003-03-31T00:00:00",
          "2003-04-30T00:00:00",
          "2003-05-31T00:00:00",
          "2003-06-30T00:00:00",
          "2003-07-31T00:00:00",
          "2003-08-31T00:00:00",
          "2003-09-30T00:00:00",
          "2003-10-31T00:00:00",
          "2003-11-30T00:00:00",
          "2003-12-31T00:00:00",
          "2004-01-31T00:00:00",
          "2004-02-29T00:00:00",
          "2004-03-31T00:00:00",
          "2004-04-30T00:00:00",
          "2004-05-31T00:00:00",
          "2004-06-30T00:00:00",
          "2004-07-31T00:00:00",
          "2004-08-31T00:00:00",
          "2004-09-30T00:00:00",
          "2004-10-31T00:00:00",
          "2004-11-30T00:00:00",
          "2004-12-31T00:00:00",
          "2005-01-31T00:00:00",
          "2005-02-28T00:00:00",
          "2005-03-31T00:00:00",
          "2005-04-30T00:00:00",
          "2005-05-31T00:00:00",
          "2005-06-30T00:00:00",
          "2005-07-31T00:00:00",
          "2005-08-31T00:00:00",
          "2005-09-30T00:00:00",
          "2005-10-31T00:00:00",
          "2005-11-30T00:00:00",
          "2005-12-31T00:00:00",
          "2006-01-31T00:00:00",
          "2006-02-28T00:00:00",
          "2006-03-31T00:00:00",
          "2006-04-30T00:00:00",
          "2006-05-31T00:00:00",
          "2006-06-30T00:00:00",
          "2006-07-31T00:00:00",
          "2006-08-31T00:00:00",
          "2006-09-30T00:00:00",
          "2006-10-31T00:00:00",
          "2006-11-30T00:00:00",
          "2006-12-31T00:00:00",
          "2007-01-31T00:00:00",
          "2007-02-28T00:00:00",
          "2007-03-31T00:00:00",
          "2007-04-30T00:00:00",
          "2007-05-31T00:00:00",
          "2007-06-30T00:00:00",
          "2007-07-31T00:00:00",
          "2007-08-31T00:00:00",
          "2007-09-30T00:00:00",
          "2007-10-31T00:00:00",
          "2007-11-30T00:00:00",
          "2007-12-31T00:00:00",
          "2008-01-31T00:00:00",
          "2008-02-29T00:00:00",
          "2008-03-31T00:00:00",
          "2008-04-30T00:00:00",
          "2008-05-31T00:00:00",
          "2008-06-30T00:00:00",
          "2008-07-31T00:00:00",
          "2008-08-31T00:00:00",
          "2008-09-30T00:00:00",
          "2008-10-31T00:00:00",
          "2008-11-30T00:00:00",
          "2008-12-31T00:00:00",
          "2009-01-31T00:00:00",
          "2009-02-28T00:00:00",
          "2009-03-31T00:00:00",
          "2009-04-30T00:00:00",
          "2009-05-31T00:00:00",
          "2009-06-30T00:00:00",
          "2009-07-31T00:00:00",
          "2009-08-31T00:00:00",
          "2009-09-30T00:00:00",
          "2009-10-31T00:00:00",
          "2009-11-30T00:00:00",
          "2009-12-31T00:00:00",
          "2010-01-31T00:00:00",
          "2010-02-28T00:00:00",
          "2010-03-31T00:00:00",
          "2010-04-30T00:00:00",
          "2010-05-31T00:00:00",
          "2010-06-30T00:00:00",
          "2010-07-31T00:00:00",
          "2010-08-31T00:00:00",
          "2010-09-30T00:00:00",
          "2010-10-31T00:00:00",
          "2010-11-30T00:00:00",
          "2010-12-31T00:00:00",
          "2011-01-31T00:00:00",
          "2011-02-28T00:00:00",
          "2011-03-31T00:00:00",
          "2011-04-30T00:00:00",
          "2011-05-31T00:00:00",
          "2011-06-30T00:00:00",
          "2011-07-31T00:00:00",
          "2011-08-31T00:00:00",
          "2011-09-30T00:00:00",
          "2011-10-31T00:00:00",
          "2011-11-30T00:00:00",
          "2011-12-31T00:00:00",
          "2012-01-31T00:00:00",
          "2012-02-29T00:00:00",
          "2012-03-31T00:00:00",
          "2012-04-30T00:00:00",
          "2012-05-31T00:00:00",
          "2012-06-30T00:00:00",
          "2012-07-31T00:00:00",
          "2012-08-31T00:00:00",
          "2012-09-30T00:00:00",
          "2012-10-31T00:00:00",
          "2012-11-30T00:00:00",
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          8.3,
          9.5,
          9.241666666666667,
          9.008333333333333,
          8.75,
          8.5,
          6.6,
          8,
          10,
          6.7,
          8.1,
          6.4,
          5.8,
          7.5,
          5.2,
          8.8,
          6.6,
          6.8,
          8.2,
          7.4,
          7.2,
          9.5,
          10,
          8.3,
          7,
          6.2,
          6.1,
          4.9,
          6.4,
          6.2,
          8,
          9.3,
          8.5,
          8.5,
          10,
          9.1,
          8.3,
          8,
          6.3,
          6.1,
          7.1,
          7.1,
          9,
          7.7,
          8,
          8,
          8.7,
          6.1,
          5.608196721311475,
          5.1,
          5.9,
          6.371910112359551,
          6.894382022471911,
          7.4,
          6.8,
          5,
          8,
          8.5,
          8.6,
          9,
          7.2,
          6.689010989010989,
          6.178021978021978,
          5.7,
          6.9,
          8.4,
          8,
          8.5,
          6.7,
          8.2,
          7.4,
          6.6,
          6.1,
          5.5,
          5.972881355932204,
          6.4,
          4.8,
          5.1,
          7.2,
          6.9,
          7.4,
          7.120491803278688,
          6.85,
          6.6,
          6,
          6.2,
          6.8,
          6.705084745762711,
          6.6,
          7.7,
          7.75,
          7.1,
          7.7,
          7.9,
          7.3,
          6.6,
          5.6,
          5.7,
          8.6,
          6,
          7.6,
          8.2,
          7.5,
          7.8,
          7.5,
          7.3,
          6.9,
          6.3,
          6.7,
          6.7,
          6.7,
          6.281111111111112,
          5.833333333333334,
          5.4,
          5.1,
          8.1,
          6.5,
          5.7,
          6.7,
          6.6,
          6.8,
          6.9,
          6.8,
          6.5,
          7.6,
          5.6,
          6.5,
          6.6,
          6.8,
          7.7,
          6.1,
          6.4,
          6.8,
          6.4,
          6.6,
          7.2,
          6.6,
          7.1,
          6.4,
          6.2,
          6,
          7.5,
          5.4,
          5.6,
          6.1,
          7.5,
          6.6,
          5.9,
          6.8,
          7.51311475409836,
          8.25,
          8,
          7.2,
          7.7,
          8.8,
          7.7,
          7.6,
          7.2,
          6.8,
          7.1,
          7.2,
          6.5,
          8.05,
          8.6,
          7.949999999999999,
          7.3,
          6.8,
          7.8,
          8.3,
          9.4,
          7.4,
          6.7,
          8,
          6.4,
          7.699999999999999,
          8.3,
          8.3,
          7.4,
          7.5,
          7.6,
          7.6,
          8.4,
          7.7,
          7.2,
          8.1,
          8.2,
          8,
          7.45,
          7.8,
          8.2,
          9.8,
          7.2,
          7.6,
          7.7,
          6.9,
          7.1,
          7,
          7.4,
          7.5,
          7.55,
          8.8,
          8.6,
          9.5,
          9.2,
          8.4,
          6.7,
          8.2,
          8.6,
          7.7,
          7.6,
          7.8,
          7.300000000000001,
          7,
          6.8,
          7.1,
          7.1,
          6.8,
          6.7,
          7,
          7.8,
          7.8,
          7.1,
          7.9,
          8,
          7.1,
          7.4,
          7.3,
          7.9,
          7,
          6.9,
          7.3,
          7.4,
          7.4,
          7.550000000000001,
          7.8,
          7.8,
          8.4,
          8.2,
          8.2,
          8.4,
          7.4,
          7.5,
          6.2,
          6.8,
          7.5,
          7.7,
          7.7,
          7.7,
          8.7,
          7.4,
          8.6,
          7.9,
          6.9,
          8.2,
          8,
          8.2,
          9.3,
          8.2,
          9.8,
          8.2,
          9.7,
          9.2,
          8.7,
          7.8,
          7.1,
          7.8,
          7.2,
          7.4,
          7.1,
          8.1,
          7.7,
          7.3,
          7.4,
          7.6,
          8.1,
          7.6,
          8.1,
          7.8,
          7.8,
          7.8,
          7.8,
          8.5,
          8.3,
          8.3,
          8.2,
          7.4,
          9,
          11.2,
          9.7,
          9.75,
          9.8,
          9.6,
          8.7,
          8.2,
          8.65,
          7.85,
          8.1,
          9.6,
          9.6,
          8.95,
          8.4,
          7.1,
          7.9,
          9.2,
          7.9,
          8.1,
          9.7,
          8.1,
          7.9,
          8.7,
          8.2,
          8.2,
          7.3,
          7.4,
          6,
          7.9,
          7.5,
          8.8,
          7.9,
          8.4,
          9.2,
          8.7,
          7.8,
          6.7,
          7.1,
          7.7,
          6.7,
          8.4,
          7.2,
          7.3,
          7.2,
          7.6,
          7,
          7.6,
          7.7,
          6.8,
          7,
          7.5,
          6.6,
          7.4,
          7.2,
          6.6,
          6.9,
          6.7,
          6.9,
          7.9,
          6.7,
          7.5,
          6.8,
          6.5,
          6.7,
          7.4,
          6.6,
          6.9,
          8.2,
          7.3,
          7.7,
          7.1,
          7,
          7,
          6.5,
          6.2,
          6.6,
          7.4,
          7.1,
          7.4,
          7,
          6.9,
          7.9,
          8.7,
          8.4,
          7.5,
          7.6,
          7.5,
          7.8,
          8.4,
          7.6,
          7.845901639344262,
          8.100000000000001,
          7.6,
          7.8,
          9,
          8.1,
          9.4,
          8.6,
          6.1,
          6.1,
          7.9,
          7.2,
          8.1,
          7.9,
          7.6,
          8,
          7,
          5.8,
          6.409836065573771,
          7,
          4.7,
          7.4,
          6.6,
          7.3,
          7.472131147540983,
          7.65,
          7.822131147540984,
          8,
          7.6,
          7.8,
          8.8,
          7.5,
          7,
          5.8,
          5.4,
          7.6,
          6.5,
          6.7,
          7.4,
          7.6,
          7.15,
          7.420491803278689,
          7.7,
          6.7,
          7,
          6.7,
          6.2,
          7.75,
          7.2,
          7.2,
          7.4,
          7.7,
          9.4,
          7.5,
          7.398360655737704,
          7.3,
          7.05,
          6.8,
          7.2,
          7.2,
          7.322950819672131,
          7.449999999999999,
          7.327049180327869,
          7.2,
          7.45,
          7.5,
          7.5,
          6.8,
          7.85,
          8.9,
          9.6
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Linear Regression",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          8.62189019541815,
          8.54235954793475,
          9.708049152919674,
          9.585485184101348,
          9.238487184177925,
          8.259975807292392,
          8.878964341074994,
          9.120641655000865,
          8.750871355836503,
          8.398795741290611,
          8.536594653012802,
          8.885289303710552,
          9.011552325962237,
          9.170397618433254,
          9.377920078941838,
          8.844977116644845,
          9.025189380553867,
          8.46378082831603,
          8.856259973362654,
          8.531038837844276,
          8.9947081574003,
          9.284150644914712,
          8.98924453941029,
          9.171274831268656,
          9.09926659149703,
          8.895081425039706,
          9.422925404286934,
          9.278156802642718,
          8.8467667109293,
          9.060655804253845,
          8.178937338582664,
          8.43777164697627,
          9.330546374093533,
          9.243931540472094,
          8.650716423587303,
          9.090784607437662,
          9.37367349126104,
          9.395002770803112,
          9.488328707115437,
          9.600511099337215,
          9.170729748872546,
          8.853511539375587,
          8.75916690445353,
          8.951648713486033,
          9.133795206948474,
          9.825907295306848,
          9.334164009546956,
          9.636052043043561,
          9.12885212456436,
          9.572365915338235,
          9.128111096951828,
          8.728192734644477,
          9.254021533274729,
          9.546056693672506,
          9.665160347004052,
          9.385212611678606,
          9.855847618923288,
          10.182505565758131,
          9.593932485672248,
          10.272960133622448,
          10.231048855126353,
          10.499052128924477,
          10.592675242343502,
          9.666941063260104,
          9.353821898606329,
          10.23236410949631,
          10.185234403975372,
          9.680870700754303,
          10.414184214361407,
          9.985145752607,
          9.799069300710109,
          9.681321260968243,
          9.719810883713878,
          10.011437272257409,
          10.260695336227222,
          10.232841902460475,
          10.948973566647346,
          11.122572715291515,
          10.218005630721704,
          11.075560198170889,
          10.86991150094328,
          10.255538874706211,
          10.183188150970436,
          10.038414122339113,
          10.51979045327853,
          11.016786006562816,
          10.591383124408155,
          10.780006092567366,
          10.412323317892715,
          10.035721659897838,
          9.952149676469832,
          9.9462280975363,
          11.429825410849942,
          10.475048436260565,
          10.130086439841563,
          10.579909096962913,
          10.596933103211716,
          10.875030741114896,
          10.479730484635411,
          10.037254804097719,
          10.047520828371976,
          10.898045648445118,
          11.322640154985582,
          11.951616740015655,
          10.76992111670008,
          11.083683624679365,
          10.936470374465578,
          10.548634036698104,
          11.960667805616328,
          11.487237233486516,
          11.623869369795916,
          11.397857384225775,
          11.033777123189637,
          10.59913702599362,
          10.739488947458842,
          10.997612769246725,
          10.36301249570956,
          10.839646440018685,
          10.84195991673357,
          11.108978367225657,
          10.975945004452214,
          11.29688942221941,
          11.327378985754962,
          11.004602533669825,
          11.119748306460485,
          11.525010317670391,
          10.561012139487149,
          10.838469898111649,
          10.937897141270192,
          11.86900852778595,
          11.030528108093801,
          11.762425701695546,
          11.693377192162677,
          13.599967974822432,
          12.943883987209777
         ]
        },
        {
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.5354214946724625,
          7.77534501933384,
          8.297146064417358,
          8.797739045018002,
          8.634800497415972,
          7.588112182233801,
          7.973911933227761,
          8.541045093800186,
          8.096711297479153,
          7.789545251579098,
          7.9833130959322425,
          8.28826421597744,
          8.367346512596955,
          8.518920004356369,
          8.526905632542007,
          8.152171445819645,
          8.406216991654292,
          7.856352446279466,
          8.22103704070582,
          7.895921233579541,
          8.159008982730779,
          8.643356655838035,
          8.365506380103604,
          8.426977950383638,
          8.19303859773286,
          8.060866224340657,
          8.618390538238247,
          8.491158736143714,
          8.064917591349257,
          8.191932226002175,
          7.405274012506096,
          7.761437801903156,
          8.528865721454803,
          8.550194184160416,
          7.69152883343964,
          8.080853699909866,
          8.367679690893947,
          7.797373451254554,
          8.608332499394338,
          8.468840667943036,
          8.348311337317602,
          8.135163581726596,
          8.001324841615586,
          8.260356761534949,
          8.408887703668908,
          8.809077264029856,
          8.567731773989888,
          8.72777397675922,
          8.248118724087883,
          8.491768231695008,
          7.995212679648658,
          7.845236833808778,
          8.476606995017553,
          8.73042423536346,
          7.747108877556099,
          8.314536682046855,
          8.781637214214628,
          9.437075418236914,
          8.772884842483672,
          9.197063388905029,
          9.182861528841174,
          9.441721643582339,
          9.603210973779737,
          8.665932200284274,
          8.484440747530309,
          9.20852331593182,
          9.266619624546642,
          8.82593754726117,
          9.350489318039099,
          9.053520896079279,
          8.663388570685855,
          8.633598337509447,
          8.623747488955564,
          9.026109529022698,
          9.216631912811714,
          9.18541587293321,
          9.62625085168869,
          9.936683403214646,
          8.726368056743329,
          10.036845666246958,
          9.685086979594454,
          9.245949362165275,
          9.217801623205084,
          9.017711523503086,
          9.322596670954464,
          9.72628582137747,
          9.414913259105505,
          9.713432312897725,
          9.405219679389004,
          8.997907753698376,
          8.93193589118523,
          8.885163491663393,
          9.946199169527056,
          9.373615838989867,
          8.748210630345302,
          9.338433845467064,
          9.285693946336341,
          9.666730573486314,
          8.690291930266032,
          8.713516410873487,
          8.844932555623505,
          9.524015674960117,
          9.938483909489205,
          10.3790875746506,
          9.667855420132804,
          9.996726538711115,
          9.768670470094055,
          9.38604755868621,
          10.363911796057643,
          10.218058791045843,
          10.364727246240847,
          10.179214410707225,
          9.84976412644874,
          9.428179991714345,
          9.373715322843283,
          9.726584058326793,
          9.125183440413174,
          9.62431530314623,
          9.523120505622382,
          9.683460404558193,
          9.57627412734486,
          9.912842866367038,
          10.030495102892493,
          9.672667871041828,
          9.930246733857736,
          10.259980024970318,
          9.266034372894048,
          9.526670690816609,
          9.640676022743476,
          10.402508571211113,
          9.456966969784993,
          10.223347384492438,
          9.84524654090845,
          11.627235927975935,
          11.098271368039628
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,0,255,0.2)",
         "line": {
          "color": "blue",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          9.708358896163837,
          9.309374076535658,
          11.11895224142199,
          10.373231323184694,
          9.84217387093988,
          8.931839432350982,
          9.784016748922227,
          9.700238216201544,
          9.405031414193854,
          9.008046231002124,
          9.089876210093362,
          9.482314391443664,
          9.655758139327519,
          9.82187523251014,
          10.228934525341668,
          9.537782787470045,
          9.644161769453442,
          9.071209210352595,
          9.491482906019488,
          9.166156442109012,
          9.830407332069822,
          9.92494463399139,
          9.612982698716976,
          9.915571712153675,
          10.005494585261198,
          9.729296625738755,
          10.227460270335621,
          10.065154869141722,
          9.628615830509343,
          9.929379382505514,
          8.952600664659231,
          9.114105492049383,
          10.132227026732263,
          9.937668896783771,
          9.609904013734965,
          10.100715514965458,
          10.379667291628135,
          10.99263209035167,
          10.368324914836537,
          10.732181530731394,
          9.99314816042749,
          9.571859497024578,
          9.517008967291472,
          9.642940665437118,
          9.85870271022804,
          10.84273732658384,
          10.100596245104025,
          10.544330109327902,
          10.009585525040839,
          10.652963598981462,
          10.261009514254999,
          9.611148635480175,
          10.031436071531905,
          10.361689151981553,
          11.583211816452007,
          10.455888541310356,
          10.930058023631949,
          10.927935713279348,
          10.414980128860824,
          11.348856878339866,
          11.279236181411532,
          11.556382614266616,
          11.582139510907266,
          10.667949926235934,
          10.223203049682349,
          11.256204903060798,
          11.103849183404101,
          10.535803854247437,
          11.477879110683716,
          10.916770609134721,
          10.934750030734362,
          10.729044184427039,
          10.815874278472192,
          10.99676501549212,
          11.30475875964273,
          11.28026793198774,
          12.271696281606003,
          12.308462027368384,
          11.709643204700079,
          12.11427473009482,
          12.054736022292106,
          11.265128387247147,
          11.148574678735788,
          11.059116721175139,
          11.716984235602595,
          12.307286191748162,
          11.767852989710805,
          11.846579872237006,
          11.419426956396427,
          11.0735355660973,
          10.972363461754433,
          11.007292703409208,
          12.913451652172828,
          11.576481033531262,
          11.511962249337824,
          11.821384348458762,
          11.908172260087092,
          12.083330908743479,
          12.26916903900479,
          11.360993197321951,
          11.250109101120447,
          12.272075621930119,
          12.706796400481958,
          13.524145905380712,
          11.871986813267357,
          12.170640710647614,
          12.104270278837102,
          11.711220514709998,
          13.557423815175014,
          12.756415675927189,
          12.883011493350985,
          12.616500357744325,
          12.217790119930534,
          11.770094060272896,
          12.1052625720744,
          12.268641480166657,
          11.600841551005946,
          12.05497757689114,
          12.160799327844758,
          12.53449632989312,
          12.375615881559568,
          12.680935978071782,
          12.62426286861743,
          12.336537196297822,
          12.309249879063234,
          12.790040610370465,
          11.85598990608025,
          12.15026910540669,
          12.235118259796907,
          13.335508484360785,
          12.604089246402609,
          13.301504018898655,
          13.541507843416904,
          15.572700021668929,
          14.789496606379926
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Random Forest",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.970175947226188,
          8.133116981123367,
          8.920086790110515,
          8.86312193545792,
          8.910256598204352,
          8.114381793745133,
          8.246457636523248,
          8.353055133925652,
          8.363346129352651,
          8.080369040407554,
          8.11839509977581,
          8.074934994718369,
          8.030241367609696,
          7.9269783749105285,
          8.088385912628564,
          7.96471718397236,
          8.154711227959364,
          7.973698679214622,
          8.098437824865666,
          8.050857859302594,
          8.404251416269528,
          8.553548461455826,
          8.255017044569644,
          8.162150112539358,
          7.646541204394334,
          7.7074844326886485,
          8.062652650448975,
          7.965450465697903,
          8.028801363172327,
          8.12866387902905,
          8.08319404522882,
          8.114659918501276,
          8.420505547327771,
          8.479194124371508,
          8.102568964203103,
          8.05281378435698,
          7.977304554288833,
          7.88454025254554,
          7.967345048471563,
          7.947545412965655,
          8.103341280487466,
          8.142455443982227,
          8.0420268359594,
          8.109557964593652,
          8.177712153165366,
          8.558290675516004,
          8.250273124151498,
          7.825126598234175,
          7.753134040299097,
          7.926653072699625,
          7.904953699729625,
          7.7351512019811,
          7.9795609344077,
          8.189826349484221,
          8.136859277256326,
          8.633783223258911,
          8.72428105338417,
          8.480268907191848,
          8.100203911953297,
          8.157828145878204,
          8.72630149535289,
          8.7091824626943,
          8.56415145130187,
          7.922963383044261,
          8.007277356597324,
          8.187367686142986,
          8.415199889241903,
          8.506024587702969,
          8.661116664546876,
          8.705307752802486,
          8.393750030969539,
          8.114746821349325,
          7.713010072462362,
          7.741470083869826,
          7.9050205287174276,
          7.9131778133570245,
          8.216895556368243,
          8.28329804369985,
          8.400612321867674,
          8.480294471165012,
          8.476597990426646,
          8.569451462222988,
          8.27504172039708,
          7.933188996763019,
          7.924545049525298,
          7.916217307154593,
          7.8641647586951295,
          8.029176227802898,
          8.07481868179733,
          8.13247314303512,
          8.190190360358848,
          8.249342871684233,
          8.565439183488758,
          8.562598693207164,
          8.338357593929715,
          8.07899316793452,
          7.798492017470494,
          7.737429828503895,
          7.86932417269179,
          7.830846953243062,
          7.914847325695302,
          8.074440913178082,
          8.375137261647664,
          8.461957557700023,
          8.405721980457338,
          8.335983988581752,
          8.108339987191991,
          7.990974553604939,
          8.053046044984168,
          7.9616186856802855,
          8.013796671253978,
          8.086852180290041,
          8.09261385324437,
          8.260742868881893,
          8.32133156630796,
          8.631055494346226,
          8.61659867583163,
          8.402220533733756,
          8.130521841447475,
          8.10931142592566,
          7.845973505079886,
          7.757210731074666,
          7.876691946553852,
          8.039299972840604,
          8.188856293901164,
          8.182218726923475,
          8.046831030041613,
          8.255511670303843,
          8.394797399613248,
          8.484065006378811,
          8.104315657816883,
          7.96539392741088,
          8.379620372688626,
          8.816909695774749,
          8.958648280879407
         ]
        },
        {
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.527018077056389,
          7.683767183171842,
          8.33664375392942,
          8.317600127752174,
          8.423214539937575,
          7.8763675999638085,
          7.842911358418431,
          8.080652983482747,
          8.073514554485865,
          7.800668851441079,
          7.7170230421242385,
          7.7364737151284935,
          7.478221867369233,
          7.509804966961025,
          7.763792377246835,
          7.460542263570346,
          7.777242899663627,
          7.732635271106223,
          7.814535083977214,
          7.728163987124751,
          8.066508555124564,
          8.203820277397702,
          7.935874098867023,
          7.790783959324364,
          7.271552307886824,
          7.298061291226585,
          7.639417336431989,
          7.644674582743099,
          7.718472565570446,
          7.805967817094831,
          7.7921336841666715,
          7.85949111507636,
          8.133653648340099,
          8.134317577353624,
          7.72425993250988,
          7.745127506249049,
          7.593898208096533,
          7.568162637373509,
          7.576110252981088,
          7.566730180933648,
          7.834079405022471,
          7.851945489509474,
          7.779691203610947,
          7.787437242288557,
          7.852025197538526,
          8.16675647988064,
          7.89065356195105,
          7.435922903271518,
          7.341586288037987,
          7.597065397115229,
          7.563205097871144,
          7.392779203597804,
          7.677809393153477,
          7.905107233001827,
          7.834245395027181,
          8.22048146613081,
          8.260146155096807,
          8.085176019545113,
          7.776181465355289,
          7.517666839994141,
          7.983621951878748,
          8.047937372016849,
          8.023737356391552,
          7.571162254643967,
          7.675842836733699,
          7.872055711153606,
          8.090201094305936,
          8.190531249747515,
          8.324066883251463,
          8.306965629416053,
          8.012872514999788,
          7.692121587833186,
          7.321490151159144,
          7.418590595027021,
          7.5646768765788615,
          7.536103181655302,
          7.915977542987897,
          7.932770275858406,
          8.0944918742514,
          8.146363689523714,
          8.169217258307116,
          8.212681344278543,
          7.895901199492744,
          7.6044969243886955,
          7.576777315586159,
          7.525415297054499,
          7.502640246704966,
          7.719153449197739,
          7.790291557827805,
          7.80494337858194,
          7.8404548294111285,
          7.947750537074051,
          8.223392164504107,
          8.194575516722239,
          7.937609324040899,
          7.728780583127209,
          7.4624783527618215,
          7.379610906986779,
          7.562357607571321,
          7.49129794555634,
          7.544368947455046,
          7.79360594046431,
          8.088387099306901,
          8.162922406458586,
          8.038616983334476,
          8.0099910046629,
          7.78036782478137,
          7.600010830087996,
          7.7034189806822715,
          7.558482234399727,
          7.701209169481627,
          7.7600533668564635,
          7.812732069134644,
          7.918164744880575,
          7.946982216414263,
          8.267998776794553,
          8.275860467052018,
          8.042895424409348,
          7.819833037890474,
          7.725181453150024,
          7.441821237711951,
          7.411522247856308,
          7.516789617338598,
          7.659103779744464,
          7.89199178050565,
          7.94186279725157,
          7.814837587327346,
          7.87635184092468,
          8.057189961087799,
          8.130127130811031,
          7.7846788708541625,
          7.302994115630078,
          7.616223674590764,
          8.188331781617888,
          8.444756199771254
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,0,0,0.2)",
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          8.531203994014433,
          8.736734190876591,
          9.34599560964334,
          9.318187850861504,
          9.314846800011924,
          8.522983888733531,
          8.784702274127701,
          8.695405047095678,
          8.719920987516971,
          8.421540933201834,
          8.578074835244953,
          8.496155093294561,
          8.921659876089041,
          8.37412969820985,
          8.585850476532885,
          8.589181198699379,
          8.575046598670557,
          8.335528937433073,
          8.470894842516378,
          8.421635855093012,
          8.7005222116118,
          8.880541780682332,
          8.596693640514498,
          8.60469898449488,
          8.015313048304083,
          8.145412734863209,
          8.569204245724283,
          8.38940054133259,
          8.408732195103621,
          8.469978318543042,
          8.420883923865228,
          8.499064194898958,
          8.67298926122803,
          8.791533968924343,
          8.47741466959339,
          8.347342940490606,
          8.380232146835871,
          8.296721851494603,
          8.513158432916288,
          8.350148488739789,
          8.55112162319429,
          8.526703443566271,
          8.426504587748445,
          8.49035195032027,
          8.53780600543547,
          8.889729347242962,
          8.66247188407164,
          8.224874341660765,
          8.364035781180197,
          8.427234040644132,
          8.370985515013663,
          8.12821069995325,
          8.342968159072242,
          8.5655411303941,
          8.538435567394798,
          9.073559617261404,
          9.202054120989049,
          8.81447263600255,
          8.504773799002383,
          9.111203744480902,
          9.44516930061961,
          9.279273023521004,
          9.138789970155269,
          8.304660459422587,
          8.429528920242866,
          8.513183091111603,
          8.781227740016845,
          8.910220905695892,
          8.932497352122594,
          9.052005148427524,
          8.738397344115793,
          8.522074028814048,
          8.102570297297012,
          8.143543007991516,
          8.354128618270368,
          8.372984924610739,
          8.611849412118387,
          8.602409234854354,
          8.841609906882006,
          8.807395468426352,
          8.824110997518959,
          8.866753000127984,
          8.677217509189402,
          8.285189520388325,
          8.293119942223216,
          8.368660129329218,
          8.306260359559916,
          8.422622140564918,
          8.500259563092062,
          8.474231222501222,
          8.568397198590024,
          8.627104600685152,
          8.828509336799202,
          8.872943366082707,
          8.688342538244378,
          8.446000344052901,
          8.156324778359155,
          8.111347677278534,
          8.279243874874492,
          8.260387856614683,
          8.307501788302554,
          8.431129384216876,
          8.693550500846525,
          8.82138659511442,
          8.795955691292146,
          8.750169507367596,
          8.473500671275351,
          8.397927409952153,
          8.478579682267647,
          8.458212777713268,
          8.514179399352942,
          8.493300953126573,
          8.547915137879492,
          8.645760370754422,
          8.686701184537574,
          9.013560440003769,
          8.920035078011146,
          8.713422428160486,
          8.4621353375847,
          8.440526033250425,
          8.235327643988798,
          8.167267371702057,
          8.334154014668426,
          8.51456763343226,
          8.584857976913938,
          8.584419418926336,
          8.442200110932497,
          8.71045289617997,
          8.777365664604025,
          8.840234464921872,
          8.511252847290379,
          8.930799924303122,
          9.298604025557765,
          9.354777727280311,
          9.340321685389105
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "XGBoost",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.480475435256958,
          7.506467304229736,
          7.472474875450135,
          7.535059423446655,
          7.669988875389099,
          7.681785173416138,
          7.775604286193848,
          7.836787371635437,
          7.826214919090271,
          7.668319544792175,
          7.583769006729126,
          7.565866255760193,
          7.5026559638977055,
          7.580262699127197,
          7.61124349117279,
          7.631822276115417,
          7.738980054855347,
          7.656036882400513,
          7.821987605094909,
          7.818881273269653,
          7.880794262886047,
          7.86156042098999,
          7.747827610969543,
          7.70810106754303,
          7.54486572265625,
          7.495430951118469,
          7.608161973953247,
          7.614802174568176,
          7.684083614349365,
          7.76194474697113,
          7.731427578926087,
          7.820618414878846,
          7.9422147178649904,
          7.7875587844848635,
          7.633152179718017,
          7.626865739822388,
          7.611078858375549,
          7.585684323310852,
          7.567767162322998,
          7.5660692405700685,
          7.617253456115723,
          7.786691889762879,
          7.790178499221802,
          7.814837198257447,
          7.819949669837952,
          7.97088164806366,
          7.699530673027039,
          7.585862298011779,
          7.508878626823425,
          7.573343424797058,
          7.566380653381348,
          7.572550783157348,
          7.645367436408996,
          7.841899876594543,
          7.7209962415695195,
          7.71094626903534,
          7.787603840827942,
          7.798426594734192,
          7.614619565010071,
          7.473442397117615,
          7.473224906921387,
          7.482385220527649,
          7.609578862190246,
          7.552701416015625,
          7.635352597236634,
          7.862449908256531,
          7.939967393875122,
          7.8819222116470335,
          7.97006820678711,
          7.883717737197876,
          7.750771040916443,
          7.675587797164917,
          7.566751022338867,
          7.563748440742493,
          7.617796287536621,
          7.601018323898315,
          7.854979395866394,
          7.818530740737915,
          7.931599445343018,
          7.893893022537231,
          8.004936380386352,
          7.884012379646301,
          7.684936656951904,
          7.641958518028259,
          7.615202865600586,
          7.662993311882019,
          7.553279032707215,
          7.630387306213379,
          7.692727518081665,
          7.754088478088379,
          7.821098313331604,
          7.896485562324524,
          8.018725967407226,
          7.890457224845886,
          7.680237112045288,
          7.711758885383606,
          7.623232707977295,
          7.599489326477051,
          7.5925959920883175,
          7.611353178024292,
          7.652192411422729,
          7.784086604118347,
          7.9814217042922975,
          8.083788590431213,
          7.845898761749267,
          7.822868504524231,
          7.7708482694625856,
          7.577174959182739,
          7.593455648422241,
          7.638514103889466,
          7.572833795547485,
          7.669348387718201,
          7.7231702661514285,
          7.804651203155518,
          7.967478194236755,
          7.982244935035705,
          7.9158597707748415,
          7.75606915473938,
          7.735076408386231,
          7.710063681602478,
          7.600265827178955,
          7.594279680252075,
          7.595086379051208,
          7.560414733886719,
          7.667753682136536,
          7.826335926055908,
          7.777089991569519,
          7.860121459960937,
          7.861065902709961,
          7.908227524757385,
          7.606064758300781,
          7.507854399681091,
          7.361002883911133,
          7.601065273284912,
          7.645006995201111
         ]
        },
        {
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.28275077342987,
          7.314425134658814,
          7.202919507026673,
          7.3033726811409,
          7.531048703193664,
          7.542886519432068,
          7.62605984210968,
          7.671083378791809,
          7.659123694896698,
          7.528957819938659,
          7.40501708984375,
          7.402864015102386,
          7.308506751060486,
          7.430739760398865,
          7.47353503704071,
          7.511225974559784,
          7.602418887615204,
          7.518355536460876,
          7.659642887115479,
          7.6617695689201355,
          7.7033926486969,
          7.693142390251159,
          7.60481104850769,
          7.577666294574738,
          7.39924190044403,
          7.329375886917115,
          7.460969305038452,
          7.48477532863617,
          7.559888505935669,
          7.616783463954926,
          7.586694896221161,
          7.66323618888855,
          7.763908791542053,
          7.634460020065307,
          7.504782450199127,
          7.494034838676453,
          7.459359931945801,
          7.447140681743622,
          7.429411351680756,
          7.398611867427826,
          7.486014807224274,
          7.648904013633728,
          7.633774375915527,
          7.659153914451599,
          7.657617223262787,
          7.779204320907593,
          7.576339542865753,
          7.453273952007294,
          7.325666379928589,
          7.4333631753921505,
          7.43544989824295,
          7.446829068660736,
          7.516134703159333,
          7.695230877399444,
          7.434680414199829,
          7.504131531715393,
          7.63306827545166,
          7.648580861091614,
          7.455742275714874,
          7.240553724765777,
          7.22448513507843,
          7.281747496128082,
          7.44492506980896,
          7.413284957408905,
          7.511372804641724,
          7.711144101619721,
          7.7754671454429625,
          7.7188940167427065,
          7.785835480690002,
          7.712727797031403,
          7.6176817417144775,
          7.558220100402832,
          7.4300735831260685,
          7.417523288726807,
          7.487360823154449,
          7.463706922531128,
          7.704931998252869,
          7.661285150051117,
          7.759284126758575,
          7.727255702018738,
          7.813475382328034,
          7.722133088111877,
          7.5570024967193605,
          7.519158494472504,
          7.483545649051666,
          7.543962216377258,
          7.409181368350983,
          7.489694488048554,
          7.572416126728058,
          7.61429625749588,
          7.664478826522827,
          7.733933353424073,
          7.821507287025452,
          7.727225804328919,
          7.5453051090240475,
          7.585431671142578,
          7.500411236286164,
          7.471119904518128,
          7.457429075241089,
          7.49166876077652,
          7.528764712810516,
          7.649424743652344,
          7.807141447067261,
          7.8731204748153685,
          7.68018057346344,
          7.6633204340934755,
          7.635302281379699,
          7.401737439632416,
          7.447592401504517,
          7.493804407119751,
          7.433157670497894,
          7.5340705752372745,
          7.6020297646522526,
          7.657905876636505,
          7.801321160793305,
          7.803255844116211,
          7.751767528057099,
          7.6122271656990055,
          7.610183084011078,
          7.593052279949188,
          7.463475525379181,
          7.455133366584778,
          7.453709053993225,
          7.409295821189881,
          7.540198957920074,
          7.681026530265808,
          7.630354034900665,
          7.70359638929367,
          7.695895302295685,
          7.733075273036957,
          7.442859578132629,
          7.304036724567413,
          7.119820499420166,
          7.3702515125274655,
          7.42525532245636
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0,255,0,0.2)",
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.637869787216187,
          7.6929965138435366,
          7.729620838165284,
          7.748852944374084,
          7.800269520282745,
          7.808655846118927,
          7.930277538299561,
          7.961907076835632,
          7.975846016407012,
          7.794490480422973,
          7.705476534366608,
          7.669271886348724,
          7.649626195430756,
          7.7223821640014645,
          7.741487526893616,
          7.742109179496765,
          7.842052710056305,
          7.791120779514313,
          7.953561449050904,
          7.969961452484131,
          8.030053210258483,
          8.002311635017396,
          7.864014756679535,
          7.8170081019401545,
          7.649290025234222,
          7.652494251728058,
          7.743425190448761,
          7.720442700386047,
          7.780851578712463,
          7.866866850852967,
          7.8530774235725405,
          7.974334812164306,
          8.10717694759369,
          7.9124943852424625,
          7.741631627082825,
          7.746607887744903,
          7.733318722248077,
          7.720948016643524,
          7.714595448970795,
          7.721003901958466,
          7.735313236713409,
          7.901368272304535,
          7.926945233345032,
          7.96039696931839,
          7.950109708309173,
          8.139766144752501,
          7.80960294008255,
          7.6909115552902225,
          7.647672533988953,
          7.716058707237243,
          7.702875816822052,
          7.698816764354706,
          7.7502427220344545,
          7.95620596408844,
          8.029235434532165,
          7.896880257129669,
          7.925402867794037,
          7.923089504241943,
          7.7368129849433895,
          7.66391259431839,
          7.672117936611175,
          7.705226349830627,
          7.771453487873077,
          7.69730178117752,
          7.736092412471772,
          7.984115207195282,
          8.102611112594605,
          8.047341179847717,
          8.134815955162049,
          8.036680674552917,
          7.8675242304801944,
          7.777685451507568,
          7.6731712341308596,
          7.707519006729126,
          7.742494511604309,
          7.715358173847198,
          7.973259508609772,
          7.9381954073905945,
          8.144661951065064,
          8.04203233718872,
          8.200194191932678,
          8.04714879989624,
          7.80087263584137,
          7.753259229660034,
          7.723386216163635,
          7.7681357860565186,
          7.68551379442215,
          7.753873646259308,
          7.799319648742676,
          7.85409984588623,
          7.949250900745392,
          8.057098317146302,
          8.217564177513122,
          8.055357432365417,
          7.802588987350464,
          7.819767546653748,
          7.731415724754333,
          7.71333487033844,
          7.732360565662384,
          7.724820756912232,
          7.753032171726227,
          7.914364349842072,
          8.163283133506775,
          8.302159571647644,
          8.010060620307922,
          7.95100177526474,
          7.882883048057556,
          7.7010670542716975,
          7.69820739030838,
          7.773853206634521,
          7.720736837387085,
          7.800638091564179,
          7.825761353969574,
          7.918441319465638,
          8.133415126800537,
          8.159302973747254,
          8.087692809104919,
          7.880816495418548,
          7.843317198753357,
          7.819355928897858,
          7.7110411643981935,
          7.718327569961548,
          7.731818807125092,
          7.719657599925995,
          7.782882845401764,
          7.940359199047089,
          7.938088309764862,
          8.02405252456665,
          8.0176029920578,
          8.05923318862915,
          7.7713991641998295,
          7.690609550476074,
          7.6423632264137265,
          7.820360994338989,
          7.836898934841156
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines",
         "name": "LightGBM",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.534676268851414,
          7.48251370630572,
          7.506978655610266,
          7.413420652800599,
          7.604823213152117,
          7.711817350446544,
          7.91519360321348,
          8.02337925627906,
          8.125455968013046,
          7.722762199683543,
          7.638623306683197,
          7.753924894814987,
          7.330281683524385,
          7.4000118240445385,
          7.389343230848936,
          7.263311546530262,
          7.638781374230652,
          7.579177481437383,
          7.660855826382217,
          7.704792195177064,
          8.112072867882853,
          8.228267831022077,
          7.903424744563009,
          7.597883068340423,
          7.504292129560347,
          7.148201358598974,
          7.314615354169314,
          7.462622411766245,
          7.581088659055204,
          7.651128111632045,
          7.694090550726495,
          7.847440677114267,
          8.164474640126247,
          8.00333235659937,
          7.713846076077634,
          7.46769601695579,
          7.753778048263546,
          7.366497548102841,
          7.495816166136715,
          7.457665133208551,
          7.490322667622682,
          7.600912387161276,
          7.785962335610008,
          7.636944795146894,
          7.764706683224163,
          8.000080477454603,
          7.642969171297268,
          7.255492207644392,
          7.188673535706085,
          7.50462603732296,
          7.563318588287362,
          7.357012211919916,
          7.838844882094365,
          7.649991761692187,
          7.854677467307146,
          8.016578705805738,
          7.988692262965149,
          7.918668929918399,
          7.557614576222237,
          7.14699981178997,
          7.1471300152294495,
          7.282553408267972,
          7.312992550302831,
          7.348631242486193,
          7.483240298271656,
          7.661898832094794,
          8.095246937458692,
          8.109196850376465,
          7.949991740229113,
          8.05089859717082,
          7.65513884157617,
          7.547806793554076,
          7.170776178123938,
          7.088972373862004,
          7.245997018763027,
          7.544118012011812,
          7.642860800375367,
          7.733016328386266,
          7.814598849158362,
          7.883365441226192,
          8.131067992708736,
          8.05217931969738,
          7.720527826164454,
          7.463581792588042,
          7.610610362448677,
          7.566719304989877,
          7.39809747567538,
          7.628009943453642,
          7.458382525414538,
          7.61220313301115,
          7.689268667607248,
          7.694764517405555,
          7.984541982360489,
          7.955041545066496,
          7.832192068168623,
          7.551386731896299,
          7.382136072001685,
          7.102360855020355,
          7.513589223496918,
          7.369567572427596,
          7.307247851081076,
          7.783695963136714,
          7.947592104768653,
          8.005877612800584,
          7.8878588694270935,
          7.7760172284561095,
          7.709908824869519,
          7.468867777290118,
          7.1738003499565925,
          7.509072645867989,
          7.299821367836087,
          7.356858186991453,
          7.669804289887287,
          7.551954045992676,
          7.713978356133066,
          8.028759079488358,
          7.989966011680335,
          7.8049646902705625,
          7.530264145464579,
          7.434011403710584,
          7.291014859365401,
          7.1464919240190685,
          7.1683075129382345,
          7.32059779451496,
          7.351806387940996,
          7.406908003320533,
          7.5420253715945105,
          7.781804741035398,
          7.829916942585824,
          7.977793410280048,
          7.669921235720956,
          7.040830469198774,
          7.115028086797971,
          7.0327573674313,
          7.192446752221369
         ]
        },
        {
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.028016255649717,
          6.9636033282835905,
          7.120565679918571,
          7.028438648865287,
          7.346140570208219,
          7.415875642358931,
          7.606569766188843,
          7.713039357535728,
          7.76204578854843,
          7.405000308796667,
          7.25619843592586,
          7.371137598989308,
          7.002590974849952,
          7.0755096523496475,
          7.079811069909154,
          6.863356865270786,
          7.264456019714815,
          7.085957019676298,
          7.3315223769019315,
          7.2176205337176675,
          7.764133132454507,
          7.8420918940039925,
          7.565269691531513,
          7.140757421968689,
          7.151841448460134,
          6.6747866429625144,
          6.9609750013174505,
          7.067510581585483,
          7.1401815242484945,
          7.117722606431331,
          7.1730375336708025,
          7.3590745157256805,
          7.750250292154966,
          7.595610732663548,
          7.307128862323789,
          7.077794969222273,
          7.325555818942875,
          6.948625749947462,
          6.9878003158926125,
          6.937377344435887,
          6.991104985555681,
          7.047721812332491,
          7.314854437312093,
          7.145209051667797,
          7.375587667403429,
          7.564243684598716,
          7.171946551646986,
          6.70733762775588,
          6.732961314879131,
          6.9644082940016805,
          6.958086735388476,
          6.837409272356626,
          7.4099275993827405,
          7.039650226682828,
          7.346553266436822,
          7.443237974993002,
          7.348365250822846,
          7.3156067296486285,
          7.007969383773505,
          6.499337671887004,
          6.664291259360545,
          6.62130411216108,
          6.703112073827066,
          6.720872963904869,
          6.933143707131389,
          7.1350508569798885,
          7.438821564309174,
          7.536419464812984,
          7.274623547197969,
          7.473742359525165,
          7.105849349726964,
          6.961009250293026,
          6.590701010606462,
          6.287263374027417,
          6.602533008047201,
          6.896570790944077,
          6.912912112761082,
          7.031136590519923,
          6.964172736673767,
          6.822202291067753,
          7.388802753232,
          7.119766681956971,
          7.0723032861272745,
          6.730359885523383,
          6.831536192245487,
          6.755454172532968,
          6.596566635160056,
          6.973199235439415,
          6.634613485430376,
          6.7012908275581085,
          6.967733860594383,
          6.81913600317564,
          7.27507320081484,
          7.005528972018086,
          7.0581752227480825,
          6.850550315445825,
          6.7069214875122345,
          6.204255255298821,
          6.625362575323288,
          6.651379981796698,
          6.6125941311437915,
          7.0109776841386395,
          7.140634744614433,
          6.893488364949841,
          6.477341534263622,
          6.701983968341117,
          6.926592592980701,
          6.67452874235612,
          6.377378208426332,
          6.719253063251403,
          6.422745053729008,
          6.457961628060116,
          6.797741947799909,
          6.588228129555271,
          6.845029986812214,
          7.086928092074873,
          6.957865377481431,
          6.728173416066103,
          6.654986076684112,
          6.667122763683249,
          6.3590792013114825,
          6.329486384581734,
          6.0742726747491655,
          6.204636321520729,
          6.338242038544435,
          6.364247211229316,
          6.587346346337942,
          6.804278140913231,
          6.868837143610394,
          6.918822564779756,
          6.6698100720843385,
          6.104262839360271,
          5.924584638320211,
          5.918734823418041,
          6.199333125232035
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(128,0,128,0.2)",
         "line": {
          "color": "purple",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.994146552093901,
          8.050983360903377,
          7.868371206320109,
          7.770665617214941,
          7.876946232322465,
          7.996378825310393,
          8.207084071792824,
          8.3844490791566,
          8.544901146641012,
          7.972686851756474,
          7.989086881478762,
          8.160922125238132,
          7.653638082687157,
          7.751100309073573,
          7.7313932914326156,
          7.681547186137859,
          8.00754800958402,
          7.91103726037315,
          7.987398637801242,
          8.067812857482368,
          8.420382586516375,
          8.607757209241507,
          8.274484488858137,
          8.105928392291908,
          7.882049724169033,
          7.47334460632369,
          7.725934671356862,
          7.849385949841462,
          7.916570989322259,
          8.111366695905657,
          8.127752716783764,
          8.27517963787737,
          8.45302841387293,
          8.382894808342199,
          8.107544902273327,
          7.734642733518851,
          8.130564539319508,
          7.793489201083353,
          8.119367948212997,
          7.857803215320828,
          7.881098917985753,
          7.90629700334096,
          8.182477409887237,
          7.992080805550286,
          8.062134685370683,
          8.356645177756997,
          8.097614446362604,
          7.7516377731090405,
          7.578184487170108,
          7.996226600290897,
          8.137951878077375,
          7.834169510147143,
          8.344802602030276,
          8.057025594813274,
          8.306146849727883,
          8.491018097279357,
          8.45196887427966,
          8.330513252059129,
          8.025535407440751,
          7.65535010625482,
          7.538344000971739,
          7.712307277053385,
          7.828215503733433,
          7.865533449846898,
          7.982517263325676,
          8.060805665989378,
          8.550659829660379,
          8.702850505534302,
          8.494463990197676,
          8.46178639354508,
          8.152592494977387,
          8.076247245030059,
          7.659504096538114,
          7.584786654257718,
          7.714806294025171,
          8.008128730824591,
          8.146054013714824,
          8.218992549266847,
          8.373127951861235,
          8.498669928720657,
          8.594494126339288,
          8.748331288225335,
          8.325719512031794,
          8.019444240783805,
          8.09955662103628,
          8.327121645557403,
          7.914002666509062,
          8.10188494532844,
          8.127334470317521,
          8.280388248511848,
          8.202650365923668,
          8.306229848584184,
          8.472051065501116,
          8.496415700420632,
          8.361421770904892,
          8.149182198536037,
          7.833557892114786,
          7.665306314879193,
          8.161512698430316,
          8.104159779561702,
          7.8561699695159435,
          8.27072852042177,
          8.544276657858434,
          8.645072485782814,
          8.56383315645829,
          8.36599371747966,
          8.392282041968013,
          8.069005344802711,
          7.724582887197398,
          8.062142776417613,
          7.977085206476035,
          7.985031715422859,
          8.34690396223317,
          8.22817955774301,
          8.31058885089622,
          8.657013919564902,
          8.795365293361453,
          8.530738069181787,
          8.261668259129543,
          8.275166263169742,
          7.928995208629613,
          7.723904348959201,
          7.799402876097024,
          8.014300772535123,
          8.12523495410394,
          8.087293738097916,
          8.252043307984819,
          8.430614760326138,
          8.488621640245295,
          8.681163379303028,
          8.392475737561583,
          7.723460715189623,
          8.078788717697421,
          7.747270280626852,
          7.970289844589357
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Neural Network",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.636288673849459,
          7.808410509573403,
          8.78227008485846,
          9.112874149213877,
          8.863653411546686,
          8.511746907934272,
          8.52499919770435,
          9.04643698701389,
          8.838732667759,
          8.419940191844873,
          8.108527288050462,
          8.25593260920198,
          8.106427660314209,
          8.042823545454816,
          8.006550342263564,
          8.040458515750009,
          7.937080043632552,
          8.093597383455261,
          8.460796313617752,
          8.40191106824585,
          8.841410371272444,
          9.000860145230115,
          8.65016029603437,
          8.288736729595014,
          7.820258622513056,
          7.662627750781353,
          8.01675965003855,
          7.879533067835665,
          8.077803220305686,
          8.13015531194012,
          8.038683085499962,
          8.202540949491642,
          8.96939434095508,
          8.75201774517721,
          7.997202037788396,
          7.567196840892425,
          7.937981470134953,
          7.941965521813645,
          7.691184288401275,
          8.327634004501226,
          8.251625091443646,
          8.383171404757991,
          8.536344827002186,
          8.471187969259528,
          8.625272287825304,
          9.015556876239344,
          8.670307172918363,
          7.9364717044879525,
          7.841990356588123,
          7.870819656331735,
          7.554946457979445,
          7.615062684763303,
          8.046652813629057,
          8.589150729959252,
          7.9334376707010605,
          8.488603779892067,
          8.860552124565201,
          9.165849165006403,
          8.630737658861888,
          8.677193552080228,
          8.60113556977576,
          8.792891864352915,
          8.695885000707218,
          8.098694437276986,
          8.026539787343761,
          8.543285386289993,
          9.051539207281131,
          8.983700075323354,
          9.292949290685357,
          9.065929204850017,
          8.729562315411837,
          8.127906492927204,
          7.828313413151663,
          7.935812763556824,
          8.150385050094377,
          8.001311177063535,
          8.491947841563764,
          8.70482095514173,
          9.007645460257397,
          9.409263811061017,
          9.195161103422233,
          9.121006081978402,
          8.444145361504773,
          8.147888541698833,
          8.049268743586861,
          8.090132388786984,
          8.17060172048722,
          8.334214391047107,
          8.472475227275508,
          8.522489932425021,
          8.509110854688663,
          8.713853486004384,
          9.04878543929043,
          9.15220690005596,
          8.592254201859127,
          8.060509753663556,
          8.174023366282924,
          7.950278933818335,
          8.018246517659799,
          7.916833903814231,
          8.047875143390488,
          8.270253587750394,
          9.15363653866934,
          9.529545431013485,
          9.247216811800378,
          9.136882155058277,
          8.859412882865909,
          8.348499776713192,
          8.469911815122586,
          8.560788771458023,
          8.62998740242508,
          8.663423105740478,
          8.516544295292055,
          8.728249648223278,
          9.17940249379293,
          9.393755959606471,
          9.294428581292378,
          8.820826784742733,
          8.484214011517636,
          8.383323861735828,
          8.183400709138711,
          8.288473656147376,
          8.446484071766049,
          8.656858839072582,
          8.859565288727072,
          9.022329058575947,
          8.757080728175326,
          8.871291569703956,
          8.914021049977798,
          9.158236989861205,
          8.489367434945134,
          8.595969089706843,
          8.608156869155643,
          9.309037171823121,
          9.620189699077487
         ]
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          7.116280759269791,
          7.512979841903892,
          8.332212757114998,
          8.725922538483696,
          8.494822418036787,
          8.224455650033162,
          8.109877268941405,
          8.7864683622307,
          8.528073168706195,
          8.106127806475627,
          7.7991156778800566,
          8.058318269974261,
          7.769484402301275,
          7.752609222876637,
          7.721551180416968,
          7.812446780281667,
          7.654016698837328,
          7.798225331322688,
          8.258648898168962,
          8.167362455233455,
          8.469542033045627,
          8.66080564474032,
          8.283916297516708,
          7.89824702096313,
          7.499042873227368,
          7.201986925824059,
          7.729462294111899,
          7.598274480809625,
          7.766170836590003,
          7.822907097436026,
          7.724554838358616,
          7.973560892391403,
          8.686842852702187,
          8.347512619924277,
          7.627178196589818,
          7.261930834755405,
          7.637199082262723,
          7.514422589464359,
          7.395997491164465,
          7.989664496894952,
          7.984273107856155,
          8.098545122419342,
          8.279200974075826,
          8.239533157807305,
          8.32070889120252,
          8.616477563735339,
          8.192086369552177,
          7.62990539361739,
          7.538078502931303,
          7.480263091717688,
          7.1671068819900015,
          7.291088422622081,
          7.763277266885392,
          8.303345674837875,
          7.3102849019480125,
          8.020234904685205,
          8.469347571351186,
          8.844389677770652,
          8.275599012575523,
          8.192634216697273,
          8.028897707878272,
          8.403803784477894,
          8.335910163122643,
          7.761716308999098,
          7.747210709217371,
          8.258300446358238,
          8.746377472658605,
          8.676282995429407,
          8.921154430237154,
          8.63391570732245,
          8.214670309408401,
          7.703160259402402,
          7.4781831831730505,
          7.476527332635083,
          7.827840396796262,
          7.686180115626383,
          8.180886695106462,
          8.341929606900994,
          8.509326855208437,
          9.052069259464638,
          8.782912509424813,
          8.75273056384361,
          8.058066767824666,
          7.7856983874745005,
          7.7230868959155705,
          7.6904533826327235,
          7.839340259552129,
          8.006047935299257,
          8.213362729353742,
          8.230506284580308,
          8.254387240662583,
          8.435698079920115,
          8.643208235744359,
          8.756774479519205,
          8.14552885996796,
          7.719445259322374,
          7.7953965906489575,
          7.499006360746327,
          7.585836653051345,
          7.584681992932014,
          7.686556346594802,
          7.894558942730029,
          8.814615403266988,
          9.07155002474439,
          8.82918534515185,
          8.773091867205231,
          8.48320681021229,
          7.996415148430655,
          8.106300432186211,
          8.116976862803096,
          8.302857642462184,
          8.335547037256793,
          8.183981942569915,
          8.446166399823715,
          8.782697554195224,
          9.02081827947196,
          8.94295242450247,
          8.364281688252134,
          8.065147781462331,
          7.974358799616124,
          7.815516045339971,
          7.82745482232102,
          8.073703864771426,
          8.337078679627982,
          8.592603435595604,
          8.745122386458805,
          8.406320748042752,
          8.595266450046212,
          8.634224802284619,
          8.796313352998192,
          8.019999427985535,
          7.984732827846881,
          7.937011020728913,
          8.827351486851784,
          9.049325766358361
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255,165,0,0.2)",
         "line": {
          "color": "orange",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "95% CI",
         "type": "scatter",
         "x": [
          "2012-12-31T00:00:00",
          "2013-01-31T00:00:00",
          "2013-02-28T00:00:00",
          "2013-03-31T00:00:00",
          "2013-04-30T00:00:00",
          "2013-05-31T00:00:00",
          "2013-06-30T00:00:00",
          "2013-07-31T00:00:00",
          "2013-08-31T00:00:00",
          "2013-09-30T00:00:00",
          "2013-10-31T00:00:00",
          "2013-11-30T00:00:00",
          "2013-12-31T00:00:00",
          "2014-01-31T00:00:00",
          "2014-02-28T00:00:00",
          "2014-03-31T00:00:00",
          "2014-04-30T00:00:00",
          "2014-05-31T00:00:00",
          "2014-06-30T00:00:00",
          "2014-07-31T00:00:00",
          "2014-08-31T00:00:00",
          "2014-09-30T00:00:00",
          "2014-10-31T00:00:00",
          "2014-11-30T00:00:00",
          "2014-12-31T00:00:00",
          "2015-01-31T00:00:00",
          "2015-02-28T00:00:00",
          "2015-03-31T00:00:00",
          "2015-04-30T00:00:00",
          "2015-05-31T00:00:00",
          "2015-06-30T00:00:00",
          "2015-07-31T00:00:00",
          "2015-08-31T00:00:00",
          "2015-09-30T00:00:00",
          "2015-10-31T00:00:00",
          "2015-11-30T00:00:00",
          "2015-12-31T00:00:00",
          "2016-01-31T00:00:00",
          "2016-02-29T00:00:00",
          "2016-03-31T00:00:00",
          "2016-04-30T00:00:00",
          "2016-05-31T00:00:00",
          "2016-06-30T00:00:00",
          "2016-07-31T00:00:00",
          "2016-08-31T00:00:00",
          "2016-09-30T00:00:00",
          "2016-10-31T00:00:00",
          "2016-11-30T00:00:00",
          "2016-12-31T00:00:00",
          "2017-01-31T00:00:00",
          "2017-02-28T00:00:00",
          "2017-03-31T00:00:00",
          "2017-04-30T00:00:00",
          "2017-05-31T00:00:00",
          "2017-06-30T00:00:00",
          "2017-07-31T00:00:00",
          "2017-08-31T00:00:00",
          "2017-09-30T00:00:00",
          "2017-10-31T00:00:00",
          "2017-11-30T00:00:00",
          "2017-12-31T00:00:00",
          "2018-01-31T00:00:00",
          "2018-02-28T00:00:00",
          "2018-03-31T00:00:00",
          "2018-04-30T00:00:00",
          "2018-05-31T00:00:00",
          "2018-06-30T00:00:00",
          "2018-07-31T00:00:00",
          "2018-08-31T00:00:00",
          "2018-09-30T00:00:00",
          "2018-10-31T00:00:00",
          "2018-11-30T00:00:00",
          "2018-12-31T00:00:00",
          "2019-01-31T00:00:00",
          "2019-02-28T00:00:00",
          "2019-03-31T00:00:00",
          "2019-04-30T00:00:00",
          "2019-05-31T00:00:00",
          "2019-06-30T00:00:00",
          "2019-07-31T00:00:00",
          "2019-08-31T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-30T00:00:00",
          "2019-12-31T00:00:00",
          "2020-01-31T00:00:00",
          "2020-02-29T00:00:00",
          "2020-03-31T00:00:00",
          "2020-04-30T00:00:00",
          "2020-05-31T00:00:00",
          "2020-06-30T00:00:00",
          "2020-07-31T00:00:00",
          "2020-08-31T00:00:00",
          "2020-09-30T00:00:00",
          "2020-10-31T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-29T00:00:00"
         ],
         "y": [
          8.02969220423721,
          8.122219520296106,
          9.306778513063186,
          9.513721514332556,
          9.227333565152042,
          8.77715276918614,
          8.977902607993299,
          9.264502230360113,
          9.145111960427117,
          8.69224593856736,
          8.388968232907041,
          8.509769065259999,
          8.37893709437292,
          8.265696563064063,
          8.265806253293889,
          8.317703162001848,
          8.225682832161361,
          8.34158181453345,
          8.66245994408914,
          8.616605284904816,
          9.147432375429355,
          9.310275224676822,
          8.931254432375418,
          8.605178552216085,
          8.108186672028301,
          7.981486389623902,
          8.276901122740101,
          8.151532050777625,
          8.339707360922898,
          8.386820409877567,
          8.331537511871279,
          8.45714844789189,
          9.266733325669378,
          9.061454249469806,
          8.312455686443442,
          7.89806604720855,
          8.266123148104878,
          8.33675988831217,
          7.976593861589869,
          8.656269103173912,
          8.52147199429675,
          8.662240864104856,
          8.78620983053134,
          8.707792109234944,
          8.828507070706245,
          9.423318986377375,
          9.035967361223992,
          8.222882902525342,
          8.133108337494118,
          8.170079837463234,
          7.881534933629728,
          7.887023288273497,
          8.25564975743333,
          8.882208289789563,
          8.53908457466146,
          8.93452836545837,
          9.238888702434695,
          9.4588929747067,
          8.923778245914772,
          9.064856715823895,
          9.125932925593782,
          9.203577869428294,
          9.05296632308676,
          8.391123130808616,
          8.28682550405511,
          8.882294152558012,
          9.394167516692496,
          9.281102853186686,
          9.623241707055751,
          9.414965449579151,
          9.1017832366557,
          8.511900019807804,
          8.123928744038261,
          8.256122656914016,
          8.430944107426296,
          8.31741906916656,
          8.834533541579207,
          9.100828637827627,
          9.526875010593976,
          9.767049947386594,
          9.632093779796229,
          9.437652857886965,
          8.779437840575522,
          8.435332619071016,
          8.385488200277832,
          8.433785122166755,
          8.500119928932566,
          8.61299769037102,
          8.73141668394486,
          8.80107750493009,
          8.775491901638365,
          9.011830338693777,
          9.507302847670168,
          9.509065493233873,
          8.946477415566404,
          8.3758376020033,
          8.507676154906385,
          8.305974505704375,
          8.433196458216322,
          8.218483102603171,
          8.329430618758762,
          8.681149280337122,
          9.577791071394433,
          10.04071182864615,
          9.65161894588136,
          9.45549749564438,
          9.155359407374632,
          8.68540462026733,
          8.788471891611827,
          8.893080184813035,
          8.928266244416239,
          8.941294284952516,
          8.876703685341115,
          9.015349796128596,
          9.541562490857405,
          9.773879265491209,
          9.633941224386557,
          9.206888555450654,
          8.812802615551496,
          8.776080745980373,
          8.503300100020097,
          8.664221657880907,
          8.752669484681082,
          8.930912676009825,
          9.14093375478337,
          9.340656896673462,
          9.072605411802092,
          9.181749965757788,
          9.20369753194667,
          9.497993412388325,
          8.841493219969689,
          9.030525682671549,
          9.266154958804245,
          9.837771444252848,
          10.26493773435358
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "DOC (mg/l) - Station 325"
        },
        "xaxis": {
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "title": {
          "text": "DOC (mg/l)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "\n",
    "for station_id in surface_df['Station'].unique():\n",
    "    print(f\"=== Station {station_id} ===\")\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = datasets[station_id]\n",
    "    \n",
    "    lr_result = lr_results[station_id]\n",
    "    rf_result = rf_results[station_id]\n",
    "    xgb_result = xgb_results[station_id]\n",
    "    lgbm_result = lgbm_results[station_id]\n",
    "    mlp_result = mlp_results[station_id]\n",
    "    \n",
    "    rmse_lr = lr_result[\"rmse\"]\n",
    "    rmse_rf = rf_result[\"rmse\"]\n",
    "    rmse_xgb = xgb_result[\"rmse\"]\n",
    "    rmse_lgbm = lgbm_result[\"rmse\"]\n",
    "    rmse_mlp = mlp_result[\"rmse\"]\n",
    "    \n",
    "    r2_lr = lr_result[\"r2\"]\n",
    "    r2_rf = rf_result[\"r2\"]\n",
    "    r2_xgb = xgb_result[\"r2\"]\n",
    "    r2_lgbm = lgbm_result[\"r2\"]\n",
    "    r2_mlp = mlp_result[\"r2\"]\n",
    "    \n",
    "    print(f\"Linear Regression RMSE: {rmse_lr}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    print(f\"XGBoost RMSE: {rmse_xgb}\")\n",
    "    print(f\"LightGBM RMSE: {rmse_lgbm}\")\n",
    "    print(f\"Neural Network RMSE: {rmse_mlp}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(f\"Linear Regression R2: {r2_lr}\")\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"XGBoost R2: {r2_xgb}\")\n",
    "    print(f\"LightGBM R2: {r2_lgbm}\")\n",
    "    print(f\"Neural Network R2: {r2_mlp}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # TRUE\n",
    "    \n",
    "    # add both the training and testing data in a unique trace\n",
    "    y_true = pd.concat([y_tr, y_ts])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_true.index,\n",
    "            y=y_true[\"DOC (mg/l)\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"True\",\n",
    "            line=dict(color=\"black\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # LINEAR REGRESSION\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_ts.index,\n",
    "            y=lr_result[\"y_pred\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Linear Regression\",\n",
    "            line=dict(color=\"blue\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # add confidence intervals\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=lr_result[\"y_pred_lower\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"blue\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=lr_result[\"y_pred_upper\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"blue\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                name=\"95% CI\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(0,0,255,0.2)\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # RANDOM FOREST\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_ts.index,\n",
    "            y=rf_result[\"y_pred\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Random Forest\",\n",
    "            line=dict(color=\"red\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # add confidence intervals\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=rf_result[\"y_pred_lower\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"red\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=rf_result[\"y_pred_upper\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"red\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                name=\"95% CI\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(255,0,0,0.2)\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # XGBOOST\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_ts.index,\n",
    "            y=xgb_result[\"y_pred\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"XGBoost\",\n",
    "            line=dict(color=\"green\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # add confidence intervals\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=xgb_result[\"y_pred_lower\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"green\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=xgb_result[\"y_pred_upper\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"green\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                name=\"95% CI\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(0,255,0,0.2)\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # LGBM\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_ts.index,\n",
    "            y=lgbm_result[\"y_pred\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"LightGBM\",\n",
    "            line=dict(color=\"purple\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # add confidence intervals\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=lgbm_result[\"y_pred_lower\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"purple\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=lgbm_result[\"y_pred_upper\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"purple\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                name=\"95% CI\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(128,0,128,0.2)\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # MLP\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_ts.index,\n",
    "            y=mlp_result[\"y_pred\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Neural Network\",\n",
    "            line=dict(color=\"orange\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # add confidence intervals\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=mlp_result[\"y_pred_lower\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"orange\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=y_ts.index,\n",
    "                y=mlp_result[\"y_pred_upper\"],\n",
    "                mode=\"lines\",\n",
    "                line_color=\"orange\",\n",
    "                line=dict(dash=\"dash\"),\n",
    "                name=\"95% CI\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(255,165,0,0.2)\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"DOC (mg/l) - Station {station_id}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"DOC (mg/l)\",\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-change-MEYtuKH4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
